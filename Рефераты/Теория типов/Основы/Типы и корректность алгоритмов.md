
### Время, чистые функции и неизменяемые значения

Как было сказано в начале, основная причина появления теории типов (теории множеств, $\lambda$-исчисления и проч.) - это предоставление возможности *доказать корректность* алгоритмов. Для появления такой возможности необходимо гарантировать *предсказуемость* вычисления. *Результат* вычисления алгоритма должен быть *детерминирован начальными условиями* - при одних и тех же условиях мы должны получать один и тот же результат. 

Математика зачастую абстрагируется от процесса вычисления, акцентируя внимание на логически корректную декомпозицию большого алгоритма на более мелкие. Например, *пути* на диаграмме типов распадаются на комбинацию отдельных стрелочек-функций. В то же время путь может быть разветвлённым и вычисления должны производиться по всем ветвям. Обычно не декларируется, как вычисление этих ветвей должно быть распределено во времени - параллельно или последовательно и в каком именно порядке - важен лишь результат всех вычислений. Таким образом, один и тот же алгоритм может выполняться по разному.

Но процесс вычислений происходит с участием каких-либо материальных сущностей (например, памяти компьютера), которые склонны менять своё состояние с течением времени. Так что даже если мы включим состояние этих объектов начальные условия алгоритма, нам ещё нужно гарантировать, что оно не изменится *снаружи в процессе вычисления* и не поломает детерминированность.

В программировании сам процесс вычисления алгоритма зачастую играет б**о**льшую роль, чем гарантия корректности этих вычислений. Но если требуется предоставить лучшие гарантии корректности, то стоит учесть перечисленные выше замечания и стараться чаще использовать, так называемые, **чистые функции**. Класс чистых функций можно определить таким двумя условиями:
- никакие вычисления не поломают чистую функцию - при фиксированных значениях аргументах мы всегда можем подменить вычисление предоставлением предопределённого результирующего значения (*ссылочная прозрачность*);
- вычисления чистой функции никак не влияет на вычисления любых других функций. 

Другими словами, функция чистая, если она *детерминирована* и не обладает *побочными эффектами*.

Ссылочную прозрачность функции можно обеспечить, если чётко выделить все начальные условия - значения, хранящиеся в ячейках памяти - и гарантировать их *неизменяемость* в процессе вычисления. Теория типов ориентирована в первую очередь на неизменяемость значений, вычисленных одними функциями и без какого-либо хранения переданные на вход другой функции.

В программировании существует также любопытная концепция *линейных типов*, гарантирующая, что вычисляемые значения будут доступны *единственному* методу, в который они передаются. В процессе вычисления никакой другой метод не сможет прочесть/изменить это значение, а по окончанию вычисления оно вовсе перестанет существовать, но внутри самого метода, где значение существует, мы можем императивно, низкоуровнево, "железо-оптимизированно" его изменить. Это можно обосновать так, будто каждая императивная инструкция принимает на вход одни значения, а возвращает уже новые значения, "забывая" старые, но при этом не возникает проблем с конкурентным доступом к этим же ячейкам памяти из других вычислений. Линейные типы не достаточно широко известны, но это очень интересная тема, достойная отдельной статьи. В общем, наука не стоит на месте, и разрабатываются теории типов, учитывающие изменяемость значений, но пока можно считать, что в общем случае **изменяемость значений = невозможность проверки корректности алгоритма**.

С побочными эффектами ситуация интереснее. Дело в том, что основная задача программирования - это автоматизация различных процессов материального мира. Польза от компьютерных программ как раз заключается в наличии эффектов, во взаимодействии вычислителя с окружением. Полностью "чистый" алгоритм имеет нулевую практическую ценность! Решение парадокса заключается в том, чтобы отделить чистые функции от эффективных вычислений - сама программа должна быть максимально чистой для гарантии корректности, а вычисленные *описания эффектов* отдаются в самом конце общим библиотечным методам или даже среде исполнения. Этот принцип используется в современных Scala-продуктах, написанных на основе библиотек вроде `Cats.Effect` или `ZIO`. К сожалению, это также выходит за рамки данной статьи.

На самом деле, честная проверка наличия побочных эффектов у функции (как "чёрного ящика") оказывается весьма нетривиальной. Оценить "невлияние" вычисления одних функций на другие можно лишь статистически, с определённой долей достоверности. И, вообще говоря, мы получаем целую совокупность классов чистых функций, не влияющих на функции из этого же класса, но потенциально "ломающих" детерминизм функции из других таких классов... Так что, "чистые функции" оказываются не таким уж "чистым", но их роль по прежнему крайне важна как рекомендация, позволяющая повысить качество алгоритмов.
<div style="page-break-after: always;"></div>



### Соответствие Карри-Ховарда.

Доказательство корректности алгоритма должно подчиняться законам математической логики. Развивая теорию типов разные исследователи обращали внимание, что построение конструктивного доказательства очень похоже на описание вычислений, а высказывания *конструктивной* логики по своей структуре схожи с *типами* вычисляемых выражений. Такая схожесть логических систем с языками программирования называется *соответствием Карри-Ховарда*:

|Логические системы|Языки программирования|
|---|---|
|Высказывание $T$|Тип $T$|
|Доказательство высказывания $T$|Терм (значение) типа $T$|
|Утверждение $T$ доказуемо|Тип $T$ обитаем (могут быть получены значения)|
|Дизъюнкция $A\lor B$|Тип суммы $A+B$|
|Конъюнкция $A\land B$|Тип произведения $A\times B$|
|Импликация $A\Rightarrow B$|Экспоненциальный тип $B^A$|
|Истинная формула|Тип-единица $1$|
|Ложная формула|Нулевой тип $0$|
|Отрицание $\neg A$|Экспоненциальный тип $0^A$|

https://habr.com/ru/articles/269907/
Корректности программы-функции эквивалентна обитаемости соответствующего ей типа. Таким доказательством является "свидетель" - значение (терм, если точнее) этого типа. Например, значением функционального типа, описывающего программу, является *реализация* этой программы, внутри которой мы получаем значение типа-результата на основе значений типов аргументов. Невозможность получить какое-либо значение описывается необитаемым нулевым типом.

### Отрицание типа и проблема останова

https://www.mccme.ru/dubna/2017/notes/bragilevsky-notes.pdf
Особого внимания заслуживает понятие "отрицание типа": $\neg A\cong0^A$. В *конструктивной* теории типов попросту невозможно построить незавершающиеся вычисления. Функции из любого обитаемого типа $A$ в нулевой тип просто не существует, тип таких функций необитаем: $0^A\cong0$. Но если необитаем сам $A\cong0$, тогда $0^A\cong1$ - единственное значение такого типа-экспоненциала - это функция идентичности. Таким образом, "отрицание" обитаемого типа превращает его в "ложный" необитаемый тип, а "отрицание" необитаемого типа - это "истинный" тип-одиночка!

Логическая тавтология $A\Rightarrow \neg\neg A$ полностью соответствует аналогичному выражению в теории типов - если есть обитаемый тип $A$, то мы всегда можем получить его двойное отрицание - тип-одиночку. Первое отрицание в $\neg\neg A$ даёт необитаемый тип, отрицание которого соответствует типу-одиночке). Но вот обратное утверждение $\neg\neg A\Rightarrow A$ уже не является конструктивным - двойное отрицание типа даёт "истинный" тип-одиночку, но не исходный тип.

В этой статье представлены лишь некоторые элементы теории типов. Но на данный момент даже самые передовые её разновидности не позволяют выяснить, может ли завершится *абсолютно любая программа*, или её тип эквивалентен $0^A$. Типичный пример проблемного алгоритма - [сиракузская последовательность (гипотеза Коллаца)](https://ru.wikipedia.org/wiki/%D0%93%D0%B8%D0%BF%D0%BE%D1%82%D0%B5%D0%B7%D0%B0_%D0%9A%D0%BE%D0%BB%D0%BB%D0%B0%D1%82%D1%86%D0%B0). Математики до сих пор точно не уверены завершится ли этот алгоритм для всех чисел, или для каких-то нет. Всё это упирается в более фундаментальную [проблему останова](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D0%B0_%D0%BE%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BA%D0%B8) - доказано, что в общем случае эта проблема неразрешима.

Тем не менее, наука не стоит на месте. Например, в 2020 году опубликованы исследования экономичной (cost-aware) теории типов, учитывающей сложность алгоритма и, в том числе, проблему останова. Может быть, в ближайшем будущем разработают достаточно гибкий язык, на котором (опционально) невозможно будет написать программу, упирающуюся в эту проблему, и всегда можно будет доказать, выполнятся ли такие программы, или же нет?

### Типизация

Разные языки предоставляют разную реализацию понятий теории типов. Система типов конкретного языка определяется синтаксисом и грамматикой при работе с типами, а также некоторыми механизмами компилятора языка, для которых используется обобщающий термин "типизация". Часто используются такие классификации типизаций:
- сильная/слабая,
- статическая/динамическая,
- явная/неявная,
- иерархическая/утиная.

"Сила" типизации заключается в том, насколько сильно компилятор противостоит попыткам программиста сделать некорректное приведение типов. Например, попытка привести указатель на ячейку памяти со значением типа `Int8` к указателю типа `Int64` может привести к фатальным последствиям, в худшем случае вы даже не заметите, что данные оказались испорчены. Сильная типизация защищает память от некорректного использования. В то же время, слабая типизация допускает изящные хаки, вроде [быстрого извлечения квадратного корня](https://habr.com/ru/articles/730872/):
```cpp
y = number;                   // numner, ok
i = * ( long * ) &y;          // ?
i = 0x5f3759df - ( i >> 1 );  // ???????
y = * ( float * ) &i;         // √number (ну, почти)))
```

Динамическая типизация позволяет не указывать типы термов - они будут вычисляться в процессе выполнения программы. Это делает язык более простым для освоения, что лежит в основе популярности таких языков, как Python или JScript. Статическая типизация требует, чтобы типы всех термов были определены на этапе компиляции - факт компиляции обеспечивает корректность алгоритма в той степени, насколько хорошо там использованы возможности теории типов.
![[динамическая типизация.png]]
Реализация в языке программирования теории типов - задача очень сложная. Немногие языки могут похвастать полнотой этой реализации, но даже они не могут предоставить стопроцентную гарантию корректности скомпилированного кода (хотя их гарантии существенно выше, чем у большинства популярных языков). Впрочем, сейчас во многих языках с динамической типизаций также становятся популярны механизмы контроля типов.

Статическую типизацию укоряют в избыточности аннотирования типами всего подряд. На это обычно отвечают что-то вроде "явное всегда лучше не явного" - девиз Капитана-Очевидность. За это все его и любят. Или же не все? На самом деле типы некоторых термов вполне однозначно фиксируются их конструкцией, вложенными термами. Этот факт часто используются для вывода типов терма как и в динамически-, так и в статически-типизированных языках. Например, ранее, в разделе, где обсуждалось каррирование, был приведён фрагмент кода на языке F# - там типы вообще нигде не указывались, тем не менее, код является хоть и *неявно*, но статически типизированным, благодаря *механизму вывода типов Хиндли-Милнера*, используемому во всех языках семейства ML. Типы настолько круты, что лишний раз их лучше не упоминать в программе!
![[явная типизация.png]]
(Подпись: Капитан-Очевидность даже дома не устаёт от явной типизации)

"Если код плавает как утка, и крякает как утка, то скорее это и есть утиная типизация". При утиной типизации не требуется, чтобы значение реализовывало конкретный тип, важно лишь наличие проекторов (свойств, методов) с заданной сигнатурой. В Scala к утиной типизации относится использование так называемых *структурных типов*:
```scala
import reflect.Selectable.reflectiveSelectable // В Scala 2 это не нужно
final class SampleTrait { def f() = 42 }       // нет наследников
type StructuralType =   { def f(): Int }       // структурный тип

val someVal   : SampleTrait    = ???           // реализация не важна
val anotherVal: StructuralType = someVal       // утиная типизация
val intVal    : Int            = anotherVal.f()// кря
```
В этом примере переменная `anotherVal` относится к структурному типу `{ def f(): Int }`, который не наследует от `SampleTrait`, но преобразование типов происходит автоматически. Утиную типизацию обычно противопоставляют иерархической подтипизации, основанной на наследовании типов. Утиная типизация значительно слабее иерархической, так теряется семантика различия типов с разными идентификаторами, но с методами и свойствами одинаковой сигнатуры:
![[утиная типизация.png]]

### SKI - корректность без типов