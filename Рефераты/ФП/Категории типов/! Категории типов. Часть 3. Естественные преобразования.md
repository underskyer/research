         
Это третья часть обзора и она всё также вводная)). **В первой** было рассказано о категориях типов, а **во второй** — о категории подкатегорий типов с её морфизмами-функторами. В этот же раз нам предстоит разобраться, как эти самые функторы взаимодействуют между собой. И, наконец-то, познакомимся с понятием «монада».


# Естественные преобразования

## Мотивация

Для компьютерных программ необходимо построить путь вычислений как композицию различных *функций* так, чтобы на вход подавалось значение типа начальных условий, и в конце формировалось значение целевого типа. Когда мы работаем в единственной категории типов, то тут всё очевидно — любые морфизмы-функции, связанные друг с другом промежуточными типами-состояниями, композируются в цепочку посредством последовательного применения:
```scala
val f: A => B = ???
val g: B => C = ???
val h: C => D = ???

val program: A => D = (a: A) => h(g(f(a))) // val program = h compose g compose f
```

Стремление повысить (в самом широком смысле) качество программ приводит к необходимости, прокладывать пути функциональных вычислений через разные категории. В этом нам помогают функторы, которые в нашем случае сами являются функциями — они применяются к морфизмам одной категории, чтобы получить морфизмы другой. Но этого не достаточно!

Помимо преобразования между категориями морфизмов-функций, необходимо также преобразовывать и сами объекты. Проще говоря, нам нужны *функции между объектами разных категорий*. Для подкатегорий F-типов в общем случае это будут профункторы вида `type ProfFG[A, B] = F[A] => G[B]` и аналогичные им. Но с такими конструкциям не очень-то удобно работать. К профункторам мы ещё вернёмся в дальнейшем, а сейчас нам будет достаточно рассмотреть более простые функции:
```scala
infix type ~>[F[_], G[_]] = [X] => F[X] => G[X]
```

Это *полиморфные функции*, единообразно работающие для любого типа `X` — объекта категории типов. Например,
```scala
val lstToOpt: List ~> Option =
  [A] => (lstA: List[A]) => lstA.headOption

optToList(List(42)) // Some(42)
```

Оказывается, что не все такие функции одинаково полезны. Ранее мы уже рассматривали возможности функторов, переводящих морфизмы одной категории в другую, и в частности, функции `A => B` в `F[A] => F[B]`. Функторы позволяют существенно упростить программный код, и не хотелось бы упускать это преимущество. Однако, некоторые реализации преобразований вида `F ~> G` ведут себя «неестественно» по отношению к выбранным функторам, внося непредсказуемость в цепочки вычислений. Чтобы избежать таких проблем, необходимо ввести дополнительные законы, согласующие эти преобразования с функторами. Функции `F ~> G`, удовлетворяющие таким законам, имеют устоявшееся название —


## Условие естественности

Чтобы понять, как подобные преобразования могут согласоваться с функторами рассмотрим следующую категориальную диаграмму:
![[Естеств.png|Красными волнистыми стрелками обозначены естественное преобразование $\alpha$ для функторов $F$ и $G$, а также его компоненты $\alpha_a$ и $\alpha_b.$ — обычные морфизмы в категории $\mathcal{D}.$|800]]
### !! перерисовать стрелку f горизонтально

Здесь стрелки $F$ и $G$ — это два *разных* функтора, действующих между категориями $\mathcal{C}$ и $\mathcal{D}$. Функторы переводят морфизмы $f$ из исходной категории в *разные* морфизмы конечной. В категории $\mathcal{D}$ морфизмы образуют квадратный ориентированный граф, демонстрирующий наличие двух путей между $F\, a$ и $G\, b$, отличающихся тем, когда именно применяется преобразование $\alpha$ — до или после «поднятого» морфизма $f$.

Было бы здорово, если бы эта диаграмма коммутировала, то есть оба эти пути были одинаковыми. Ведь тогда, имея скомпозированный морфизм из $F\, a$ в $G\, b$, не было бы причины уточнять, как он устроен, и его поведение было бы более *предсказуемым*.

Условие коммутативности данной диаграммы накладывается на преобразование $\alpha$, которое в таком случае можно называть *естественным* по отношению к функторам $F$ и $G$.

Касательно программирования, мы чаще всего имеем дело с естественными преобразованиями между эндофункторами категории типов. Так что в коде условие естественности можно формально продемонстрировать так:
```scala
val f: A => B = ???

given   listFunctor: Functor[List  ] = [A, B] => (f: A => B) => (_: List  [A]).map(f) // встроенный метод
given optionFunctor: Functor[Option] = [A, B] => (f: A => B) => (_: Option[A]).map(f) // встроенный метод

val α: List ~> Option = [A] => (lstA: List[A]) => lstA.headOption                     // встроенный метод

val path1: List[A] => Option[B] = f.lift[Option] compose α[A]
val path2: List[A] => Option[B] = α[B] compose f.lift[List]

assert(path1(lstA) == path2(lstA)) // для любых lstA: List[A]
```

Если наше преобразование кристально чистое и универсально полиморфное, не гарантирует ли это его естественность автоматически (как это написано у Милевски)? На самом деле нет. Приведённое выше преобразование вполне себе естественно для пары функторов, представленных встроенными методами `List.map` и `Option.map`. Но если первый функтор заменить на `darkFunctorList: Functor[List]` из **предыдущей части обзора**, то естественность сразу теряется:
```scala
// если в контексте лежат darkFunctorList и обычный optionFunctor из предыдущего примера,
// тогда эти два пути уже не коммутируют!
val path1: List[String] => Option[Int] = f.lift[Option] compose α[String]
val path2: List[String] => Option[Int] = α[Int] compose f.lift[List]

val lstString = List("list", "42")

path1(lstString)  // Some(4)
path2(lstString)  // Some(2)
```

Для `darkFunctor` (в паре с `Option.map`) естественным будет такое  тривиалььное преобразование:
```scala
val β: List ~> Option = [A] => (_: List[A]) => None
```
Оно будет также естественным и для варианта с `List.map`, но пользы от него, очевидно, не много.

Естественные преобразования являются морфизмами между функторами, но с их помощью мы *не преобразуем существующие функторы*, получая новые. Но условие естественности говорит нам, что для такого преобразования обязательно должны быть заданы помимо пары категорий и два сонаправленных функтора между ними.




## Преобразования для контравариантных функторов

Выше были представлены естественные преобразования для ковариантных функторов. Оказывается, аналогичные преобразования можно построить и для контравариантных. Только условие естественности будет отличаться от введённого ранее:

### !!! рисунок!

```scala
val f: A => B = ???
val α: F ~> G = ???
//                                     было A ↓
val path1: F[A] => G[B] = f.lift[G] compose α[B] // требуется Contravariant[G]
val path2: F[A] => G[B] = α[A] compose f.lift[F] // требуется Contravariant[F]
//                          ↑ было B

assert(path1(fA) == path2(fA)) // для любых fa: F[A]
```

Если же вариантности функторов различаются, а также, если хотя бы один из них инвариантный, то для них уже не получится определить что-то похожее на естественные преобразования. Тем не менее, такие функторы можно трактовать как *профункторы*, для которых вводится понятие *диестественного* преобразования. Но об этом будет удобнее поговорить в продолжении обзора, когда мы будем рассматривать *концы профункторов*.



## Категории функторов

Полиморфные функции `F ~> G` композируются между собой и с их помощью можно построить *ещё одну* категорию подкатегорий типов (используется класс типов `Category`, **определённый в предыдущей части**):
### !!!! здесь и далее использовать для естественных преобразований символы α и β
```scala
val cat: Category[~>] = (
  identity = [F[_]] => () =>
    [A] => (fa: F[A]) => fa,
  compose  = [F[_], G[_], H[_]] => (gh: G ~> H, fg: F ~> G) =>
    [A] => (fa: F[A]) => (gh[A] compose fg[A])(fa)
)

extension [H[_], G[_]] (gh: G ~> H)(using cat: Category[~>])
  @targetName("verticalComposition")
  infix def ⋅[F[_]](fg: F ~> G): F ~> H = cat.compose(gh, fg)
```
Cимвол `⋅` для композиции естественных преобразований позаимствован из **книги МакЛейна** (также **поступил и Милевски**). Вот пример использования:
```scala
val idToList: Id   ~> List   = [A] => (a: A) => List(a)
val lstToOpt: List ~> Option = [A] => (lstA: List[A]) => lstA.headOption    
val idToOpt:  Id   ~> Option = lstToOpt ⋅ idToList

idToOpt(42) // Some(42)
```

Частным случаем `F ~> G` будут и естественные преобразования. Они также являются морфизмами в определённой только что категории, но любопытно то, что их ещё можно рассматривать в качестве морфизмов в *категории функторов*, действующих между двумя фиксированными категориями!

Действительно, рассмотрим такую диаграмму для $F,\,G,\,H:\: \mathcal{C} \rightarrow \mathcal{D}$:

![[вертикальная композиция.png|Композиция естественных преобразований.|1000]]

### !! перерисовать: α ⋅ β заменить на β ⋅ α; добавить стрелку (β ⋅ α)ₐ (изменить цвета стрелок?)

Здесь подразумевается, что прямоугольник $Fb\;Hb\;Ha\;Fa$ коммутирует — все пути от $Fa$ до $Hb$ эквивалентны. Преобразование $\alpha$, заданное для функторов $F$ и $G$, можно скомпозировать с $\beta$,  определённом для $G$ и $H$, при этом получается преобразование $\alpha \cdot \beta$ между функторами $F$ и $H$. Композиция получается ассоциативная и уважающая тождественное преобразование.

Объектами категории, основанной на такой композиции, являются все возможные функторы, но только между двумя фиксированными категориям. Например, категорию образуют все возможные *значения* эндофукнкторов `Functor[F]` для всех конструкторов типов `F[_]`. Hom-типы в таких категориях будут зависеть от значений-функторов, так что в данном обзоре мы обойдём эту тему.



## 2-категория

Структура категории категорий оказывается очень богатой. Морфизмами здесь являются функторы, которые в свою очередь образуют свою категорию с помощью естественных преобразований. Получается такая иерархия:
- категории — 0-ячейки;
- функторы — 1-ячейки (1-морфизмы);
- естественные преобразования — 2-ячейки (2-морфизмы).

Это и привело к появлению нового термина — «2-категория». Если возникнет необходимость, то технически возможна и категория естественных преобразований с новым видом морфизмов (3-ячейки) и так далее по индукции. Идея в том, что на каждом (кроме нулевого) уровне иерархии объекты являются одновременно и морфизмами в предыдущей категории. В этом смысле уровни аналогичны друг другу, что упрощает работу с ними. Таким образом в теории категорий и появляются N-категории. В прочем, в программировании обычно достаточно только второго уровня. 

«Богатство» 2-категории обусловлено *взаимодействием морфизмов* из разных уровней между собой. Например, выше мы уже видели, что 2-ячейки (естественные преобразования) могут выступать в качестве морфизмов между 0-ячейками (категориями конструкторов типов). А сейчас мы рассмотрим другие аспекты такого взаимодействия.

Пусть у нас есть две пары функторов $F,\, F': \mathcal{C} \rightarrow \mathcal{D}$ и $G,\, G': \mathcal{D} \rightarrow \mathcal{E}$,  а также пара естественных преобразований $\alpha: F \rightsquigarrow F'$ и $\beta: G \rightsquigarrow G'$. Функторы первой пары приводят в категорию $\mathcal{D}$, из которой исходят функторы второй пары. Следовательно, функторы из разных пар можно композировать между собой. Оказывается, что в таком случае можно построить такую «горизонтальную» композицию естественных преобразований $\beta \circ \alpha: G \circ F \rightsquigarrow G' \circ F'$:
![[горизонтальная композиция эскиз.png]]

Само же устройство горизонтальной композиции проще понять, если эту диаграмму развернуть так:
![[горизонтальная композиция.png|Горизонтальная композиция естественных преобразования.|1000]]

Здесь в середине мы получаем «волнистый квадрат» естественных преобразований c диагональю $\beta \circ \alpha$. Эта диагональ отражает коммутативность квадрата — оба пути от $G \circ F$ к $G' \circ F'$ эквивалентны. Запись $G\, \alpha$ обозначает естественное преобразование, получаемое действием функтора $G$ на *каждую* компоненту-функцию $\alpha_a: F\, a \rightarrow F'\, a$.

Для эндофункторов в категории типов горизонтальную композицию естественных преобразований можно записать так:
```scala
infix type ∘[G[_], F[_]] = [X] =>> G[F[X]]

extension[F1[_], F2[_]] (α: F1 ~> F2)
  @targetName("horizontalComposition")
  infix def ∘[G1[_], G2[_]: Functor](β: G1 ~> G2): (G1 ∘ F1) ~> (G2 ∘ F2) =
    [A] => (gfa: (G1 ∘ F1)[A]) => (α[A].lift[G2] compose β[F1[A]])(gfa)
```
При реализации нужен лишь один функтор. Здесь выбран «нижний» путь на квадрате, поэтому потребовался только `Functor[G2]`. Но всегда помним, что при работе с двумя естественными преобразованиями подразумевается наличие всех четырёх функторов.

Две разные композиции естественных преобразований называются «вертикальной» и «горизонтальной» от части потому, что они действуют в как бы «перпендикулярных измерениях», не влияя друг на друга. Композиции, как бинарные операции, удовлетворяют так называемому «обменному» (interchange) закону:

$$
(\alpha \cdot \beta)   \circ (\alpha' \cdot \beta') =
(\alpha \circ \alpha') \cdot (\beta   \circ \beta')
$$

Это взаимоотношение естественных преобразований можно визуализировать так:
![[взаимодействие композиций.png]]

То есть, порядок применения композиций не важен, важно лишь, чтобы сохранилось первоначальное расположение операндов относительно каждого оператора (что было «слева» должно остаться «слева» и наоборот).


## Естественный изоморфизм

Естественные преобразования являются морфизмами в категории функторов между двумя категориями. Следовательно, как и в любой другой категории, можно определить понятие изоморфизма. В нашем случае это будет *естественный изоморфизм функторов*.

Для наших любимых эндофункторов в подкатегории типов естественный изоморфизм опишем так:
```scala
infix type ≅[F[_], G[_]] = (
  right: F ~> G,
  left : G ~> F,
)
```

Закон изоморфизмов обязывает, чтобы обе вертикальные композиции этих преобразований совпадали с тождественным:
```scala
assert((left  ⋅ right)(fa) == fa) // для любого типа A и значения fa: F[A]
assert((right ⋅ left )(ga) == ga) // для любого типа A и значения ga: G[A]
```

Ране уже упоминалось, что естественные преобразования можно также трактовать как морфизмы в категории категорий. При этом пара естественных преобразований, удовлетворяющая приведённому выше закону, образует своеобразное отношение эквивалентности между категориями. Однако, в общем случае было бы опрометчиво утверждать, что такая эквивалентность будет именно изоморфизмом.

Дело в том, что понятие «изоморфизм» говорит о соответствии «форм», что в случае категории означает соответствие не только объектов, но и морфизмов между ними. В то же время естественные преобразования связывают только объекты, но ничего не говорят о морфизмах. Например, естественно изоморфные функторы могут связывать неизоморфные категории с одинаковым количеством объектов, но разным количеством морфизмов между ними.

А вот в случае эндофункторов в категории типов картина интереснее — их естественный изоморфизм автоматически влечёт за собой изоморфизм соответствующих подкатегорий! Встречные функторы *между подкатегориями* (`Hom[F, G]`, `Hom[G, F]`) строятся путём «подъёма» эндофункторами преобразований естественного изоморфизма. Эти функторы сразу получаются «взаимоуничтожающимися», что и даёт изоморфизм категорий.

В предыдущий части обзора через встречные функторы строился изоморфизм категорий для обобщённых типов
```scala
type Pair[X] = X × X
type Pow2[X] = Boolean => X  // X²
```
Покажем, что его гораздо проще продемонстрировать с помощью естественного изоморфизма соответствующих эндофункторов:
### !!! написать пример
```scala

```

В продолжении обзора нам встретятся естественные изоморфизмы и для других разновидностей функторов.

# Монады

## Мотивация

Те, кто дочитал до этого места, ~~получат бутылку шампанского!~~ наверняка уже знакомы с монадами и понимают, для чего они нужны программистам. И всё же, на всякий случай, напомню)).

Компьютерные алгоритмы исполняются на целом наборе различных физических устройств, да ещё и разнесённых пространстве. Очевидно, что для линейных алгоритмов в каждый момент времени будет работать лишь одно устройство, а остальные будут бездействовать. Поэтому очень важной задачей является снижение времени простоя вычислительных мощностей.

Одним из способов решения этой задачи является *параллельное выполнение* сразу нескольких алгоритмов. В этом случае выше шанс, что в каждый момент времени будет задействовано больше устройств-вычислителей. Однако, возникают другие сложности. Например, из-за конкуренции за ресурсы, происходят блокировки процессов вычислений, что опять же приводит к неэффективному использованию физических устройств и нежелательным задержкам.

Существуют специальные техники программирования, позволяющие добиться *асинхронного выполнения* алгоритмов, не блокирующего доступ к одним ресурсам при временной недоступности других. Эти техники отличаются в основном тем, как именно они *описываются* в выбранном языке программирования, какие требования предъявляются к их описанию.

Для статически типизированного функционального программирования, характерны такие требования к алгоритмам:
- перенос проверки корректности программы на этап компиляции, что обеспечивается максимальным использованием системы типов языка;
- проста, лаконичность и выразительность кода, обеспечивающаяся использованием фундаментальных абстракций.
- предсказуемость поведения (устойчивость к рефакторингу), которую дают «чистота» функций и другие «законы» используемых абстракций.

Всё это приводит тому, что во многих языках программирования асинхронность так или иначе (через «синтаксический сахар») реализуется посредством [контейнерных типов](https://habr.com/ru/articles/807467/) `F[_]`. В экземплярах `F[A]` инкапсулирован *контекст вычисления* целевого значения типа `A`. Например, есть специальные контейнерные типы, обеспечивающие асинхронность вычислений последовательности функций вида `A => F[B]`.

Но, кроме того, есть ещё и другие полезные контейнеры `F[_]`, например, списки и опциональные значения. Отличаются они лишь тем самым пресловутым контекстом вычисления, «эффектом». Копая глубже, можно обнаружить, что и любые другие обобщённые типы специализированы на обработке каких-то своих полезных эффектов. И оказывается, что методы комбинирования вычислений у всех таких контейнеров очень похожи.

На передний план выходит сама техника работы с *абстрактными* контейнерными типами. И прежде всего — техника *композиции вычислений*, производимых как в одном и том же контейнере, так и в разных. Ранее мы уже рассмотрели один из важных элементов этой техники — преобразования, предоставляемые эндофукнторами в категории типов. И вот теперь пришло время представить главного героя данного обзора))).


## Монада — это «разматрёшивание»

Нам нужно научится композировать «эффективные функции», например  `f: A => F[B]` и `g: B => F[C]`. Если у нас есть экземпляр `Functor[F]`, то можем попробовать сделать так:
```scala
def compose[F[_]: Funcor, A, B, C](f: A => F[B], g: B => F[C]): A => F[F[C]] =
  f andThen g.lift[F]
```
Сразу видна проблема — искомый результат «заматрёшился» в `(F ∘ F)[C]`, тогда как нам хотелось бы получить просто `F[C]`. Значит для `F[_]` требуется возможность «разматрёшивания», то есть, функция вида `(F ∘ F)[C] => F[C]` , универсально работающая для любого `C`. Очевидно, что речь идёт о естественном преобразовании
```scala
type Flatten[F[_]] = F ∘ F ~> F

def flatten[F[_]: Flatten] = summon[Flatten[F]]

def compose[F[_]: {Funcor, Flatten}, A, B, C](g: B => F[C], f: A => F[B]): A => F[C] =
  f andThen lift(g) andThen flatten
```

Преобразование `Flatten[F]` должно быть естественным для `Functor[F]`. И вроде, можно было бы поискать такой способ композиции, который не использует естественные преобразования, и не задействует функтор вообще. Но из высказанных ранее требований *предсказуемости поведения* (и многих полезных следствий из этого), любые реализации такой композиции *обязаны* быть эквивалентными представленной выше.

Теперь может показаться, что естественного преобразования `Flatten[_[_]]` должно быть достаточно для решения задачи композиции «эффективных функций». Однако, не всё так просто. Необходимость *предсказуемости композиции* накладывает дополнительные ограничения.

Например, когда мы композируем три функции `f`, `g` и `h`, то сделать это можно уже двумя разными способами: `compose(f, compose(g, h))` или `compose(compose(f, g), h)`. Меняется не порядок вычисления функций, а лишь порядок композиции. Мы (все, я уверен в этом) ожидаем, результат не должен меняться от этого порядка. И данное требование ассоциативности композиции перекладывается на преобразование `Flatten[F]`.

В теории категорий это требование соответствует такому *естественному изоморфизму* для композиции функторов $F$ (здесь уже не конструкторы типов!):
$$
F \circ (F \circ F) \cong (F \circ F) \circ F
$$
Или же, иногда избавляются от скобочек, записывая $F \circ F \circ F \equiv F^3$, и переформулируют требование через коммутируемость такой диаграммы в категории эндофункторов:
![[Pasted image 20250907195600.png|400]]
### !!! перерисовать !!

$$
F(flatten) \circ flatten= flatten \circ flatten
$$

Для эндофункторов в категории типов это правило говорит нам, что неважно, «разматрёшиваем» ли мы сперва внешнюю композицию `F ∘ F`, а потом то, что осталось, или же мы начнём внутри внешнего `F`, пользуясь его *функториальностью*. То есть, получается ещё одно правило, помимо естественности, связывающее преобразование `Flatten[F]` с эндофунктором `Functor[F]`.

Но и это ещё не всё!

Преобразование `Flatten` требуется для композиции эффективных функций вида `A => F[B]`, возвращающими «запакованные» значения. Но как же происходит эта самая «запаковка»? Пожалуй, самая простая отвечающая за это функция, будет  преобразованием:
```scala
type Pure[F[_]] = Id ~> F

def pure[F[_]: Pure] = summon[Pure[F]]
```
Преобразование очевидно обязано быть естественным для `Functor[F]`. Конечно, для конкретных контейнеров `F` встречаются «запаковывающие» функции и с другой сигнатурой, но, на самом деле, их всегда можно факторизовать, вынеся «запаковку» в вызов `pure` (возможно, это не всегда очевидно, но факт).

А теперь посмотрите на этот фрагмент кода:
```scala
val a: A         = ??? // какое-то значение
val f: A => F[B] = ??? // какая-то функция

val fb1: F[B] = f(a)
val fb2: F[B] = pure[F](a).flatMap(f)
```

Как считаете, должны ли значения `fb1` и `fb2` совпадать для любых `A`, `B`, `F[_]`, `f` и `a`? Требование предсказуемости обязывает нас обеспечить это. Нам нужно гарантировать, что такая диаграмма будет коммутативна:
```scala
f == pure andThen lift(f) andThen flatten
```
### !!! вставить диаграмму вместо формулы !!
Но обычно такое согласование преобразований `pure` и `flatten` формулируют через коммутативность диаграммы в категории эндофункторов:

![[Pasted image 20250909092233.png]]
### !!! перерисовать !!

Попытка согласовать `flatten` с каким-либо другим преобразованием, например, «распаковки» вместо «запаковки», не даст полезных результатов. Более того, даже убедительно обосновать подобное согласование будет затруднительно.

В итоге получаем, что если нам для композиции «эффективных» функций нужно предсказуемое преобразование `Flatten`, значит  не обойтись без понятия **монады**.

В программировании монада определяется не как одно, но как пара естественных преобразований для некого «значения по умолчанию» `Functor[F]`:
```scala
type Monad[F[_]] = (
  flatten: Flatten[F], // F ∘ F ~> F
  pure   : Pure[F],    // Id    ~> F
)
```
удовлетворяющая законам:
- оба преобразования естественны по отношению к конкретному значению `Functor[F]`;
- закон ассоциативности, который формально можно выразить равенством функций `lift(flatten) andThen flatten == flatten andThen flatten`;
- преобразования согласуются друг с другом (`lift(pure) andThen flatten == pure andThen flatten`).


## Методы для монады

Для удобства добавим в контекст такие преобразования:
```scala
given    pureFromMonad: [F[_]: Monad as F] => F.pure
given flattenFromMonad: [F[_]: Monad as F] => F.flatten
```
Теперь, если у нас в контексте будет монада `Monad[F]`, значит сразу будут доступны оба преобразования `pure` и `flatten`, введённые ранее.

Формально, функториальность `F[_]` требуется монаде не больше, чем любым естественным преобразованиям — лишь для удовлетворения законам. На практике же обычно функториальность и «разматрёшивание» используются вместе в таких методах:
```scala
extension [F[_]: {Functor, Monad}, A](fa: F[A]):
  def flatMap[B](afb: A => F[B]) = fa.map(afb).flatten
  
extension [F[_]: {Functor, Monad}, A, B](afb: A => F[B]):
  infix def andThenF[C](bfc: B => F[C]) => afb andThen lift[F](bfc) andThen flatten
```

ООПшно-имепративный метод `flatMap` привычен большинству scala-программистов. Более того, в различных языках программирования часто встречается специальный синтаксис, позволяющий не упоминать этот метод явно, а компоновать вычисления в привычном стиле стековых вычислений. В Haskell это do-нотация, в C# — Linq, а в Scala используются for-выражения. В разных языках встречается и альтернативный подход, вроде «[direct style](https://noelwelsh.com/posts/direct-style/)» в Scala. Многие считают такой синтаксический сахар преимуществом языка, подслащающим работу с трудноперевариваемыми монадами. Я же вижу в этом *огромный шаг назад*, так как императивно-стековый стиль плохо сочетается со стабильностью и качеством алгоритмов и влечёт к типичным ошибкам, которые регулярно просачиваются через заслоны тестирования. Проблемы заложены в саму концепцию данного стиля, их появление не возможно устранить оставаясь в его рамках.

С другой стороны, чисто ФП-шный комбинатор `andThenF` (и обратный `composeF`) знаком, возможно, не всем. А ведь, это наиболее надёжный, лаконичный и выразительный способ комбинирования эффективных функций:
```scala
val getPackage:         PackageKey     => IO[Package]
val handlePackage:      Package        => IO[HandlingResult]
val sendNotification:   HandlingResult => IO[Unit]

val greatBusinessLogic: PackageKey     => IO[Unit] =
  getPackage       andThenF
  handlePackage    andThenF
  sendNotification
```

Здесь мы сталкиваемся с ещё одними F-подкатегориями типов, называемыми категориями Клейсли. Объектами в них являются всё те же типы, а вот морфизмы — «F-эффективные» функции `A => F[B]`. Комбинатор `andThenF` играет роль оператора композиции Клейсли. В [библиотеке Cats](https://typelevel.org/cats/api/cats/syntax/Function1Syntax$Function1FlatMapOps.html#andThenF[C](g:B=%3EF[C]):A=%3EF[C]) у него также есть символический псевдоним `>=>` — изобретённый хаскелистами оператор «рыбка».

Популярные реализации класса типов `Monad[_[_]]` представлены в библиотеках [Cats](https://eed3si9n.com/herding-cats/Monad.html) и [Scalaz](https://eed3si9n.com/learning-scalaz/Monad.html). Но эти реализации оказываются существенно перегруженными различными методами, которые не относятся напрямую к понятию «монада». В частности, и там, и там `Monad` наследует класс типов `Applicaitive` — «аппликативный функтор». Мало того, что его возможности выходят за рамки монады, так ещё и самого этого термина нет в теории категорий!

Сам факт наследования монады от функтора приводит к такой нелепице, что в Scala монада считается функтором! Которым, в свою очередь, называется любой ковариантный класс с методом `Map`… но эту ошибку мы уже разбирали предыдущих частях обзора. Ладно, не будем искать виновных.

### !! в спойлер !!
>Хотя это конечно же математики.
>Вот как они это видят: «**монада — это эндофунктор**, снабженный двумя естественными преобразованиями…»
>Привыкшие во главу угла ставить бесполезную сущность, математики путают нормальных людей, отодвигая в конец наиболее важные для нового понятия аспекты — его *взаимоотношения* с другими сущностями.
>А вы знали, что с точки зрения математики, **автомобиль — это четыре колеса**, к которым присоединена рама со всеми остальными элементами?... Ведь если нет четырёх колёс, то это уже будет что-то другое. Да, «автомобиль» способен «двигаться сам», но это где ближе к концу его определения. Для математиков же гораздо важнее колёса!
>И на таких колёсах они сидят уже не первый век.


## Моноид в категории эндофункторов

Если есть два функтора $F: \mathcal{C} \rightarrow \mathcal{D}$ и $G: \mathcal{D} \rightarrow \mathcal{E}$, то их можно скомбинировать получить новый функтор $G \circ F: \mathcal{C} \rightarrow \mathcal{E}$. В общем случае, все три функтора связывают разные категории. Если же мы работаем с *эндофункторами*, то есть, действующими внутри одной и той же категории, то все они, а также всевозможные их композиции образуют свою собственную категорию с естественными преобразованиями в качестве морфизмов.

Интересно то, что операция композиции эндофункторов теперь определена *для всех объектов новой категории*. По сути, композиция является бифунктором, отображающее пару категорий эндофункторов в неё же.

Категории $\mathcal{C}$, с бифунктором $\otimes: \mathcal{C} \times \mathcal{C} \rightarrow \mathcal{C}$, являющимся ассоциативным и «уважающим» фиксированный тождественный объект $id:\mathcal{C}$, называются *моноидальными*. Это означает, что для объектов $c:\mathcal{C}$ можно определять так называемые «*моноиды*» — пары морфизмов $(c \otimes c \rightarrow c,\, id \rightarrow c)$, согласованными друг с другом и удовлетворяющими закону ассоциативности. Категориальное определение моноида является обобщением алгебраического определения, заданного только на множествах.

Категория эндофункторов, очевидно, является моноидальной, с бинарной операцией композиции $\circ$, то есть для каждого эндофунктора $F$ можно определить моноид $(F \circ F \rightsquigarrow F,\, Id \rightsquigarrow F$). Но ведь это и есть наша монада! А а её законы полностью соответствуют законам моноида. Так и получается, что
> Монада — это моноид в категории эндофункторов.

Эта фраза может сойти за определение, но важно не забывать, что под бинарной операцией подразумевается именно композиция эндофункторов, а не что-то ещё.

[Monads Categorically](https://bartoszmilewski.com/2016/12/27/monads-categorically/)


## Зоопарк монад

Среди целей данного обзора нет подробного описания применения монад. Такого материала и так хватает в интернете, а здесь представлены лишь основные идеи и некоторые отсылки для дальнейшего изучения темы. И всё же, обзор был бы не полным, если бы мы не уделили внимания разнообразию монад, используемых в программировании.

Монды строятся для эндофункторов, которые, в свою очередь, опираются на ковариантные конструкторы типов
(вспоминаем `compositeFuntor` из предыдущей части).  Функториалность и «разматрёшивание» таких контейнерных типов используют и преобразуют контекст «хранения» значения, что и определяет связанный с ними «эффект». Поэтому, «зоопарк» монад мы представим как сопоставление конструкторов типов с его эффектом.

Самые простые конструкторы типов — это алгебраические операции — сумма, произведение и экспоненциал типов. Именно так и образуются «базисные» монады в программировании. Для наглядности многопараметрические конструкторы типов записаны не в привычном, а в каррированном виде, что не меняет их сути.

| Конструктор типов             | Эффект                                                                   |
| ----------------------------- | ------------------------------------------------------------------------ |
| `Id        = [X] =>> X`       | Тождественный конструктор типов                                          |
| `Const [C] = [X] =>> C`       | Константный тип, независящий от переданного типа аргумента               |
| `Either[E] = [X] =>> E  +  X` | Альтернативный, как правило, «несчастливый» результат                    |
| `Writer[L] = [X] =>> L  ×  X` | Результат вместе с дополнительными данными («запись» в журнал изменений) |
| `Reader[R] = [X] =>> R =>  X` | «Чтение» значения из окружения, инъекция зависимостей                    |
Частным случаем эффекта альтернативного результата является просто его отсутствие. За это отвечает контейнер `Option ≅ Either[Unit] = [X] =>> 1 + X`.

Из базисных конструкторов типов собираются составные, для которых также можно вывести монады. Например, монада состояния, когда значение в контейнере преобразуется с использованием и изменением некого состояния:
 ```scala
 type State[S] = Reader[S] ∘ Writer[S] // S => S × X
 ```

Но не все составные монады собираются из ковариантных конструторов типов. Хороший контрпример — монада продолжения:
```scala
type Cont[A] = [+X] =>> (X => A) => A
```
Это функция, принимающая на вход другую функцию, продолжающую вычисления от «запакованного» значения `X`. Сам по себе данный контейнер ковариантен, но параметр в нём находится в дважды отрицательной позиции, чего нельзя добиться, композируя ковариантные же конструкторы типов. Монада продолжения очень важна в программировании и мы обсудим её подробнее в продолжении обзора.

К отдельной разновидности монад можно отнести *рекурсивные структуры данных*. Это различные деревья, и, в частности, списки. Такие контейнеры являются параметризированными [наименьшими неподвижными точками](https://habr.com/ru/articles/863324/#type_algebras) простых (нерекурсивных) конструкторов типов:
```scala
case class Fix[F[_]](val: F[Fix[F]]) // неподвижная точка конструктора типов

type OptCell[A] = [X] =>> Option[(A, X)]     // 1 + A × X
type List[A] = Fix[OptCell[A]]               // 1 + A × List[A]

type OptCell2[A] = [X] =>> Option[(A, X, X)] // 1 + A × X × X
type Tree[A] = Fix[OptCell2[A]]              // 1 + A × Tree[A] × Tree[A]
```
Рекурсивные структуры данных считают носителем эффекта *недетерминированности* — при преобразованиях контейнера меняются сразу все его элементы, так как за ранее не известно, какой (какие) из них пригодится в итоге.

Ещё более интересные монады можно получить, совмещая идеи рекурсивных и *зависимых* типов. Пожалуй, самым важным представителем таких монад будет следующая:
```scala
enum Lazy[X]:
  case Pure   [X](a: X)                           extends Lazy[X]
  case FlatMap[X, Y](y: Lazy[Y], f: y => Lazy[X]) extends Lazy[X]
```
По сути, это список преобразований, приводящий к значению целевого типа `Lazy[X]`. Но у каждого такого преобразования *тип зависит от его позиции* в этом списке. Обратите внимание на параметр `Y` — он как бы «спрятан» за родительским `Lazy[X]`, но каждом шагу он наверняка будет отличаться от `X`. Эффект, соответствующий этому контейнеру — это ленивая, «свободная» композиция вычислений.  Удобство контейнера `Lazy` в том, что вычисления накапливаются чисто, без непосредственного выполнения функций, которые могут содержать побочные эффекты.

На этом принципе основан контейнер `IO` из библиотеки Cats — вся «асинхронщина» срабатывает лишь в самом конце, «под капотом», в момент *интерпретации* ленивой композиции эффективных функций. А в библиотеке ZIO представлен одноимённый контейнер, который очень упрощённо можно себе представить, как немного усложнённый `IO`:
```scala
type IO = Lazy
type ZIO[R, E, X] = (Reader[R] ∘ Either[E] ∘ IO)[X] // R => (E + Lazy[X])
```

В Scala есть также встроенные «недомонады» `Try` и `Future`. У них также есть методы `map` и `flatMap`, но они не удовлетворяют законам монады. Основная проблема в том, что функции преобразования для них срабатывают не внутри, но снаружи контейнера, что ломает ссылочную прозрачность и предсказуемость поведения. А значения `Future` так и вовсе зависят от времени. Поэтому для надёжности приложений вместо этих контейнеров рекомендуется использовать именно ленивые `IO`/`ZIO`.

 ### !!! трансформеры


## Распределительный закон

В предыдущей части [был представлен](https://habr.com/ru/articles/933016/#anyfunctor) `compositFunctor` — он из эндофункторов `Functor[F]` и `Functor[G]` *автоматически* выводит `Functor[G ∘ F]`. Можно ли подобный трюк провернуть и для получения `Monad[G ∘ F]`? На самом деле, задача весьма нетривиальная, её исследованию и посвящён данный обзор. Сейчас же мы рассмотрим один из подходов, основанный на естественном преобразовании специального вида.

Итак, мы ищем следующую функцию
```scala
def composeMonad[F[_]: Monad, G[_]: Monad]: Monad[G ∘ F]
```
Монада представлена парой преобразований, но вывод `Pure[G ∘ F]` тривиален, так что остаётся только, используя известные `Flatten[F]` и `Flatten[G]`, найти естественное преобразование `Flatten[G ∘ F] = (G ∘ F) ∘ (G ∘ F) ~> (G ∘ F)`. Раскрыв скобки, слева мы получим конструкцию `G ∘ F ∘ G ∘ F`, которую какими-то средствами нужно свести к `G ∘ F`.

Тут есть разные пути. Например, исходное выражение сразу упрощается до целевого, если у нас будет преобразование `G ∘ F ~> Id`, или `F ∘ G ~> Id`. Тогда нам даже не потребуются ни `Flatten[F]`, ни `Flatten[G]`. Но требование наличия подобных «распаковок» само по себе достаточно неожиданное, да и оно не отвечает исходной задаче композиции монад.

### !!! Спойлер !!! Подстановка в естественных преобразованиях
> Если есть естественное преобразование `A ~> B`, то можно получить преобразование `F ∘ A ∘ G ~> F ∘ B ∘ G` (просто вспомните про функториальность `F`). То есть, мы можем *подставить* `B` вместо `A` также, как мы привыкли это делать в уравнениях обычной алгебры. Только если равенство позволило бы и `A` подставлять вместо `B`, то со стрелками `~>` такое уже не прокатит. Да и не нужно)).

В левой части мы стремимся получить `F ∘ F` и `G ∘ G`, чтобы было к чему применять `Flatten[F]` и `Flatten[G]`. Для этого надо *переставить* `F` и `G`местами в середине выражения. То есть, нам нужно преобразование
```scala
type Swap[F[_], G[_]] = F ∘ G ~> G ∘ F
```

Подставив его в `composeFlatten`, получим `(G ∘ G) ∘ (F ∘ F)`, которое уже легко сворачивается до `G ∘ F`. Тогда получаем 
```scala
def composeFlatten[
  F[_]: {Functor as liftF, Flatten as flattenF}, // liftF в данной реализаци не испльзуется
  G[_]: {Functor as liftG, Flatten as flattenG}
](
  using Swap[F, G] as swap
): Flatten[G ∘ F] =
  [A] => (gfgfa: G[F[G[F[A]]]]) =>
    (liftG(swap) andThen flattenG andThen liftG[flattenF])(gfgfa)
```
Для того, чтобы результат вычисления `composeFlatten[G ∘ F]` был основой для полноценной монады необходимо, чтобы `Swap[F, G]` удовлетворял дополнительным законам, сохраняющим ассоциативность `Flatten[G ∘ F]`. В этом случае естественное преобразование `F ∘ G ~> G ∘ F` называется [распределительным законом](https://en.wikipedia.org/wiki/Distributive_law_between_monads).

Таким образом, наличие естественного, законопослушного преобразования `Swap[F, G]` достаточно, чтобы монады композировались. Для многих конкретных `F[_]` существуют более или менее естественные реализации `Swap[F, _[_]]`, единообразно работающие для любого `G[_]`. Но *в общем* случае оказывается, что
![[Pasted image 20250919220016.png|Поверьте, Боромир шарит за теорию категорий.|800]]

Характерным примером будет композиция `Reader` и `State`. Преобразование в одну сторону достаточно простое:
```scala
type Reader[A] => R =>     A  // для простоты R фиксирован
type State [A] => S => (S, A) // для простоты S фиксирован

val swap: State ∘ Reader ~> Reader ∘ State =
  [A] => (sra: S => (S, R => A)) =>
    ((r: R) => (s: S) => sra(s).map(_ apply r))
```
А вот обратное преобразование `State ∘ Reader ~> Reader ∘ State` не получится реализовать без потерь.

С другой стороны,  для `Reader ∘ State` вполне возможно реализовать «разматрёшивани»:
```scala
given readerStateFlatten: Flatten[Reader ∘ State] =

    !!!! Реализовать !!! 

	!!! Проверить отсутвие преобразваония
```
Значит, если есть монада, то вовсе не обязательно, что для неё существует соответствующий `Swap`!
Категориально, естественное преобразования `F ∘ G ~> G ∘ F`, совместимое с этой монадной структурой, является морфизмов в *категории монад*.

Тем не менее, преобразование `Swap` имеет собственную ценность в программировании. Переставлять контейнерные типы приходится достаточно часто. Пожалуй, самыми частыми случаями являются перестановки общего контейнера эффектов `IO` с `Option`, или `List`. Например:
```scala
val urls: List[URL] = ???
def getStringFromUrl(url: URL): IO[String] = ???

val tasks: List[IO[String]] = urls.map(getStringFromUrl)

def sequense: Swap[List, IO] = ??? // List ∘ IO ~> IO ∘ List
val contents: IO[List[String]] = sequense(tasks)
```

Перестановка контейнеров, аналогичных спискам, предоставляется классом типов `Traversable[F[_]]`. Подробнее мы рассмотрим его в продолжении обзора. А сейчас разберём ещё одну перестановку, определяющую такое понятие, как


## Аппликативный функтор

Переставлять полезно не только обычные функторы, но и бифункторы. Соответствующие преобразования выглядят так:
```scala
type Swap2[Bi[_, _], F[_]] = [A, B] => Bi[F[A], F[B]] => F[Bi[A, B]]
```

В программировании чаще всего востребована перестановка с бифунктором-произведением:
```scala
infix type × = [A, B] =>> (A, B)

type Tupled[F[_]] = Swap[×, F] // [A, B] => (F[A], F[B]) => F[(A, B)]

extension [F[_]: Tupled, A, B](fafb: (F[A], F[B]))
  def tupled = summon[Tupled](fafb)
  
extension [F[_]: Tupled, A](fa: F[A])
  infix def product[B](fb) = (fa, fb).tupled
```
В некоторых библиотеках метод `product` называют `zip`. Он как застёжка-молния сшивает пару последовательностей `Seq` в последовательность пар.

Данный метод расширения не редко используется самостоятельно, но чаще его совмещают с функториальностью:
```scala
extension [F[_]: {Functor, Tupled as tupled}, A, B](fafb: (F[A], F[B]))
  def map2[C](abc: (A, B) => C): F[C] = tupled(fafb).map(abc)
  
extension [F[_]: {Functor, Tupled}, A](fa: F[A])
  def productL[B](fb) = (fa, fb).map2((l, r) => l)
  def productR[B](fb) = (fa, fb).map2((l, r) => r)
```
В библиотеке Cats представлен метод `mapN`, работающий не только для пар, но для кортежей разных размеров. Только там этот метод требует вместо двух классов типов один `Apply[F[_]]`, наследующий `Functor[F[_]]` и реализующий метод `ap`:
```scala
trait Apply[F[_]] extends Functor[F]:
  def ap[A, B](ff: F[A => B])(fa: F[A]): F[B]
```
Не сказал, бы, что на практике этот метод используется часто, но именно через него принято реализовать основные возможности, характерные для `Tupled[F[_]]`. Сам же `ap` считается ещё одним способом «преобразований в контейнере». Просто сравните чуть изменённые сигнатуры функций:
```scala
  def map    [A, B]: (  A  =>   B ) => F[A] => F[B]
  def flatMap[A, B]: (  A  => F[B]) => F[A] => F[B]
  def ap     [A, B]: (F[A  =>   B]) => F[A] => F[B]
//def apply  [A, B]: (F[A] => F[B]) => F[A] => F[B] // identity[F[A] => F[B]]
```

В то время, как `flatMap` отвечает за *последовательное* вычисление эффектов, когда следующий зависит от предыдущего, преобразование `tupled` обеспечивает *независимое* вычисление. С точки зрения математики, начало и окончание такого вычисления обоих эффектов вообще не привязано ко времени. Но в программировании все вычисления проходят через узкое место — исполнитель. Поэтому для обеспечения предсказуемости эффекты вычисляются в детерминированном порядке — сначала «левый», а потом «правый». Да, есть способы запускать вычисления и *параллельно*, но для этого используются хоть и похожие по сигнатуре, но уже другие возможности и это совсем другая история.

Следующий фрагмент кода демонстрирует различие последовательных и независимых вычислений:
```scala
flatMap vs tupled
```
В первом случае второй эффект не сработает, так как для задействованного там метода `map` не найдётся значения `A` внутри вычисленного `Option[A]`. А во втором случае второй эффект срабатывает независимо от того, завершилось ли первое вычисление «успешно».

Так как метод `Apply.ap` отвечает за комбинирование эффектов, то по тем же причинам, что и для монад, вместе с ним очень полезно иметь под рукой и преобразование «запаковки» значений `pure`. Поэтому в Cats предоставлен также такой класс типов:
```scala
trait Applicative[F[_]] extends Apply[F]:
  def pure[A](a: A): F[A]
```
Это и называется аппликативным функтором в программировании — ковариантный эндофунктор `Functor[F]`, обогащённый естественными преобразованиями `pure: Id ~> F` и `tupled: × ∘ F ~> F ∘ ×`.

Но разработчики scala-библиотек идут ещё дальше, и добавляют к `Applicative`, «разматрёшивание», называя всё это «монадой»:
```scala
trait Monad[F[_]] extends Applicative[F]:
  def flatten[A](ffa: F[F[A]]): F[A] // вообще-то, тут обычно flatMap, но это не принципиально
```

В итоге получается типичная scala-монада:
```scala
type TypicalScalaMonad[F[_]] = (
  lift:    Functor[F], // (A => B) => (F[A] => F[B])
  pure:    Pure   [F], //    Id ~> F
  flatten: Flatten[F], // F ∘ F ~> F
  tupled:  Tupled [F], // × ∘ F ~> F ∘ ×
)
```
Все остальные монадные возможности реализуются через эти три естественные преобразования и функториальность. Да, выглядит монструозно, и у многих ФП-программистов подгорает от такой архитектуры, основанной на слабооправданном наследовании, но всё же, данный подход считают наиболее оптимизированным и удобным…




## Комонада

Монада используется для «чистого разматрёшивания» посредством `flatten` эффектов, которые собираются из «эффективных» функций `A => F[B]`, напрямую или косвенно использующих «запаковку» `pure`. Разматрёшивание обычно производится на лету, сразу после комбинирования эффектов, но иногда его полезно откладывать в самый конец. В этом помогает свободная монада — реализация `Monad` для свободного контейнера `Free[F][_]` (см. мой [предыдущий обзор](https://habr.com/ru/articles/863334/)). Результатом композиции функций вида `A => Free[F][B]` будет сложная *рекурсивная структура данных*, которую в итоге нужно будет свернуть с помощью `Monad[F]`.

И хотя технически они отличаются, первый вариант с немедленным разматрёшиванием концептуально мало отличается от второго, задействующего свободные монады. В любом случае сперва вручную из элементов `A => F[B]` (`pure`) собирается чистая программа — рекурсивная структура данных со вложенными `F[_]`, которая потом *сворачивается* в единое эффективное действие. Просто во втором случае появляется промежуточное состояние — «программа-как-данные», значение рекурсивного типа — которое сворачивается потом. В первом же случае процесс свёртки как бы *уже содержит в себе* процесс порождения — он сразу потребляет новую структуру, как только она усложняется, без промежуточного хранения рекурсивной структуры.

Отсылка к рекурсии не случайна. Ведь монада является моноидом, который представляет собой *свёртку списка*, рекурсивной структуры данных. И в данном случае исходный список составляют эффективные функции `A => F[B]`.

Дуальной операцией к свёртке является *разврётка* (см. [тут](https://habr.com/ru/articles/863324/)) — порождение рекурсивной структуры, из которой в дальнейшем будет извлекаться значение. Cоответствующая конструкция, аналогичная монаде, называется **комонада**:
```scala
type Comonad[F[_]] = (
  coflatten: F ~> F ∘ F,
  extract  : F ~> Id
)

def coflatten
def extract
```
Преобразование «заматрёшивания» `coflatten` согласуется с `Functor[F]` и `extract`, и удовлетворяет закону, аналогичному ассоциативности для монад.

Комонада позволяет комбинировать «извлекающие» функции вида `F[A] => B`:

### !!! Здесь и ранее для монад вместо combine делать andThenF
```scala
def compose(f: F[A] => B, g: F[B] => C): F[A] => C =
  coflatten[F][A] andThen lift(f) andThen g
  
 
extension 
  def coFlatMap
```

Комонада реже используется в программировании. Это могут быть задачи, связанные с клеточными автоматами, или обработкой потоков данных, когда для извлечения из контейнера требуются предыдущие контексты вычислений. Но так или иначе, всё сводится именно к порождению рекурсивных структур, из которых в дальнейшем будут извлекаться данные.

### !!! Описать пример комонады
http://typelevel.org/cats/typeclasses/comonad.html

```scala
import cats.data.NonEmptyList
import cats.implicits._ // Provides syntax for type classes like Comonad

// Define a function that calculates the average of a NonEmptyList of Ints
def average(nel: NonEmptyList[Int]): Double =
  nel.toList.sum.toDouble / nel.length

// Create a NonEmptyList
val numbers: NonEmptyList[Int] = NonEmptyList.of(1, 2, 3, 4, 5)

// Use coflatMap (also known as extend) to apply the average function
// to all "sub-contexts" of the NonEmptyList.
// For a NonEmptyList, this means applying the function to all suffixes.
val slidingAverages: NonEmptyList[Double] = numbers.coflatMap(average)

// The result will be a NonEmptyList where each element is the average
// of the suffix starting at that position.
// For example, the first element is average(NonEmptyList(1,2,3,4,5)),
// the second is average(NonEmptyList(2,3,4,5)), and so on.

println(s"Original list: $numbers")
println(s"Sliding averages: $slidingAverages")

// Using extract (also known as copoint) to get the "focused" value
val firstElement: Int = numbers.extract
println(s"Extracted first element: $firstElement")
```

```scala
case class Store[S, A](pos: S, peek: S => A)
```


Примеры использования комонад можно увидеть в моём [предыдущем обзоре, где обсуждались схемы рекурсий](https://habr.com/ru/articles/863362/). И вот ещё пара интересных материалов о комонадах в Haskell:
- [Комонада, она как монада, только комонада](https://habr.com/ru/articles/283368/) — статья на Хабре.
- [Comonads](https://bartoszmilewski.com/2017/01/02/comonads/) — глава книги Бартоша Милевски.



# Дополнительная литература

Эта часть обзора опирается в основном на публикацию Бартоша Милевски [Natural Transformations](https://bartoszmilewski.com/2015/04/07/natural-transformations/).

[Monads: Programmer’s Definition](https://bartoszmilewski.com/2016/11/21/monads-programmers-definition/)
[Monads and Effects](https://bartoszmilewski.com/2016/11/30/monads-and-effects/)

[Distributive laws for relative monads](https://arxiv.org/abs/2007.12982) arxiv.org
[Distributive law between monads](https://en.wikipedia.org/wiki/Distributive_law_between_monads) wiki
[Composition and Distributive Laws](https://stringdiagram.com/2022/11/06/composition-and-distributive-laws/) надо перечитать!!!


# Применение (вместо заключения)

Функции, действующие как естественные преобразования, используются в программировании повсеместно, когда приходится иметь дело  с обобщёнными типами. Например, вычисление длины списка тоже можно трактовать как естественное преобразование в константный функтор:
```scala
val getLenght: List ~> Const[Int] = [A] => (lst: List[A]) => lst.lenght
```

Да и само создание экземпляра обобщённого типа тоже можно записать как естественное преобразование:
```scala
val pureOption: Id ~> Option = [A] => (a: A) => Some(a)
```

Для «чистой» работы с побочными эффектами нам приходится средствами функторов комбинировать «эффективные» функции, возвращающие значения «в контейнерах» `F[_]`. При этом нужно уметь «разматрёшивать» результаты таких комбинаций `F[F[A]]`. Здесь нас выручают следующие естественные преобразования:
```scala
val flattenList: List ∘ List ~> List = [A] => (lstA: List[List[A]]) => lstA.flatten
//                                                    встроенный метод ↑↑↑↑↑↑↑↑↑↑↑↑
```
Да, это самая характерная способность монады, но о них самих мы поговорим лишь в следующей части обзора.

Ну и, конечно же, вычисление всех побочных эффектов в финале — «распаковка» контейнера `F[_]` — это тоже естественное  преобразование:
```scala
val runUnsafe: IO ~> Id = ???

val myProgram: IO[Int] = ???

val exitCode: Int = runUnsafe(myProgram)
```

Ещё естественные преобразования являются ключевым инструментом в специальной технике программирования основанной на *свободных контейнерах* (монадах). Я уже [рассказывал о них в одном из предыдущих обзоров](https://habr.com/ru/articles/807495/#free)

### !! Спойлер: Напомню

Следуя примерам кода из того обзора выделю следующие моменты.

- Сперва для описания взаимосвязанных бизнес-действий строятся *обобщённые алегбраические типы данных*, вроде `enum UsersRepository[A]`. Они не предоставляют реализации этих действий — только перечисление названий и описания типов входных параметров и результата. Каждый такой контейнер и считается носителем своего (пока что абстрактного) бизнес-эффекта.
- Эти контейнеры-алгебры объединяются в общий контейнер вида `type TotalAlgebra = UsersRepository :+: SearchServcie :+: NotificationService`.
- Затем эти контейнеры «поднимаются в свободный мир» контейнера `Free: (* => *) => * => *` посредством библиотечных <u>естественных преобразований</u> вида `UsersRepository ~> Free[TotalAlgebra]`.
- В «свободном мире» уже и строится вся программа с помощью стандартных комбинаторов (`map`, `flatMap` и проч.). По сути, это лишь рекурсивная структура данных типа `Free[TotalAlgebra][Result]` — описание последовательности действий.
- Только когда уже готова «свободная» программа-как-данные, для её вычисления требуется предоставить реализацию всех бизнес-действий.
	- Сперва собираются отдельные интерпретаторы — <u>естественные преобразования</u> бизнес-алгебр в целевой контейнер эффектов вида `UsersRepository ~> IO`.
	- Затем из них, опять же, библиотечными методами собирается тотальный интерпретатор — <u>естественное преобразование</u> `TotalAlgebra ~> IO`.
- «Свободная программа», будучи рекурсивной структурой, [сворачивается](https://habr.com/ru/articles/863334/) методом `foldMap` с помощью тотального интерпретатора в итоговый результат `IO[Result].`

Для целей данного обзора более интересными оказываются другие приложения естественных преобразований, а именно
- пределы и копределы, позволяющие конструировать типы на основе описания их универсальных свойств;
- сопряжение функторов, позволяющее, в частности, проанализировать весь базис возможностей построения новых обобщённых типов, а также вывести для них
- монады, которые, в свою очередь, также часто представляют в виде пары естественных преобразований.

Именно эти приложения мы и рассмотрим в следующей части обзора.





