
![[Великий Думатель.png|Теория типов способна дать ответы даже на очень сложные вопросы. Осталось только научится правильно формулировать вопросы.]]

В предыдущей статье раскрывались некоторые базовые понятия теории типов. В этот раз мы рассмотрим обобщённые типы (*generics*) – необходимость появления такой абстракции, ключевые особенности и различные сценарии использования в программировании.

Статьи цикла:
[Теория типов](https://habr.com/ru/articles/758542/)
[Обобщённые типы]()

## Оглавление

В статье основная тема раскрывается с различных точек зрения:
- [[##К обобщённым типам|Обобщённые типы]]
- [[##Конструкторы типов|Конструкторы типов]]
- [[##Полиморфные типы|Полиморфные типы]]
- [[##Типы высокого рода|Типы высокого рода]]
- [[##Классы типов|Классы типов]]
- [[##Типы-контейнеры|Типы-контейнеры]]
- [[##Контейнерные типы как фундамент разработки|Контейнерные типы как фундамент разработки]]
- [[##Подкатегории типов (вместо заключения)|Подкатегории типов (вместо заключения)]]

## Предисловие

Однажды я делал доклад для сотрудников о технических решениях на одном из наших Scala-проектов. Там рассказывалось про применение монадических трансформеров, Tagless Final и прочих ФП-шных вкусностей. После доклада по обратной связи я получил в числе прочих и вопрос, который звучал примерно так: "а зачем вообще нужны обобщённые типы?". В тот момент я не был готов к такому вопросу и пообещал, что в следующий раз обязательно раскрою эту тему.

При подготовке ответа выяснилось, что тема обобщённых типов очень обширна. То, что подсказывал интернет, даже если бы и удовлетворило любопытство спросившего, но не убеждало меня. Обычно там говорятся общее слова, мол, обобщённые типы дают "типобезопасность", "оптимизацию" (не требуется явное приведение к типам-значений и т.п.), "переиспользуемость" и прочая "вода". Зачастую, далее приводится пример, в котором раскрываются преимущества типизированных (обобщённых) *коллекций* над нетипизированными... Однако, во многих языках программирования со строгой типизацией уже есть встроенные типизированные коллекции со своими методами, например, массивы. Выглядит так, что будто бы и нет необходимости давать программистам возможность создавать свои обобщённые типы?

На самом деле, полезными бывают, конечно же, не только типизированные списки и методы для работы с ними. Кроме того, “обобщённые типы” – это лишь одно из нескольких названий, каждое из которых выделяет определённые аспекты этой концепции. В данной статье мы рассмотрим обобщённые типы во всём их многообразии с различных точек зрения.

Так же как и предыдущая статья, эта не является подробным учебником с систематическим изложением материала. Основная задача – поверхностный обзор темы с самых разных точек зрения, с тем, чтобы заинтересовавшийся каким-либо аспектом читатель смог найти подробности самостоятельно. Далее предполагается, что читатель уже знаком с базовыми понятиями теории типов (см. например, предыдущую статью).

Для примеров кода в статье выбран язык Scala 3. Да, мало в каких популярных языках есть поддержка типов высокого рода (HKT), или контекстных абстракций, как в Scala, но многие высказанные тут утверждения относительно обобщённых типов справедливы для большинства языков программирования, поддерживающих эту абстракцию. Выразительные возможности третьей версии Scala дают возможность очень наглядно продемонстрировать некоторые интересные особенности обобщённых типов.

<anchor>generic_types</anchor>
## Обобщённые типы

<anchor>motivation</anchor>
### Мотивация

Представим, что у нас есть функция, которая может завершится ошибкой, которую в дальнейшем можно будет обработать. Это может быть поиск элемента в коллекции (искомого значения может не найтись), или запрос на web-сервер (тут может быть много разных ошибок). В привычном императивном программировании для работы с ошибками обычно применяется механизм выброса исключений и их отлов. Такой подход, как правило, недекларативен – по сигнатуре функции нет возможности понять, какие "несчастливые" исходы вычисления возможны. В любом случае, такие механизмы усложняют язык, вводя новые синтаксические конструкции, вроде `try/catch`.

В то же время, с использованием понятия *[суммы типов](https://habr.com/ru/articles/758542/#:~:text=%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%D0%B2%D1%81%D0%B5%D0%B3%D0%BE%20%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F!-,%D0%A1%D1%83%D0%BC%D0%BC%D0%B0%20%D1%82%D0%B8%D0%BF%D0%BE%D0%B2,-%D0%92%D0%BE%D0%BE%D1%80%D1%83%D0%B6%D0%B8%D0%B2%D1%88%D0%B8%D1%81%D1%8C%20%D0%BF%D0%BE%D0%BD%D1%8F%D1%82%D0%B8%D0%B5%D0%BC%20%D1%83%D0%BD%D0%B8%D0%B2%D0%B5%D1%80%D1%81%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE)* сигнатура таких функций может выглядеть следующим образом:
$$findItem: RegEx \Rightarrow ItemType + NotFound$$
$$getSmthFromWeb: Request \Rightarrow Response + Unaccessable + BadRequest + InternalError$$
При такой записи явно выделяются возможные исходы вычислений. Благодаря очевидному алгебраическому изоморфизму, описанного в предыдущей статье, для каждой такой суммы типов однозначно определяется функция, которая из значений этого типа вычисляет значения произвольного типа $X$ – механизм сопоставления с шаблонами проверяет, чтобы программист предоставил функции в тип $X$ из всех типов-слагаемых:
```scala
def foldToString(itemOrNot: ItemType | NotFound)( // ItemType + NotFound
  itemToString: ItemType => String,  // на вход приходят две функции
  notFoundResult:   Unit => String   // по количеству слагаемых типа
): String = 
  itemOrNot match     // тело функции не зависит от конкретного ItemType!
    case it: ItemType => itemToString(it)
    case _: NotFound  => notFoundResult()
```
Здесь объединение типов `ItemType | NotFound` можно считать суммой типа `ItemType` и *[единичного типа](https://habr.com/ru/articles/758542/#:~:text=%D0%B0%D0%BB%D0%B3%D0%B5%D0%B1%D1%80%D0%B0%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B3%D0%BE%20%D0%B8%D0%B7%D0%BE%D0%BC%D0%BE%D1%80%D1%84%D0%B8%D0%B7%D0%BC%D0%B0%20%D1%82%D0%B8%D0%BF%D0%BE%D0%B2%3A-,%D0%95%D0%B4%D0%B8%D0%BD%D0%B8%D1%86%D0%B0,-%D0%98%D0%BD%D0%BE%D0%B3%D0%B4%D0%B0%20%D0%B2%D0%BE%D0%B7%D0%BD%D0%B8%D0%BA%D0%B0%D0%B5%D1%82%20%D0%BD%D0%B5%D0%BE%D0%B1%D1%85%D0%BE%D0%B4%D0%B8%D0%BC%D0%BE%D1%81%D1%82%D1%8C)* `NotFound`.

И поиск элемента в коллекции, и загрузка контента из веб-сервиса являются весьма распространёнными сценариями, которые неоднократно встречаются во многих приложениях. При этом, конкретные типы `ItemType`, или `Response` будут различаться в разных местах, но *способы использования* результирующих значений типов суммы – реализации методов `fold` – не будут зависеть ни от `ItemType`, или `Response`! Более того, различные реализации метода `fold` будут отличаться только заменой типа `ItemType` (или, аналогично, `Response`) на какой-нибудь другой. Многократное дублирование этого кода для каждого такого конкретного "типа-параметра" выглядело бы весьма неудачным решением...

Помимо сценариев с суммами типов, рассмотрим и другие. Например, если какой-либо метод ищет некий контент на разных ресурсах, было бы полезно вместе с результатом вернуть и сведения об первоисточнике, откуда этот контент был получен. Тут уже поможет *[произведение типов](https://habr.com/ru/articles/758542/#:~:text=%D0%BF%D1%80%D0%BE%20%D0%B8%D0%B7%D0%BE%D0%BC%D0%BE%D1%80%D1%84%D0%B8%D0%B7%D0%BC%D1%8B%20%D1%82%D0%B8%D0%BF%D0%BE%D0%B2.-,%D0%9F%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B8%D0%BF%D0%BE%D0%B2,-%D0%95%D1%81%D0%BB%D0%B8%20%D0%BD%D0%B0%20%D0%B4%D0%B8%D0%B0%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B5)* `Content × Source`, где тип `Content` может отличаться в разных конкретных случаях, а `Source` – это фиксированный тип, например, `String`. В таких случаях способы использования такого кортежа на основе проекторов в типы `Content` и `Source` не будут зависеть от того, какой именно тип-параметр `Content` будет там использоваться.

```scala
def foldToInt(contentWithSource: Conent & Source)( // Conent × Source
  handler: Conent => Source => Int  // на вход приходит каррированная функция
): Int = 
  // обработчик handler вполне может игнориовать свой второй параметр source
  handler(contentWithSource: Conent)(contentWithSource: Source)
```

Ещё один популярный сценарий – "избавление от зависимостей". Если в неком методе требуется использование какого-то сервиса типа `Service`, то обычно его называют зависимостью и передают в самом начале, например, вместе "бизнес**о**выми" параметрами метода (или же по-ООП-шному, чуть раньше – в конструктор класса, где реализован метод). Получается, так называемый, "жадный" захват зависимости. Сигнатура вычисления примерно такая: `(Service, BusinessParam) => Result`. "Жадному" механизму противопоставляется "ленивый", когда метод не требует предоставление зависимости в самом начале, но возвращает функцию, которая на вход требует только значение `Service`, и сигнатура будет уже другая: `BusinessParam => (Service => Result)`. Получается, что *[каррирование](https://habr.com/ru/articles/758542/#:~:text=%D1%81%D0%BE%D0%BF%D0%BE%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%81%20%D1%88%D0%B0%D0%B1%D0%BB%D0%BE%D0%BD%D0%B0%D0%BC%D0%B8.-,%D0%9A%D0%B0%D1%80%D1%80%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5,-%D0%A7%D1%82%D0%BE%D0%B1%D1%8B%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D1%8C%20%D0%BD%D0%B5%D0%BA%D0%BE%D1%82%D0%BE%D1%80%D0%BE%D0%B5)* помогло избавить метод от зависимости! Таким образом, всю бизнес-логику можно описать чисто, **вынеся всю работу с зависимостями в самый конец приложения**, оставить это библиотечным методами или среде исполнения. В такого рода сценариях наблюдается знакомая закономерность – способ использования значений *[экспоненциального типа](https://habr.com/ru/articles/758542/#:~:text=%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%B8%20%D0%BA%D0%B0%D0%BA%20%D1%82%D0%B0%D0%BA%D0%BE%D0%B2%D0%BE%D0%B9!-,%D0%AD%D0%BA%D1%81%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%86%D0%B8%D0%B0%D0%BB%20%D1%82%D0%B8%D0%BF%D0%BE%D0%B2,-%D0%A0%D0%B0%D1%81%D1%81%D0%BC%D0%BE%D1%82%D1%80%D0%B8%D0%BC%20%D1%81%D1%83%D0%BC%D0%BC%D1%83%20%D0%B4%D0%B2%D1%83%D1%85)* `Service => Result` не зависит от типа `Result`, он является параметром метода:
```scala
def foldToResult(
  resultByService: Service => Result)( // Resultˢᵉʳᵛⁱᶜᵉ
  service: Service                     // на вход приходит сервис
): Result = 
  resultByService(service)             // что такое Result - не важно!
```

Можно привести и другие аналогичные сценарии, в которых конкретизация некоторых типов (вроде `Result`, `Content`, `Response`, `ItemType`) не нужна – в разных вариантах это могут быть самые разные типы, но *паттерн* остаётся тем же самым! Было бы весьма расточительно многократно копипастить такие функции, отличающиеся лишь своей сигнатурой, но имеющие одинаковую реализацию.

Для решения такой проблемы необходима новая абстракция - *обобщённые методы*.

<anchor>generic_mehtods</anchor>
### Обобщённые методы

Идея простая – достаточно описать единственную обобщённую функцию, которая будет описывать все варианты сценария с различными конкретными типами, передаваемыми ей как параметры. [В Scala](https://docs.scala-lang.org/ru/tour/polymorphic-methods.html) параметры-типы передаются не в круглых скобках, как обычные аргументы, а в квадратных. Перепишем методы `fold`, объявленные в предыдущем примере, в обобщённой форме:
```scala
def foldToString[ItemType](itemOrNot: ItemType | NotFound)( // ItemType + NotFound
  itemToString: ItemType => String,  // на вход приходят две функции
  notFoundResult:   Unit => String   // по количеству слагаемых типа
): String = ???                      // реализация такая же, как и раньше

def foldToInt[Conent](contentWithSource: Conent & Source)( // Conent × Source
  handler: Conent => Source => Int  // на вход приходит каррированная функция
): Int = ???                        // реализация такая же, как и раньше

def foldToResult[Result](resultByService: Service => Result)( // Resultˢᵉʳᵛⁱᶜᵉ
  service: Service                  // на вход приходит сервис
): Result = ???                     // реализация такая же, как и раньше
```
Использовать их можно так:
```scala
val doubleOrNot: Double | NotFound = 4.2
val str = foldToString[Double](doubleOrNot)(d => s"double: $d", _ => "no double found")
//                     ↑↑↑↑↑↑ - тип-параметр указан явно (но это не обязательно)

val intOrNot: Int | NotFound = 42
val str = foldToString(intOrNot)(i => s"int: $i", _ => "no int found")
//                   ↑↑ - зачастую, тип-параметр компилятор и сам может вывести
```
Тут обобщённый метод `foldToString`, определённый единообразно **для любого** конкретного типа `ItemType`, используется со значениями разных типов: `Double` и `Int`. Причём во втором случае тип не указан явно – компилятор сам определяет его по типу первого параметра метода.

Телом обобщённых методов являются выражения, в которых используемые там термы могут быть любого, не известного заранее типа. Такие типы участвуют в выражении *свободно* – они могут меняться в зависимости от контекста использования этого выражения. Метод же образуется путём *связывания* всех свободных параметров выражения с параметрами, которые нужно передать в метод (замыкания сейчас не рассматриваем). В случае обобщённых методов некоторыми из таких параметров будут типы.

В типах аргументов представленных выше обобщённых методов `ItemType | NotFound`, `Conent & Source`, `Service => Result` упоминаются *неопределённые* типы-параметры `ItemType`, `Conent` и `Result`. То есть, параметризация методов типами отразилась прежде всего на типах их аргументов и результата.

Часто бывает полезно параметризировать типом не один метод, а целую группу. ООП-шные языки программирования, в том числе и Scala, предлагают собирать группу методов в классы. И в нашем же случае это будут уже *обобщённые классы*.

<anchor>generic_classes</anchor>
### Обобщённые классы

Типы-параметры [обобщённых классов в Scala](https://docs.scala-lang.org/ru/tour/generic-classes.html) указываются в квадратных скобках сразу после имени класса.:
```scala
case class ContentAndSource[Content](content: Content, source: String)

trait ContentHandler[Content, Result] {
  def handleContent(contentAndSource: ContentAndSource[Content]): Result
}
```

Чтобы создать экземпляр обобщённого класса, помимо значений-параметров конструктора, нужно конкретизировать и типы-параметры:
```scala
case class MyContent(test: String) // будем подставлять его как тип-параметр

val contentHandler = new ContentHandler[MyContent, String] {
  def handleContent(contentAndSource: ContentAndSource[Content]) =
	  s"Из источника '${contentAndSource.source}' получено содержимое: ${contentAndSource.content.text}"
	  //                                    используем проектор конкретного класса MyContent.text ↑↑↑↑
}

val myContentAndSource = ContentAndSource(MyContent("text"), "hardcoded")
//                                      ↑↑ необязательно указывать тип - он будет выведен автоматически

val str = contentHnadler.handleContent(myContentAndSource) // String
// "Из источника 'hardcoded' получено содержимое: text"
```

Практически о всех ФП-шных Scala-библиотеках обобщённые типы представлены именно как обобщённые классы (и трейты). Это обусловлено, в частности, полезностью разграничения контекстов – определённые через классы, *типы считаются разными*, даже если реализованы они одинаково. Это значит, что применимые к ним наборы функций не будут пересекаться. В то же время, с рассматриваемыми в следующей главе псевдонимами λ-выражений типов ситуация обратная – типы сравниваются по формулировке, а не по названию, значит, могут быть (потенциально нежелательные) коллизии между наборами функций, предоставляемыми для этих типов разными библиотеками. Избежать таких нежелательных коллизий возможно и ФП-шными средствами Scala, но, проще и привычнее использовать классы.

Говоря об обобщённых классах Scala стоит упомянуть такую особенность JVM, как “[стирание типов](https://squidarth.com/scala/types/2019/01/11/type-erasure-scala.html)”. Дело в том, в JVM экземпляры обобщённых классов не хранят информацию о типе-параметре. При компиляции такого кода
```scala
def checkType[A](xs: List[A]) = xs match
  case _: List[String]  => "Список строк"
  case _                => "Что-то ещё"
```
будет выведено предупреждение
```
the type test for List[String] cannot be checked at runtime because its type arguments can't be determined from List[A]
```
Этот код всегда будет сворачивать на первую ветку, независимо от типа-параметра: при передаче в функцию `List(4, 2)` она всё равно вернёт `"Список строк"`. Дело в том, что механизм сопоставления с шаблонами проверяет типы значений не на этапе компиляции, а во время выполнения. Для этого он пытается вытащить через *отражения* информацию о классе, конструктором которого было создано это значение, и сравнить её с шаблоном типа. Но так как там нет упоминания конкретного типа-параметра, код хоть и скомпилируется, но будет работать не так, как можно было бы ожидать. Такую “фишку” JVM всегда стоит иметь ввиду при работе с обобщёнными классами, а любые проверки типов стоит стараться выносить на этап компиляции.

Рассмотрим также понятие “*[обобщённые алгебраические типы данных](https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D0%BE%D0%B1%D1%89%D1%91%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BB%D0%B3%D0%B5%D0%B1%D1%80%D0%B0%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D1%82%D0%B8%D0%BF_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)*“ (generalized algebraic data type, GADT). Термин, появившийся изначально в среде хаскелистов относится к типам, представимым в виде сумм других типов. В терминологии ООП сами классы описывают типы произведения своих членов (полей и методов, суть значений функционального типа), а суммы типов определяются через наследование – тип суперкласса является суммой типов подклассов (желательно, но не обязательно, чтобы наследование было ограничено “[запечатыванием](https://docs.scala-lang.org/ru/tour/pattern-matching.html#%D0%B7%D0%B0%D0%BF%D0%B5%D1%87%D0%B0%D1%82%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5-%D1%82%D0%B8%D0%BF%D1%8B)” и “[финализацией](https://www.scala-lang.org/files/archive/spec/2.11/05-classes-and-objects.html#:~:text=A%20final%20class%20may%20not,generally%20redundant%20for%20them%2C%20too.)”):
```scala
sealed trait CalcResult[R] // CalcResult[R] ≅ String + R × Rᶜᵃˡᶜᴼᵖᵗⁱᴼⁿˢ
final case class Error(msg: String)    extends CalcResult[Nothing]
final case class Successful[R](res: R) extends CalcResult[R]:
  def recalcWithOptions(options: CalcOptions): R = ??? // (CalcOptions => R) ≡ Rᶜᵃˡᶜᴼᵖᵗⁱᴼⁿˢ
```
Здесь запечатанный трейт `CalcResult[_]` определяет обобщённый алгебраический тип данных, представляющий сумму типов, связанных с финальными классами-наследниками `Error` и `Successful[_]`. Далее же мы рассмотрим более ФП-ориентированные способы определения подобных типов.

<anchor>type_constructors</anchor>
## Конструкторы типов

Термин "конструкторы типов" буквально отражает идею возможности построения новых типов из существующих. Единожды описав такой конструктор (или используя встроенные) можно создавать новые типы, подставляя разные известные типы в этот конструктор. Термин отражает функциональную природу обобщённых типов – это, по сути, отображения из типов в тип (а не из значений в значения, как обычные функции).

Любая функция строится вокруг некоторого выражения, которое становится её телом. Поэтому в первою очередь рассмотрим, какие выражения над типами можно использовать в языке Scala.

<anchor>type_operations</anchor>
### Встроенные операции над типами в Scala

В Scala 3 есть такие конструкции для построения новых типов из существующих:
- просто тип `A` – случай настолько тривиальный, что легко упустить его полезность,
- кортеж `(A, B, C)` – суть тип-произведение,
- объединение типов `A | B` – если типы разные, то это аналогично их сумме,
- пересечение `A & B` – если типы разные, то это аналогично их произведению,
- "вызов" другого конструктора типов, например,
	- `A => B` – тут используется псевдоним для `Function[A, B]`,
	- `A Either B` – синоним для `Either[A, B]`,
	- `Option[A]`, `Map[K, V]`,
	- `MySupperClass[A, B, C]` – конечно, можно вызывать и конструкторы типов, связанных с классами (или трейтами), не определёнными в стандартной библиотеке Scala.
- [сопоставление с шаблонами для типов](https://docs.scala-lang.org/scala3/reference/new-types/match-types.html).

> Механизм сопоставления с образцом для типов сочетает в себе несколько разных аспектов: специальный полиморфизм, зависимые типы, деконструкция дерева выражений. Только первый пункт имеет прямое отношение к обобщённым типам и он будет рассмотрен далее. Два оставшихся аспекта выходят далеко за рамки темы этой статьи, поэтому и механизм сопоставления с образцом здесь не будет рассматриваться.

Комбинируя эти конструкции можно определять типы произвольной сложности:
```scala
type Action  = NoAction | ((Service1 & Service2) => MyIO[(SingleResult Either List[AltResult], Log)])
//             ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑
//                       Вот такое кучерявое выражение получилось. Конечно, можно и длиннее 😄
```

<anchor>type_functions</anchor>
### Функции над типами

Идентификаторы, которые используются в выражении, могут относится как к известным в текущем контексте конструкциями, так быть неопределёнными, *свободными* переменными. Чтобы иметь возможность вычислить выражение, можно построить функцию, *связать все свободные переменные* выражения с параметрами, которые требуется передать при вызове этой функции.

С этой точки зрения удобно рассматривать и **обобщённые типы – это функции, отображающие из одного или нескольких типов в тип**. Аналогия обобщённых типов Scala с обычными функциями нагляднее прослеживается в объявлениях _псевдонимов типов_ с помощью ключевого слова `type`:
```scala
type Union[A, B]          = A | B                     // объединение типов
type OrErrorAndContext[X] = Union[(X, String), Error] // "вызывается функция" (конструктор типов) Union
```
Действительно, похоже на определения обычных функций, только "тип" аргументов и результата нигде не указывается. У них у всех одинаковый "тип" – это тип!😀

В Scala 3 также есть возможность использовать литералы обобщённых типов – λ-выражения типов:
```scala
type    WithContext = [A] =>> (A, String) // псевдоним типа, опеределённый через λ-выражение 
type IntWithContext = WithContext[Int]    // "вызвали функцию" WithContext с аргументом Int и получили (Int, String)
```
Опять же, синтаксис похож на обычные λ-выражения.

Для обобщённых типов, принимающих ровно два аргумента, возможна инфиксная запись, которая иногда бывает полезна, а иногда – не очень:
```scala
// если такой код компилируется, значит использованы эквивалентные типы по обе стороны =:= 
summon[(Either[String, Int]) =:= (String Either Int)]     // близко к естественному языку "строка или целое число"
//      ↑↑↑↑↑↑ обычная запись            ↑↑↑↑↑↑ инфиксная запись 
summon[(Function[String, Int]) =:= (String Function Int)] // а с таким типом инфиксная запись читается хуже
```
С другой стороны, Scala позволяет объявлять идентификаторы, состоящие из специальных символов, что может повысить читаемость:
```scala
type =>[A, B] = Function[A, B] // такой псевдоним уже есть в стандартной библиотеке
type  ×[A, B] =         (A, B) // новый псевдоним для типа произведения

// используем псевдонимы из спец-сиволов в инфиксной форме:
val func: Int => String = _.toString
val pair: Int ×  String = (5, "пять")
```

Важно отметить, что с помощью ключевого слова `type` объявляются не сами типы, а *псевдонимы выражений* типов. Т.е. это некие [синтаксические деревья](https://ru.wikipedia.org/wiki/%D0%90%D0%B1%D1%81%D1%82%D1%80%D0%B0%D0%BA%D1%82%D0%BD%D0%BE%D0%B5_%D1%81%D0%B8%D0%BD%D1%82%D0%B0%D0%BA%D1%81%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE), которые можно нарастить, например, в другом определении псевдонима типа, или же преобразовать с помощью упомянутого ранее механизма сопоставления с шаблонами типов. Эти выражения вычисляются в процессе типизации конкретных термов (например, переменных). С помощью различных построений псевдонимов типов можно получить схожие деревья выражения, дающие в итоге одинаковые типы, что не всегда может быть желанным результатом. Семантически различимые новые типы в Scala можно ввести только описав новые классы (трейты, объекты), либо используя [литеральные типы](https://scala-lang.org/files/archive/spec/2.13/03-types.html#literal-types). Работа с синтаксическими деревьями выходит за рамки данной статьи.

Каждый тип характеризуется набором функций-стрелок, связывающих одни типы с другими. Обобщённые типы позволяют связывать между собой любые такие наборы стрелок с помощью функций, определяемых телом обобщённого типа (комбинации сумм, произведений, экспоненциалов и т.п.):
![[обобщённое встраивание диаграмм.png|Обобщённый тип F[_] связывает с помощью проекторов произведения типов фиксированный тип B с типом, который может быть подставлен в тело F вместо A.]]


<anchor>generic_recursion</anchor>
### Обобщённые рекурсивные типы

Особого внимания заслуживает возможность объявлять типы рекурсивно, когда в теле выражения используется идентификатор объявляемого типа. 

В Scala рекурсивные типы зачастую описываются в ООП-стиле, например,
```scala
sealed trait List[A]
case object Nil                                  extends List[Nothing] // почему Nothing - будет рассказано далее
final case class Cons[A](head: A, tail: List[A]) extends List[A]

val myList: List[Int] = Cons(1, Cons(2, Cons(3, Cons(2, Cons(1, Nil))))) // 1, 2, 3, 2, 1
```
Рекурсивность `List` с первого взгляда, возможно, незаметна. Она спрятана за наследованием классов (`extends`). Соответствующие объявленным классам типы можно записать так:
$$\begin{align} 
List[A] &= Nil + Cons[A],\\
Cons[A] &= A \times List[A],\\
Nil &\cong 1.\\
\end{align}$$
Если подставить два последних выражения в первое, то получается равенство, в котором рекурсия видна явно:
$$List[A] \cong 1 + A \times List[A].$$
(Если вместо $A$ подставить тип $Nothing \cong 0$, то можно убедиться, что $List[Nothing] \cong 1 \cong Nil$.)
Таким образом, список – это либо пустой список, либо элемент (голова) и другой список (хвост).

Просуммируем такой список:
```scala
def sum(list: List[Int]): Int = list match
  case Nil              => 0
  case Cons(head, tail) => head + sum(tail) // тут рекурсия!
```
Прослеживается очевидная закономерность – для рекурсивных типов нужны рекурсивные методы!

Пользуясь только суммой и произведением типов с помощью рекурсии можно построить любые древовидные структуры, например,
```scala
sealed trait NonEmptyTree[A]
final case class Leaf[A](value: A) extends NonEmptyTree[A]
final case class Node[A](left: NonEmptyTree[A], right: NonEmptyTree[A]) extends NonEmptyTree[A]
```
Трейту `NonEmptyTree` соответствует такой тип:
$$NonEmptyTree[A] \cong A + NonEmptyTree[A] \times NonEmptyTree[A].$$

Объявить рекурсивный тип в актуальной версии Scala без привлечения ООП несколько затруднительно. Например, такая конструкция не скомпилируется:
```scala
type List[A] = Unit + (A, List[A]) // illegal cyclic type reference...
```
Компилятор ~~пытается~~ даже не пытается развернуть выражение типа, спрятанного за псевдонимом, а, определив бесконечную рекурсию, сразу сообщает об ошибке. Выглядит как недоработка компилятора, так как [есть обходной путь](https://contributors.scala-lang.org/t/unintuitive-meaning-of-some-recursive-type-aliases/5776/2) с использованием механизма сопоставления с шаблонами на уровне типов – там типы вычисляются "лениво" и подобная рекурсия считается вполне легальной.

Такие обобщённые древовидные типы иногда называются [абстрактными типами данных](https://ru.wikipedia.org/wiki/%D0%90%D0%B1%D1%81%D1%82%D1%80%D0%B0%D0%BA%D1%82%D0%BD%D1%8B%D0%B9_%D1%82%D0%B8%D0%BF_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85) (неизменяемыми). Они описывают коллекции определённой структуры, которые могут "хранить" элементы любого типа. В частности, обычный список является вырожденной разновидностью дерева.

Нетривиальность концепции рекурсивных типов можно ощутить, если для их построения задействовать экспоненциал типов (типы функций). Например, давайте посмотрим на два таких симметричных типа:
```scala
case class SelfModifyingHandler[A](f: A      => SelfModifyingHandler[A])
case class Wtf[A]                 (f: Wtf[A] => A)
```
Попробуйте самостоятельно создать значения этих типов и придумать сценарии их использования (названия толсто намекают...). Результатами предлагаю поделиться в комментариях.

Тема рекурсивных типов и рекурсии в целом настолько богата, что хотелось бы раскрыть её в отдельной статье. В ней хотелось бы рассказать о таких вкусностях, как
- ограничения на рекурсию ("что не так с `Wtf`");
- хвостовая рекурсия, трамплины;
- ряд Тейлора и корни многочленов для обобщённых рекурсивных типов ;
- производные от обобщённых рекурсивных типов;
- комбинаторы неподвижной точки;
- схемы рекурсии (ката-, ана- и прочие морфизмы).
Очень надеюсь, что найдётся возможность подготовить и такой обзор.

<anchor>polymorphic_types</anchor>
## Полиморфные типы

<anchor>polymorphism_kinds</anchor>
### Разновидности полиморфизма

В интернете можно встретить различные определения полиморфизма, но вряд ли какое-либо из них можно считать “общепринятым”. Например, определение полиморфизма в [Википедии](https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D0%BB%D0%B8%D0%BC%D0%BE%D1%80%D1%84%D0%B8%D0%B7%D0%BC_(%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)) немного отличается от аналогичного в [Wikipedia](https://en.wikipedia.org/wiki/Polymorphism_(computer_science)). Там указаны разные источники, но в качестве первоисточника приводится одна статья 1967 года “*Fundamental Concepts in Programming Languages*” Кристофера Стрейчи, [переизданная в 2000м](https://web.archive.org/web/20170812012310/http://www.itu.dk/courses/BPRD/E2009/fundamental-1967.pdf). Однако, и там нет *определения* полиморфизма как такового. Пожалуй, в наиболее общем виде это понятие можно сформулировать так:
> *Полиморфизм в программировании* – это свойство фрагмента кода определять разное поведение в зависимости от типов термов, использованных в нём.
> Такой код ссылается на набор различных алгоритмов, “форм”, ассоциированных с конкретными типами, то есть, является *полиморфным по типу* (слово “*πολυμορφή*“ можно перевести с греческого как “множество форм”).

В той статье Стрейчи говорится о двух основных разновидностях полиморфизма – *универсальном (параметрическом)* и *специальном (ad-hoc)*. Разные исследовали приводят множество разновидностей полиморфизма и, если собрать их все вместе, то наберётся не меньше дюжины. Но, так или иначе, любой такой подвид можно притянуть за уши либо к универсальному, либо к специальному (или же к их сочетаниям). В этой статье помимо прочих будут рассмотрены такие разновидности, как полиморфизм видов и полиморфизм вселенных – они являются обобщениями приведённого определения, в которых расширено понятие “тип”.

Отдельно стоит сказать про полиморфизм в языках с динамической типизацией. Как правило, в таких языках явно типизированными остаются лишь некоторые функции, например, встроенные арифметические операции, но типы любых значений проверяются только в момент попытки их использования в типизированных функциях. Вне контекста выполнения типы термов просто не определены, что не позволяет проводить проверку корректности программы до её выполнения. Но теория типов используются в программировании прежде всего для обеспечения корректности алгоритма в целом, *для любых начальных условий*. Не смотря на то, что при динамической типизации код является фактически полиморфным (описывает работу со значениями разных типов), далее динамический полиморфизм не будет рассматриваться в этой статье.

Классификация Стрейчи канонична, но при нынешнем засилье объектно-ориентированной парадигмы у многих программистов уже могло сложиться представление о полиморфизме, как лишь об одном из "столпов ООП". Например, перейдя по [одной](https://blog.skillfactory.ru/glossary/polimorfizm/) из первых ссылок в результатах интернет-поиска по слову "полиморфизм", можно прочесть:
> Полиморфизм (polymorphism) — это понятие из объектно-ориентированного программирования, которое позволяет разным сущностям выполнять одни и те же действия. При этом неважно, как эти сущности устроены внутри и чем они различаются.

Не уверен, что имеет смысл упрекать авторов подобных цитат в том, что они вводят в заблуждение читателя. Популярность какого-либо мнения превалирует в массовом сознании над его качеством, корректностью. ООП-шный полиморфизм рассмотрим подробнее чуть позднее, а сейчас предлагаю сосредоточиться на наиболее востребованном универсальном полиморфизме.


<anchor>universal_polymorphism</anchor>
### Универсальный полиморфизм и λ-исчисление

Само понятие универсального (параметрического) полиморфизма появилось в процессе развития **$\lambda$-исчисления**. Эта формальная система создавалось как фундаментальный язык, алгоритмы на котором можно было бы проверить на логическую корректность.

Изначально $\lambda$-исчисление [было безтипововым](https://ru.wikipedia.org/wiki/%D0%9B%D1%8F%D0%BC%D0%B1%D0%B4%D0%B0-%D0%B8%D1%81%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5). Там было введено понятие $\lambda$-абстракции с правилом аппликации (применения):
$$\begin{align}
f&:=\lambda x.\;2\cdot x+1;\\
f\;5\equiv f(5)&=2\cdot 5+1=11.
\end{align} $$

Затем появилось [просто-типизированная система](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%81%D1%82%D0%BE_%D1%82%D0%B8%D0%BF%D0%B8%D0%B7%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BB%D1%8F%D0%BC%D0%B1%D0%B4%D0%B0-%D0%B8%D1%81%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5) $\lambda^{\rightarrow}$.  Здесь у каждой переменной, которая связывается квантором $\lambda$ фиксируется метка-тип (явно – в стиле Чёрча): 
$$\begin{align}
\lambda x:A.M;\\
\end{align} $$
Тип самого $\lambda$-выражения однозначно (по возможности) определяется по типу аргумента $x$ и телу выражения $M$.

Обозначение $\lambda^{\rightarrow}$ (стрелочка) связано с тем, что простые типы можно выразить как функции высшего порядка [в кодировке Чёрча](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%A7%D1%91%D1%80%D1%87%D0%B0), т.е. :
```scala
type Zero     = Any        // 𝟘 ≅ Any
type One      = Any => Any // 𝟙 ≅ Any => Any
type Bool     = Any => One // 𝟚 ≅ Any => Any => Any
type Natural  = One => One // ℕ ≅ (Any => Any) => Any => Any - натуральные числа по Пеано
```
Например:
```scala
val trueWay: Bool = happyWay => unhappyWay => happyWay
val one  : Natural = suc => z =>         suc(z)
val three: Natural = suc => z => suc(suc(suc(z)))

// вычисления
def calc(cond: Bool, trueNum: Natural, falseNum: Natural) =
  cond(trueNum)(falseNum).asInstanceOf[Natural]
val result = calc(trueWay, three, one)

// натуральное число к Int32
def natToInt(num: Natural): Int =
  num(_.asInstanceOf[Int] + 1)(0).asInstanceOf[Int]  
natToInt(result) // 3
```

Дальнейшее развитие – полиморфная система $\lambda2$ ([система F](https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B0_F)). Теперь в $\lambda$-выражении стало возможно связывать не только обычные переменные, но и типовые:
$$\begin{align}
\lambda A:\star.\; \lambda x:A.\; M
\end{align} $$
Здесь $\star$ – это "тип типа". Система $\lambda2$ позволяет определять *обобщённые функции*. В изоморфизме Карри-Ховарда типы соответствуют утверждениям, свойствам объектов, следовательно, система $\lambda2$ ассоциируется с [логикой второго порядка](https://en.wikipedia.org/wiki/Second-order_logic) (отсюда и двойка в названии).

В Scala 3 добавлен специальный синтаксис для типов обобщённых функций:
```scala
// обычный метод
def foldWithContext[A, B](aWithContext: WithContext[A])(folder: (A, String) => B)
  = folder(aWithContext._1, aWithContext._2)

// переменная обобщённого функционального типа
val foldWithContextVal
  : [A, B] => WithContext[A] => ((A, String) => B) => B // тип      ∀A,B. WithContext[A] → ((A, String) → B) → B
  = foldWithContext                                     // значение λA,B. λa:WithContext[A]. λf:(A,String) → B. f(a._1, a._2)
```
Значения такого типа можно передавать в методы, в которых будет решаться, какие типы подставить для этих обобщённых функций.

Наконец ещё более продвинутая [система](https://en.wikipedia.org/wiki/Lambda_cube#%CE%BB%CF%89) $\lambda\omega$  (или $F\omega$) позволяет уже *строить типы*, используя $\lambda$-выражения
$$
List = \lambda A.\; \forall B.\; (A\rightarrow B\rightarrow B)\rightarrow B\rightarrow B;\\
$$
Именно тут появляются полноценные полиморфные (обобщённые) типы:
```scala
type List = [A] =>> [B] => (A => B => B) => B => B

def emptyList[A]: List[A] =
  [B] => (aggr: A => B => B) => (start: B) => start

def append[A](lst: List[A], a: A): List[A] =
  [B] => (aggr: A => B => B) => (start: B) => aggr(a)(lst(aggr)(start))

def fold[A, B](lst: List[A], start: B, aggr: A => B => B): B = lst(aggr)(start)

val myList = append(append(append(emptyList[Int], 1), 2), 3) // [1, 2, 3] 
fold(myList, "список:", i => _ + " " + i)                    // "список: 1 2 3"
```
Сами выражения, на которых строятся полиморфные типы, определяют способы их использования – связанные с ними полиморфные функции. Компилятор сам может (его можно научить) строить такие функции для полиморфных типов, что может значительно сократить количество кода, которого приходится писать программистам вручную.

Ввиду того, что в таких полиморфных типах параметр связывается через квантор "*для любого*", параметрический полиморфизм называется *универсальным*. Полиморфизм, где используется дуальный квантор "*существует*", называется *специальным* – он будет рассмотрен позже.


<anchor>subtyping_polymorphism</anchor>
### Полиморфизм подтипов

Рассмотрим теперь полиморфизм подтипов на конкретном примере:
```scala
trait Person { val name: String def sayHello(): String }
case class Français(name: String) extends Person { def sayHello() = "Bon après-midi!" }
case class Русский (name: String) extends Person { def sayHello() = "Здаров!" }

def dialogWith(person: Person) =
  println("Привет, " + person.name)
  println(person.sayHello())              // 1

val Француа = Français("François")
val Василий = Русский("Вася")
dialogWith(Француа); dialogWith(Василий)  // 2
```
Возможно, у кого-то возникнет впечатление, что полиморфизм тут проявляется в строке с пометкой `1`, ведь именно там конкретное поведение метода `sayHello` определяется "типом значения", спрятанного за переменной `person`. Но проблема в том, что, по определению, типы привязываются к термам языка (литералам, переменным, выражениям), а не к значениям, размещённым в памяти компьютера. 

Да, у значения, зачастую, есть ссылка на описание класса, конструктором которого это значение создано, и класс связан с конкретным типом, который используется *во время выполнения* при проверке возможности использования значения в тех или иных операциях. Но, как уже было сказано, основанный на этой идее динамический полиморфизм не помогает в проверке корректности алгоритма, и мы не будем его рассматривать.

В данном же примере у переменной (терма) `person` тип `Person` фиксирован в сигнатуре метода, в строчке `1` идёт однозначное обращение к методу `sayHello` трейта `Person`, следовательно, тут полиморфизма нет. То, что “под капотом” будет переадресация на метод из таблицы виртуальных методов, связанной со значением, нас не должно волновать, так как мы сейчас на более высоком уровне языка программирования рассматриваем статическую типизацию.

Но полиморфизм есть в строке с пометкой `2` – при вызовах метода, принимающих параметр типа `Person`, используются переменные других типов, `Français` и `Русский`. В этой строке срабатывает *неявное приведение* от подтипов к супертипу – именно это и определяет ООП-шный *полиморфизм подтипов*! Например, если бы с помощью `dialogWith` обрабатывалась коллекция значений типа `Person`, то полиморфным было бы добавление значений классов `Français` и `Русский` в эту коллекцию.
А
Вызов по имени метода, перегруженного в неизвестном подклассе, который определяется по значению `person` не является какой-то "ООП-шной магией", ведь методы суть значения функционального типа – по ссылке `person` можно добраться до размещённой в памяти таблицы виртуальных методов, а уже в этой таблице лежат *ссылки на методы* именно того подкласса, конструктором которого это значение было создано. Ссылки на методы можно вытащить явно, и в предыдущем примере достаточно просто переписать эти три строчки (и выкинуть классы-наследники)
```scala
case class Person(val name: String, val sayHello: Unit => String)
val Француа = Person(       "François",           ()   => "Bon après-midi!")
val Василий = Person(       "Вася",               ()   => "Здаров!")
```
и получить тот же самый результат, но уже без привлечения полиморфизма.

Следуя Википедии, полиморфизм подтипов относится к разновидности *универсального полиморфизма с ограничениями подтипизации* - об этом будет далее. Но с другой стороны, сами эти ограничения можно реализовать с помощью *специального полиморфизма*, о котором будет рассказано в разделе **Классы типов**.

<anchor>variance</anchor>
### Вариантность

Является ли список строк списком произвольных объектов? Конкретнее, можно ли передать терм типа `List[String]` в функцию, которая принимает аргумент типа `List[Any]`? Опытным путём можно убедиться, что в Scala (да и во многих других языках) это можно сделать. Но вот, наоборот, передавать терм типа `List[Any]` в функцию, принимающую `List[String]`, запрещено. Получается, что `List[String]` является подтипом `List[Any]` и, очевидно, безо всякого наследования! Попробовав с другими простыми типами, можно заметить, что конструктор типов `List` *транслирует отношения подтипизации* для своих аргументов.

Но для других типов наблюдается иная картина:
```scala
type Func[X] = X => Int // псевдоним для конструтора типов Function1

// если этот "призыв" компилируется, значит такая подтипизация корректна
summon[     String  <:<      Any]
summon[List[String] <:< List[Any]]
summon[Func[Any]    <:< Func[String]] // поменялись местами String и Any!
```
Получается, что конструктор типов `[X] =>> X => Int` обращает подтипизацию в обратную сторону! Причём, у похожего типа`[X] =>> Int => X` подтипизация вновь окажется “прямой”!

А вот если мы наивно попробуем то же самое со своим классом, у нас ничего не получится:
```scala
class Test[A](val a: A)
summon[Test[String] <:< Test[Any]]    // ошибка!
summon[Test[Any]    <:< Test[String]] // ошибка!
```

Чтобы разобраться в чём причина, достаточно [~~просто прочесть документацию~~](https://docs.scala-lang.org/ru/tour/variances.html) посмотреть на определение типов `List` и `Function` (`=>`) в стандартной библиотеке:
```scala
type List    [+A]     = scala.collection.immutable.List[A]
type Function[-A, +B] = Function1[A, B]
```
Именно значки перед параметрами конструкторов типов определяют вид *вариантности*:
- `+` означает прямую *ковариантную* трансляцию подтипизации,
- `-` – инвертированную, *контравариантную*,
- нет значка – подтипизация блокируется – *инвариантность*.
(Псевдонимы типов по-умолчанию пробрасывают вариантность своих выражений без изменений.)

В представленном выше классе `Test` параметр `A` используется двояко – и как тип аргумента конструктора (контравариантно), и как тип проектора поля `a` (ковариантно). Следовательно, полиморфный тип, связанный с этим классом, является *инвариантным*. Попытки поставить в квадратных скобках перед `A` плюс или минус приведут к ошибке компиляции вида `contravariant type A occurs in covariant position in type A of value a` ("контравариантный тип A появляется в ковариантной *позиции* типа переменной a"). О какой же позиции тут идёт речь?

На первый взгляд может показаться, что имеется ввиду позиция "относительно стрелки" `=>`:
- отрицательная позиция (знак `-`), если слева от стрелки и
- положительная позиция (знак `+`), если справа.
Но не всё так просто))). Например, вот этот тип внезапно оказывается ковариантным:
```scala
type Cont[+X] = (X => Int) => Int
summon[Cont[String] <:< Cont[Any]]
```
Параметр `X` стоит левее сразу двух стрелок – дважды отрицательная позиция превращается в положительную!

Обобщённые списки ковариантны, и это объясняет, почему тип пустого списка `Nil ≅ List[Nothing]`. Универсальным свойством нулевого типа `Nothing` (см. предыдущую статью) является наличие неявного преобразования от `Nothing` к *любому* другому типу, поэтому, вследствие ковариантности, пустой список типа `Nil` можно использовать везде, где требуется `List[A]` при *любом* `A`.

Как уже не раз упоминалось, отношение подтипизации – это просто функция от одного типа к другому (неявное преобразование). Тогда, вариантность – это то, как подобные функции преобразуются "под действием" конструкторов типов. Чуть подробнее такие возможности обобщённых типов будут раскрыты в этой статье позднее.

![[Вариантность.png|Тип вариантности полиморфного типа F[_] проявляется в том, как отношения подтипизации (функции неявных преобразований) между A и B переносятся на типы F[A] и F[B]. Синими стрелками обозначены ключевые черты функтора: ковариантного или контравариантного, в зависимости от направления красной стрелки.]]

В дополнение можно рекомендовать эту статью: [Demystifying Variance in Scala](https://scalajobs.com/blog/demystifying-variance-in-scala/).

<anchor>subtyping_bounds</anchor>
### Ограничения подтипизации

Привычный ООП-шный полиморфизм подтипов подразумевает, что в любую функцию мы можем передавать значения *любых типов*, являющихся подтипами к типу соответствующего параметра функции.

```scala
trait SupperClass { val i: Int }
case class SubClass(i: Int) extends SupperClass

def someFunc(x: SupperClass) =
  x.i + 3

val sub = SubClass(5)
someFunc(sub) // полиморфизм тут
```

Это эквивалентно ситуации, как если бы функция явно декларировала, что может принимать значения *разных типов* (т.е. имеет тип-параметр, превращающий её в обобщённую), но для которых задано определённое ограничение подтипизации.

Такая система типов $F_{<:}$, в которой универсальный полиморфизм сочетается с ограничениями подтипизации, реализуется во многих популярных языках, в том числе и в Scala. Например, во фрагменте кода выше достаточно изменить сигнатуру метода `someFunc`, чтобы продемонстрировать полиморфизм явно:
```scala
def someFunc[A <: SupperClass](x: A) =
  x.i + 3 // тело функции не меняется
```
Таким образом, система $F_{<:}$ позволяет относить полиморфизм подтипов к разновидности универсального полиморфизма, дополненного ограничениями подтипизации.

Ограничения подтипизации для параметров обобщённых методов мощнее, чем полиморфизм подтипов. Рассмотрим пару примеров. Следующий фрагмент кода показывает, что полиморфизм с ограничением подтипизации позволяет без потерь *передать тип аргумента на выход функции*:
```scala
trait SupperClass { val i: Int }
case class SubClass(i: Int, s: String) extends SupperClass // в подклассе новое поле s
val sub: SubClass = SubClass(5, "string")

def extractInt1[A <: SupperClass](x: A): (A,           Int) = (x, x.i)
def extractInt2(x  : SupperClass      ): (SupperClass, Int) = (x, x.i)

// с помощью "_1" обращаемся к первому элементу кортежа 
extractInt1(sub)._1.s // "string"
extractInt2(sub)._1.s // !!! ОШИБКА !!! Компилятор не видит тут никакого s!
```
В последней строке будет ошибка компиляции, так как функция `extractInt2` ничего не знает об исходном типе переданного ей аргумента – неявное преобразование подтипизации сработало *до того*, как значение было передано в функцию.

Выше были представлены такие ограничения, когда тип-параметр должен быть чьим-то подтипом – так называемые, *верхние границы типа*. Но существует также понятие *нижней границы типа*: запись `X >: SubType` означает, что тип-параметр `X` должен быть супертипом для некого фиксированного типа `SubType`. Наглядный пример использования такого ограничения можно подсмотреть [в официальной документации Scala](https://docs.scala-lang.org/ru/tour/lower-type-bounds.html).

В ранних версиях Scala была возможность использовать, так называемые, *ограничения представления*. Запись `A <% SomeType` означала, что известно некое *неявное преобразование* от типа `A` к типу `SomeType`, то есть, возможности типа `SomeType` применимы к значениям типа `A`. Такое преобразование вовсе не обязательно завязывалось на наследовании классов, вариантности обобщённых типов (`List[String] <: List[Any]`) или встроенной подтипизации (`Short <: Int`) – могут быть использованы в том числе и пользовательские неявные преобразования:
```scala
given def intToSubClass(i: Int) // объявляем неявное преобразование Int => SubClass
  = SubClass(i, "нечто") 
def getString[A <% SubClass](a: A) = a.s

getString(5) // "нечто"
```
В Scala 3 такой синтаксис убрали, но эффектов, аналогичных использованию ограничений `<%` можно достичь с помощью классов типов – о них будет рассказано далее.

Отношения подтипизации можно ввести не только для простых типов, но и для полиморфных. Сделать это можно разными способами, но, пожалуй, самый очевидный из них - это *поточечная подтипизация*: считаем `F` подтипом `G`, если `F[X]` является подтипом `G[X]` для любого типа `X`. При подготовке статьи очень удивился, обнаружив, что такая подтипизация уже присутствует в Scala:
```scala
def headOption[F <: [X] =>> Iterable[X], A](fa: F[A]): Option[A] = fa.headOption
  
headOption(List(5))          // Some(5)
headOption(Option("строка")) // Some("строка")
headOption(Map(1.2 -> true)) // Some((1.2, true))
```
К сожалению, в актуальной на данный момент версии Scala в ограничении приходится явно указывать $\lambda$-выражение для типов, что выглядит коряво. К слову, аналогично эффекта можно добиться, написав `F[_] <: List[_]`.

Очевидно, поточечную подтипизацию по индукции можно распространить и на полиморфные *типы более высокого рода* которые будут рассмотрены далее.

Существует одна разновидность полиморфизма подтипов под названием “F-ограниченный полиморфизм“, когда подтипизация завязывается рекурсивно на определяемый тип. Рассмотрим такой пример:
```scala
trait F[U <: F[U]]
class C extends F[C]
```
Здесь трейт `F` принимает параметр `U`, ограниченный сверху `F[U]` – это и есть то самое рекурсивное “*F-ограничение*”. Конкретный класс `C` *расширяется* обобщёнными возможностями, представленными в трейте `F[C]`, то есть, задействующими всё тот же тип `C`. Собственно для этих целей и используется F-ограничения. Подробнее о них можно прочесть в статье Брюка Кайсена [F-bounded polymorphism in Scala](https://brieuckaisin.hashnode.dev/f-bounded-polymorphism-in-scala). Сценарии, в которых обычно применяются F-ограничения, также могут быть реализованы посредством специального полиморфизма.

<anchor>higher_tyeps</anchor>
## Типы высокого рода

<anchor>hkt</anchor>
### Higher Kinded Types

В математике существуют такие понятия, как
- функционал, превращающий функции в "простые" нефункциональные значения (например, интегральная свёртка),
- оператор, превращающий одни функции в другие (например, дифференцирование).
В отличие от обычных функций, такие отображения связывают не только простые множества, вроде действительных чисел, но и множества функций!

Отображения, из функций и/или в функции в информатике называются [*функциями высших порядков*](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%B2%D1%8B%D1%81%D1%88%D0%B5%D0%B3%D0%BE_%D0%BF%D0%BE%D1%80%D1%8F%D0%B4%D0%BA%D0%B0) (higher-order functions). Такие функции могут оперировать не только "простыми" функциями (первого порядка), но и такими же функциями высших порядков. При этом, "порядок" новой функции будет выше чем, у тех, которые она принимает/возвращает.

>Функция, как набор инструкций, размещённых в памяти, представляет собой обычное значение, и даже в Ассемблере можно передавать указатель на функцию в другую функцию, вызывать её по указателю, или возвращать его.  Но сам термин "функции высших порядков" вошёл в оборот, кода в популярных *высокоуровневых* языках появилась *возможность использовать функции как значения* – "[функции первого класса](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B8_%D0%BF%D0%B5%D1%80%D0%B2%D0%BE%D0%B3%D0%BE_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B0)".

В свою очередь, конструкторы типов, как уже было замечено, представляют собой функции на уровне типов – отображают одни типы в другие. Имеющиеся в системе $F2$ "простые" конструкторы типов (переводящие один простой тип в другой) в системе $F\omega$ расширяются *функциями высших порядков на типах* – **higher kinded types** (HKT).

Слово "kind" вызывает известные трудности перевода. Встречаются такие варианты:
- **кайнд** – незамысловатая транслитерация, заимствование из английского, которое не всегда считается оправданным;
- **сорт** в русском языке привычно индексируется натуральными числами, что порождает эклектику вроде "типов третьего сорта";
- **вид** типа кажется хорошим вариантом перевода, если избегать словосочетания "типы высокого вида";
- **род** привносит в предметную область не очень уместную, но ставшую уже привычной, "высокородность". 
Далее будут рассмотрены *виды* типов высокого *рода* 😜.

Рассмотрим примеры:
```scala
type Option = [A] =>> Unit | A
type Reader = [Dep] =>> [A] =>> Dep => A
type Functor = [F[_]] =>> [A, B] => (A => B) => (F[A] => F[B])
type TaglessFinalProgram = [Algebra[_[_]]] =>> [A] =>> [F[_]] => Algebra[F] => F[A]
```
Конструктор `Reader` принимает на вход тип зависимости и возвращает другой конструктор, принимающей тип результата и возвращающий тип функции. По сути, `Reader` является каррированной версией конструктора типов, принимающего два параметра. В свою очередь `Functor` принимает на вход уже конструктор типов, и возвращает простой тип полиморфной функции.

Не каждый тип может быть подставлен в эти конструкторы типов:
```scala
type FOpt = Functor[Option]
//type FReader1 = Functor[Reader]       // нельзя!
type FReader2 = Functor[Reader[Int]]
//type FInt = Functor[Int]              // нельзя!
type OptInt = Option[Int]
//type OptReader1 = Option[Reader]      // нельзя!
//type OptReader2 = Option[Reader[Int]] // нельзя!
type OptReader3 = Option[Reader[Int][String]]
type OptF = Option[Functor[Option]]
//type Reader1 = Reader[Int]            // нельзя!
type Reader2 = Reader[Int][String]
```
Полиморфные типы добавляют красок в однообразие простых типов – теперь типы не все одинаковые)). Но это приносит не только радость. Ведь даже для простых конструкторов типов вроде `Option` возникает вопрос: можно ли считать типы высокого рода, собственно, типами, если их нельзя приписать к значениям, как метки? Какой смысл может иметь запись `val opt: Option`?

Можно, конечно, пофантазировать, сказав, что подставив в значение `opt` конкретный тип, мы сможем получить новый тип, например `val intOpt: getType[Int](opt) = Some(42)`. Конечно, всё зависит от языка, и, хотя конкретно так Scala не умеет, но с помощью определённых костылей (основанных на полиморфных функциях и зависимых типах) можно добиться схожего результата, но…

Действительно, для типов высокого рода не предусмотрено использование в качестве меток термов, так что на самом деле **полиморфные типы не являются типами**! (См. также [тут](https://stackoverflow.com/questions/54620961/can-type-constructors-be-considered-as-types-in-functional-programming-languages).) Конструкторы типов называют типами скорее по аналогии с функциями высших порядков, которые все являются значениями (функции первого класса). В Scala есть синтаксис, использование которого позволяет трактовать конструкторы типов как метки, но уже не для значений, а для других типов - это будет рассмотрено при обсуждении классов типов.

Другие примеры использования типов высокого рода можно подсмотреть, например, тут:
- [Higher-kinded data in Scala](https://github.com/Michaelt293/higher-kinded-data),
- GitHub-проект [DataPrizm](https://github.com/Katrix/DataPrism) (и [статья об использовании типов высокого рода](https://bora.uib.no/bora-xmlui/bitstream/handle/11250/3073826/Generic-programming-using-Higher-Kinded-Data.pdf), в этом проекте).

<anchor>higher_logic</anchor>
### Логика высших порядков

С точки зрения изоморфизма Карри-Ховарда полиморфные типы высокого рода связаны с логикой высших порядков. Например, тип
```scala
type Product = [A, B] =>> (A, B)
```
можно прочесть как
"*Для любых типов `A` и `B` из их обитаемости следует обитаемость типа-произведения `A × B`.*"
Изоморфное этому типу утверждение в логике второго порядка будет выглядеть так:
"*Для любых высказываний `A` и `B` из их истинности следует истинность высказывания `A ∧ B`.*"

Именно наличие квантора "для любого" (или "существует") над типами/высказываниями определяет с одной стороны изоморфизма "высокородность" типа, а с другой - высший порядок логики. Связь более сложных полиморфных типов с логиками высших порядков выводится по индукции.

Предоставление реализации некоторого метода является доказательством обитаемости соответствующего функционального типа. Если компилятор не ругается на такую реализацию, то тип результата метода удалось *логически корректно* связать с типом его аргумента. С полиморфными типами (функциональными отображениями из типов в тип) ситуация совершенно аналогичная. Полиморфные типы представляют собой инструмент мощной выразительной силы, но при этом сохраняют ключевую особенность простых типов - благодаря изоморфизму Карри-Ховарда, компилятор по-прежнему может проверить логичность алгоритма до его исполнения. (Да, рекурсивные типы, упомянутые ранее, могут усложнить проверку корректности, а то и вовсе сделать её невозможной, но это отдельная история.)

<anchor>type_kind</anchor>
### Вид типа

Приведённые выше примеры демонстрируют, что типы высокого рода могут относится к разным **видам типа** (type kinds). В определениях этих типов однозначно указывается, параметры какого вида типов они принимают: `A`, `F[_]`, `Algebra[_[_]]`. Такие параметры должны быть либо простыми типами, либо другими конструкторами типов - отображениями из типов в простые типы.

Для видов типов разработана своя система обозначений. Вид простых типов обозначается звёздочкой $\star$. Вид конструкторов типов, принимающих на вход простые типы, записывается как $\star\rightarrow\star$. Все остальные виды типов строятся по индукции. В языках семейства ML (том же Haskell) функции сразу записываются в каррированном виде, это же правило относится и к конструкторам типов. В Scala использован более традиционный синтаксис, когда функция может принимать несколько параметров, разделённых запятыми – также реализуются и конструкторы типов. В итоге получаем следующую формализацию:
> *Вид типа - это либо вид простых типов ($\star$), либо отображение ($\rightarrow$) из одного вида типа (или нескольких через запятую) в другой вид типа.*

Стрелка, как оператор, обычно подразумевает правую ассоциативность, поэтому вид $\star\rightarrow(\star\rightarrow\star)$ эквивалентен виду $\star\rightarrow\star\rightarrow\star$. Таким образом, в конце каждого вида типа после стрелочки будет вид простого типа $\star$, следовательно, любой вид типа описывает конструкторы простых, “истинных” типов!

В этой таблице демонстрируется соответствие видов типа и параметров конструкторов типа:

| Вид типа                                                    | Параметр конструкторов типа этого вида                                                | Пример типа этого вида                                |
| ----------------------------------------------------------- | ------------------------------------------------------------------------- | ------------------------------------- |
| $\star$                                                     | `A`                                                                       | `Int`                                 |
| $\star\rightarrow\star$                                     | `F[_]`                                                                    | `Option`                              |
| $\star\rightarrow\star\rightarrow\star$                     | `F[_][_]`, но Scala плохо понимает типы каррированного вида(( | `Reader` из примера выше              |
| $(\star\rightarrow\star)\rightarrow\star$                   | `Alg[_[_]]`                                                                 | `Functor`                             |
| $((\star\rightarrow\star)\rightarrow\star)\rightarrow\star$ | `Prog[_[_[_]]]`                                                           | `TaglessFinalProgram` из примера выше | 
| $(\star,\star)\rightarrow\star$                             | `M[_, _]`                                                                 | `Map`                                 |
Ещё раз стоит обратить внимание на вид типа `Functor` из примера выше. В Scala конструкции вроде `[A, B] => ...` обозначают *простой тип* полиморфной функции, поэтому в итоге для `Functor` и получается вид $(\star\rightarrow\star)\rightarrow\star$.

В [Scala REPL](https://docs.scala-lang.org/ru/scala3/book/taste-repl.html) (интерпретатор командной строки) есть возможность подсмотреть вид типа, воспользовавшись командой `:kind` (с опциональным параметром `-v`). Например, для типа `Functor` из библиотеки [Cats](https://typelevel.org/cats/) вывод команды будет такой: 
```
scala> :kind -v cats.Functor
cats.Functor's kind is X[F[A]]
(* -> *) -> *
This is a type constructor that takes type constructor(s): a higher-kinded type.
```
К сожалению, команда `:kind` работает только с определёнными ранее обобщёнными классами (трейтами). Псевдонимы типов или λ-выражения эта команда не воспринимает.

При подготовке статьи была идея реализовать что-то вроде *типа вида типа* 😀:
```scala
type Kind
type GetKind[A <: AnyKind] // <: Kind   // (про AnyKind будет дальше)
def instantinate[K <: Kind]: Kind = ??? // конструтор значения типа вида типа
def toString(kind: Kind): String = ???  // строка вида "(⋆ → ⋆) → ⋆"
```
Сам тип `Kind` можно было бы определить как-то так:
```scala
opaque type ⋆ = Unit                    // вид простых типов
type -->[K1, K2] = (K1, K2)             // просто некая стрелка
type Kind = ⋆ | (Kind --> Kind)         // тип вида типа (без множественных параметров)
```
Но, такой код, к сожалению, не компилируется. Есть различные обходные манёвры для этого препятствия, но, так или иначе, все они завели в тупик. [Чего-то похожего](https://github.com/lampepfl/dotty/blob/main/tests/pos/anykind.scala) можно добиться, предоставив неявные экземпляры некоторого класса типов, но такой метод работает *только для конечного числа* видов типа.  Если у кого-то из читателей получилось победить компилятор Scala и реализовать эту задумку для всех видов типов, пожалуйста, поделитесь рецептом в комментариях.

<anchor>type_calculus</anchor>
### Вычисления на уровне типов

Итак, у нас есть возможность строить алгебраические выражения из типов, а также строить функции из типов в тип. И этих возможностей достаточно, чтобы заняться программированием на уровне типов!

Рассмотрим такие определения типов:
```scala
type ⊥        = Unit      // тип "нулевого вида"
type ⊤        = [A] =>> A // тип "единичного вида"

type IfFalse  = [False] =>> [True] =>> False
type IfTrue   = [False] =>> [True] =>> True

type Zero     = [Z] =>> [Succ[_]] =>> Z
type One      = [Z] =>> [Succ[_]] =>> Succ[Z]
type Two      = [Z] =>> [Succ[_]] =>> Succ[Succ[Z]]
type Three    = [Z] =>> [Succ[_]] =>> Succ[Succ[Succ[Z]]]
```
Использование представленных типов сопряжено с трудностями, связанными с отсутствием в Scala должной поддержки каррированных типов-параметров, но всё же возможно. Принадлежность представленных выше типов одному "типу" определяется *видом этих типов*:
$$
\begin{split}
Zero    &:&&\;\; \star\\
One     &:&&\;\; \star\rightarrow\star\\
Bool    &:&&\;\; \star\rightarrow\star\rightarrow\star\hspace{2cm} (\text{тут и ниже подразумевается каррирование})\\
Natural &:&&\;\; (\star\rightarrow\star)\rightarrow\star\rightarrow\star\\
Pair    &:&&\;\; (\star\rightarrow\star\rightarrow\star)\rightarrow\star\\
\end{split}
$$
Не сложно заметить, что представленные тут виды типов коррелируют с типами в кодировке Чёрча, представленными **ранее**, при выведении типов в изначально бестиповой системе. И это логично, так как вид типа является, по сути, типом типа (а $\star$ – это изначально “безтиповый” вид)!

Трактовка таких конструкторов типов достаточно очевидна. Например, типы натуральных чисел соответствуют итерациям применения некого конструктора типов `Succ` к типу `Z`.  Но также эти типы можно интерпретировать, как *фантомные*, не предусматривающие использование в качестве меток термов, но которые можно передавать в другие конструкторы типов. С помощью таких фантомных типов можно, например, построить тип списка фиксированной на этапе компиляции длины – при конкатенации длина нового списка будет также рассчитываться на этапе компиляции. И, в принципе, алгоритмы на уровне типов используются именно для каких-либо вычислений на этапе компиляции. Эта идея хорошо раскрывается в habr-статье [Решение задачи о 8 ферзях на трёх уровнях Scala — программа, типы, метапрограмма](https://habr.com/ru/articles/725462/).

Плюсом программирования на типах является его *чистота* с точки зрения функционального программирования. Нет никаких эффектов – вообще никакого “нечистого” взаимодействия с окружением. Но это же является и минусом, ведь каждый такой алгоритм может решить лишь единственную задачу, условия которой известны до компиляции. Во многих программах есть как минимум одна такая сверхзадача – построение корректной композиции функций, благодаря которой в процессе работы приложения обычные значения будут передаваться между объектами окружения (клавиатура, монитор, память, БД, web-службы и т.п.) согласно техническому заданию. Так вот с такой сверхзадачей программирование на типах справляется вполне успешно.

Другие примеры программирования на типах можно найти тут:
-  [Typelevel Church Numerals in Scala 3](https://raasahsan.com/posts/typelevel-church-numerals-in-scala-3/) – там также определены типы сложения и умножения для таких "натуральных чисел".
- habr-статья [Scala: структура данных в пространстве типов — множество](https://habr.com/ru/articles/776798/);
- [Type-Level Programming in Scala](https://apocalisp.wordpress.com/2010/06/08/type-level-programming-in-scala/) из журнала [Apocalisp](https://apocalisp.wordpress.com/);
- цикл статей *Type-Level Programming in Scala* с ресурса [Rock the JVM Blog](https://blog.rockthejvm.com/) ([Part I](https://blog.rockthejvm.com/type-level-programming-scala-3/), [Part II](https://blog.rockthejvm.com/type-level-programming-part-2/), [Part III](https://blog.rockthejvm.com/type-level-programming-part-3/))
- цикл статей *Meta-Programming with Scala*: ([Part I](https://michid.wordpress.com/2008/04/18/meta-programming-with-scala-part-i-addition/), [Part II](https://michid.wordpress.com/2008/07/30/meta-programming-with-scala-part-ii-multiplication/), [Part III](https://michid.wordpress.com/2008/08/27/meta-programming-with-scala-part-iii-partial-function-application/));
- презентация [Type-Level Computations in Scala](https://scala-slick.org/talks/scalaio2014/Type-Level_Computations.pdf);
- pdf-статья Луки Карделли [Typeful Programming](http://www.lucacardelli.name/Papers/TypefulProg.pdf);
- реализации SKI на уровне типов:
	- статья [Scala type level encoding of the SKI calculus](https://michid.wordpress.com/2010/01/29/scala-type-level-encoding-of-the-ski-calculus/) из весьма познавательного [блога Мичида](https://michid.wordpress.com/);
	- GitHub-проект [Type level lambda calculus in Scala](https://github.com/tarao/lambda-scala).

<anchor>kind_polymorphism</anchor>
### Полиморфизм видов

Есть ли какие-нибудь операции, которые можно было бы сформулировать единообразно для полиморфных типов *разного* вида? Конечно, есть – это и отношения конструкторов типов (в частности, эквивалентность), и банальный проброс типа произвольного вида (аналог функции `identity` на значениях), какие-либо модификации вида типа (например, усложнение). Вариантов множество.

Такого рода операции над конструкторами типов должны быть [полиморфными по виду](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%BF%D0%BE%D0%BB%D0%B8%D0%BC%D0%BE%D1%80%D1%84%D0%B8%D0%B7%D0%BC#%D0%9F%D0%BE%D0%BB%D0%B8%D0%BC%D0%BE%D1%80%D1%84%D0%B8%D0%B7%D0%BC_%D1%80%D0%BE%D0%B4%D0%BE%D0%B2) Полиморфизм видов (kind polimorphism) также называют *полиморфизм высокого рода* (higher kinded polymorpism), подразумевая, что в этом случае универсальная квантификация идёт по *типам типов*. Язык Haskell позволяет работать с видами типов также как и с обычными типами, соответственно, для них также реализован и [полиморфизм видов](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/poly_kinds.html).  В Scala 3 же для этих целей [предусмотрен специальный синтаксис](https://docs.scala-lang.org/scala3/reference/other-new-features/kind-polymorphism.html), похожий на ограничение подтипизации для параметров обобщённых типов: `<: AnyKind`:
```scala
type SomeTypeConstructor[A <: AnyKind]
```
Из за такой записи может показаться, что `AnyKind` является ещё одним типом, но это не так. На самом деле это просто метка для компилятора, допускающая вольную трактовку вида типа-параметра.

Практическое применение полиморфизма видов в Scala ограничено реализацией поддержки `AnyKind`. На упомянутой ранее странице официальной документации Scala до сих пор есть строка:
>(todo: insert good concise example)

В интернете же можно найти такие примеры использования `AnyKind`:
- внутри Scala, например, [при работе с макросами](https://github.com/lampepfl/dotty/blob/5bb6f0ddf6eca05dfb2d224be6ccddecb07700c9/library/src/scala/quoted/Quotes.scala#L1812);
- [проверка концепции](https://github.com/lampepfl/dotty/blob/main/tests/pos/anykind.scala) полиморфизма видов, по уже упоминавшейся ранее ссылке;
- две любопытных реализации моноида, полиморфного по видам типа: [gist s5bug](https://gist.github.com/s5bug/dc9b765ee2ba11cab3d7bcfc2a0a44dc), [gist mandubian](https://gist.github.com/mandubian/dfd670f7740f47a1a2a7b662f828aac6);
- ещё один [пример](https://github.com/sellout/category-parametric-talk/blob/master/scala-io.org#anykind) определения монады, через моноид, полиморфный по видам;
- [Implement SKI combinator calculus](https://codegolf.stackexchange.com/a/210062) с использованием `AnyKind`;
- Вопрос на StackOverflow [Scala 3. Kind polymorphism and AnyKind type - any code example?](https://stackoverflow.com/questions/75494119/scala-3-kind-polymorphism-and-anykind-type-any-code-example)
- Слайды презентации [Adding kind-polymorphism to the Scala programming language](https://milessabin.com/talks/2018/11/08/codemesh-ldn-2018/)
- Обсуждение предложения по доработке [Proposal to add kind polymorphism to the language](https://contributors.scala-lang.org/t/proposal-to-add-kind-polymorphism-to-the-language/2958)

Если у читателей есть хорошие примеры, пожалуйста, приведите их в комментариях.

<anchor>type_universes</anchor>
### Вселенные типов

Итак, виды типов – это типы типов высокого рода. Но “типы типов” не могут сами быть типами – это привело бы к так называемому *парадоксу Жирара*.
> Парадокс Жирара в теории типов – это аналог [парадокса Рассела](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%B4%D0%BE%D0%BA%D1%81_%D0%A0%D0%B0%D1%81%D1%81%D0%B5%D0%BB%D0%B0), демонстрирующего, что [совокупность всех множеств](https://ru.wikipedia.org/wiki/%D0%A3%D0%BD%D0%B8%D0%B2%D0%B5%D1%80%D1%81%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B5_%D0%BC%D0%BD%D0%BE%D0%B6%D0%B5%D1%81%D1%82%D0%B2%D0%BE) сама не может быть множеством. В интернете сложно найти более-менее популярную литературу по парадоксу Жирара, разве что pdf-статья Хёркенса [A Simplification of Girard’s Paradox](https://www.cs.cmu.edu/~kw/scans/hurkens95tlca.pdf).

Наличие логических парадоксов может скомпрометировать всю теорию типов, делая её ненадёжной. Во избежание этого вводится концепция *вселенных типов*: простые типы и типы высокого рода относятся к “обычной” вселенной типов $U_0$, в то время как все виды типов принадлежат уже к другой вселенной $U_1$. В Haskell реализована работа с типами из обеих вселенных и считается, что этого достаточно для задач языка.

Тем не менее, аналогию между видами типов и самими типами можно продолжить, введя конструкторы видов типа – виды высокого рода! Соответственно, для классификации таких полиморфных видов типов потребуется ввести некие *виды видов типов*, которые, во избежание всё того же парадокса Жирара, будут относится уже к следующей вселенной типов $U_2$. Таким образом по индукции можем получить бесконечную последовательность вселенных типов: $U_0,\;U_1,\;U_2,\;\ldots$

Любопытно, что *все вселенные устроены одинаково* (без учёта концепции вложенности, рассмотренной далее). Например, ранее был представлен вид типов, аналогичный типу натуральных чисел, и таким же способом можно описать обитателей и более далёких вселенных. Интересной является возможность написания кода, который бы одинаково работал для типов из любой вселенной. Такая возможность уже реализована в некоторых языках ([Agda](https://agda.readthedocs.io/en/latest/language/universe-levels.html), [Coq](https://coq.inria.fr/refman/addendum/universe-polymorphism.html)) и называется она “**полиморфизм вселенных**“.

Можно также заметить, что вселенная видов типов похожа на вселенную типов примерно также, как типы похожи на значения – выше было продемонстрированно, как вычисления можно производить на уровне типов почти также, как это можно делать и со значениями. Это даёт основания для включения в последовательность вселенных типов ещё одну – *вселенную значений* с не очень удачным индексом $U_{-1}$. Она является выделенной, начальной, в том смысле, что “типы” этой вселенной уже больше ничего не индексируют, вселенных с меньшими индексами просто не существует (но так ли это?🤔).

Пожалуй, самое интересное в концепции вселенных типов то, что между ними можно путешествовать! Для этого достаточно построить функцию от типа из одной вселенной к типу другой. И хотя в Sacla для взаимодействия с далёкими вселенными есть только упомянутый ранее `Anykind`, но всё же доступны червоточины между $U_{-1}$ и $U_0$, то бишь между значениями и типами.

Отображение из $U_0$ в $U_{-1}$ уже встречались в этой статье – это обобщённые функции. Действительно, достаточно передать туда типы-параметры, и обобщённая функция становится обычным значением функционального типа:
```scala
val doubleA                  // червоточина  
  : [A] => A      => (A, A)  // из вселенной типов в значение-функцию  
  = [A] => (a: A) => (a, a)  // техника сейчас не важна  
  
val doubleInt                // сюда положим значение  
  : Int => (Int, Int)        // простого типа  
  = doubleA[Int]             // вжух!
```

[В Scala существуют](https://docs.scala-lang.org/ru/scala3/book/types-dependent-function.html) также возможности и обратного путешествия – от значений в типы! О, это очень сильное колдунство под названием **зависимые типы**. Посмотрим на такой код:
```scala
trait IHaveAType { type Type; val v: Type }     // трейт содержит членом абстрактный тип!
val valWithInt:    IHaveAType =                 // червоточина 1
  new IHaveAType { type Type = Int;    val v = 42 }
val valWithString: IHaveAType =                 // червоточина 2
  new IHaveAType { type Type = String; val v = "вселенная" }
  
val doubleDep // функция, ТИП результата которой зависит от ЗНАЧЕНИЯ первого аргумента  
  : (carier: IHaveAType) => (carier.Type, carier.Type)       // вжух туда!
  = (carier: IHaveAType) => doubleA[carier.Type](carier.v)   // вжух обратно!

val stringsPair: (String, String) = doubleDep(valWithString) // ("вселенная", "вселенная")
val intsPair:    (Int, Int)       = doubleDep(valWithInt)    // (42, 42)
//               ↑↑↑↑↑↑↑↑↑↑ указание иных типов приведёт к ошибке компиляции!
//               а всё потому, что тип valWithInt хитрее чем кажется: IHaveAType { type Type = Int }
```
Тут в строке `вжух туда!` выражение `carier.Type` телепортирует из $U_{-1}$ в $U_0$, а в следующей строке возвращаемся обратно уже знакомым способом. [Зависимые типы](https://www.youtube.com/watch?v=63syJfNoDPI) не редко используется в Scala – по большей части в популярных библиотеках, но можно встретить и в продуктовом коде. Это очень интересная, но очень объёмная тема, рассмотрение которой стоит отложить на другой раз.

Сама функция, переводящая из одной вселенной в другую, относится ко вселенной с максимальным индексом, и в случае описанных выше путешествий, это была вселенная типов $U_0$. Но чаще считают, что такие функции работают с типами одной и той же вселенной, однако действует простое, но важное правило: вселенные со старшими индексами *включают все вселенные* с меньшими: $U_{-1}:U_{0}:U_{1}:U_{2}:\ldots$ Таким образуется *кумулятивная иерархия вселенных*. А вот мультивселенной $U_{\infty}$, включающей в себя все остальные вселенные попросту не существует (это всё выдумки киношников!) из-за всё того же парадокса Жирара.

Ещё почитать про вселенные типов можно тут:
- [пара](https://cs.stackexchange.com/questions/13285/universes-in-dependent-type-theory) [ответов](https://math.stackexchange.com/questions/4637779/unnested-universes-in-type-theory) на вопросы о кумулятивных вселенных;
- [статья](https://ncatlab.org/nlab/show/type+universe) на nLab;
- pdf-статьи:
	- [On Universes in Type Theory](http://www2.math.uu.se/~palmgren/universe.pdf),
	- [Type Theory with Explicit Universe Polymorphism](https://arxiv.org/pdf/2212.03284.pdf),	- 
	- [Notes on Universes in Type Theory](https://ncatlab.org/ufias2012/files/LuoUniverse.pdf).

Путешествие к далёким вселенным таит множество опасностей для неподготовленного приключенца. Давайте пока вернёмся в нашу вселенную, к привычным классам и типам.

<anchor>type_classes</anchor>
## Классы типов

<anchor>no_type_of_class</anchor>
### Это не типы классов!

Если “типы классов” – это, буквально, типы, ассоциированные с классами, то перестановка слов обладает совершенно иной семантикой. Давайте разберёмся, какой смысл имеет словосочетание “классы типов”.

Рассмотрим такой код:
```scala
case class Context[A](meta: String)  
def enrichWithMeta[A](a: A, context: Context[A]) = (a, context.meta)  
//                (1)   (?)            (2)  (3)  

val contextForInt = Context[Int]("целые числа")  
enrichWithMeta[Int](42, contextForInt) // (42, "целые числа")
```
Нет, никакой особой магии тут искать не нужно, сейчас важна лишь определённая трактовка элементов этого кода. Обобщённый метод `enrichWithMeta` параметризирован неким типом `A`, и в качестве одного из аргументов принимает значение `Context[A]`, то есть, обобщённого типа, параметризированного тем же типом-параметром `A`. Ключевой вопрос тут – какие типы можно использовать при вызове метода `enrichWithMeta`? С первого взгляда кажется очевидным, что универсальный полиморфизм позволяет использовать *любой тип* в качестве параметра.

Однако, если рассматривать аргумент `context: Context[A]` как *вспомогательный* (в любом смысле!), то правильным может стать и такой ответ: при вызове метода `enrichWithMeta` можно использовать не любые типы, а только те `SomeType`, для которых *существует значение типа* `Context[SomeType]` (с тем, чтобы его передать в метод, как аргумент). Если же значение типа `Context[SomeType]` не доступно, то вызвать метод `enrichWithMeta` не получится.

Таким образом, само требование предоставления значения обобщённого типа, конкретизированного типом-параметром метода, накладывает ограничения на этот тип-параметр. Причём, важен не *значение* аргумента метода, а только его *тип*, связанные с ним возможности-функции. Более того, так как тип-параметр может быть любой, то за ограничение отвечает не простой тип `Context[A]`, а конструктор типов `Context`. Во фрагменте кода выше ключевые моменты отмечены цифрами: тип-параметр метода (1), тип аргумента метода, полученный применением конструктора типа (2) к типу-параметру метода (3). Про это будет сказано далее, но пока предлагаю задуматься, можно ли считать схожим ограничением тип первого аргумента (?)?

В математике ограничение, позволяющее классифицировать некую совокупность на “подходящее” сущности или “неподходящее”, называется *классом*. Привычные для программистов классы фильтруют значения – они являются *классами значений*. В то же время, использованные представленным выше способом обобщённые типы классифицируют другие типы, следовательно, их можно трактовать как **классы типов**.

В хабр-статье [Что такое класс типов?](https://habr.com/ru/articles/771896/) говориться, что для точного определения класса типов могут потребоваться некие *законы* – дополнительные ограничения на те возможности, что предоставляет класс типов. Законы (как правило, некие отношения, в частности, равенства) нужны для *математических абстракций*, которые формулируются в виде классов типов, но для того, чтобы просто обобщённый тип считать классом типов никакие законы не требуются. В той статье как раз ставится открытый вопрос, можно ли некий обобщённый класс называть классом типов?

Тут важно заметить, что классы типов и обобщённые типы – это *разные понятия*. Существуют так называемые *фантомные обобщённые типы*, для которых вообще нельзя сконструировать значение, следовательно, их не получится использовать в качестве классов типов. Прочие *обобщённые типы можно трактовать как описания классов типов*, но всё же это подразумевает *определённый способ использования* таких типов.

Выше приведён пример очень простого обобщённого класса `Context[A]`, предоставляющего единственный проектор типа `String`, и совсем не использующий параметр `A`. Ближе к концу раздела будут рассмотренные более полезные примеры классов типов, предоставляющие различные функции, задействующие тип-параметр. Пример `Context[A]` призван подчеркнуть, что классы типов могут быть описаны *любыми* обитаемыми обобщёнными типами.

Также далее будет рассказано, что именно предлагает Scala для работы с классами типов, но сперва стоит обратить внимание на использованную формулировку ограничения на тип-параметр `enrichWithMeta[A]`: *существуют такие типы `A`, для которых доступно значение `Context[A]`*. Такого рода логические утверждения при переносе в теорию типов соответствуют понятию “*экзистенциальные типы*”.

<anchor>existential_types</anchor>
### Экзистенциальные типы

Иногда нам просто не интересен конкретный тип, используемый в выражении типа. Например, можно представить такую функцию:
```scala
def getLenght(l: List[_]) = l.lenght
//               ↑↑↑↑↑↑↑ вполне себе коррекное выражение в Scala
```
Тип элементов списка не важен, если нам требуется только его длинна. Однако, само *существование* такого типа предполагается, так как список элементов без типа попросту не возможен. Scala также позволяет указывать ограничения для неизвестного типа параметра, впрочем, ввиду ковариантности `List`, выражение `l: List[_ <: SomeType]` можно переписать проще: `l: List[SomeType]`. Но случается, что столь широкое ограничение на параметр конструктора типов оказывается не тем, что нужно. Давайте лучше попробуем подойти к экзистенциальным типам от универсальных, воспользовавшись их *дуальностью*.

Рассмотрим выражение `A Either String`, определяющее сумму типов `A` и `String`. Здесь `A` – свободная переменная, и для использования выражения эту переменную нужно связать каким-либо квантором. Ранее для мы пользовались только квантором $\lambda$ (или аналогичным $\forall$), который можно читать как "для любого":
```scala
//   OrStringA = λA.     A   +    String
type OrStringA = [A] =>> A Either String
```
"Для любого типа `A` есть тип-сумма `A` и `String`".

Дуальным к утверждению "для любого `A`" является утверждение "существует такой `A`, что". В математике, в том числе и в теории типов, для таких случаев используется квантор $\exists$ (exists). Если этот квантор использовать с выражением из примера выше, то получится такой тип: $OrStringE = \exists A.\; A + String$.

>Дуальность кванторов $\forall$ и $\exists$ в логике проявляется по отношению к отрицанию:
>- утверждение *“**не** для любого `A` верно `B`”* равносильно *“существует такое `A`, что **не** верно `B`”*;
>- утверждение  *“**не** существует такого `A`, что верно `B`”* равносильно *“для любого `A` **не** верно `B`”*.

Что может быть значением такого типа? При трактовке типов как утверждений (изоморфизм Карри-Ховарда) доказательством корректности определения типа является его обитаемость, *свидетельством* которой является предоставление любого "значения" этого типа. Для полиморфного типа $OrStringA = \lambda A.\;A + String$ его "реализацией" является определение `[A] =>> A Either String`, отражающее "функциональный" характер квантора $\lambda$ ("для любого") – при *использовании* этого типа мы сами должны *предоставить* простой тип, чтобы подстановкой его вместо `A` был построен новый тип. В случае типа $OrStringE$ некий простой тип *уже должен быть предоставлен* в качестве свидетельства его существования, и вместе с ним значение выражения типа, в котором свободный параметр заменён на "тот самый" тип (в нашем случае, `Int Either String`. То есть, в итоге получаем такой [экзистенциальный тип](https://en.wikipedia.org/wiki/Type_system#Existential_types):
```scala
trait OrStringE:
  type A
  val value: A Either String
```

Если универсальный тип `OrStringA` представлял собой **функцию** от *любого* типа `A` в тип значения, представленный выражением, то экзистенциальный тип `OrStringE` описывает **пару** из *некого* типа `A` и значения типа, представленного выражением. Ввиду этого, иногда используют альтернативное обозначение для экзистенциальных типов в виде пары $\{\exists A,\; ExprA\}$, где `ExprA` – некое выражение, например, `A Either Strig`. Первый элемент такой пары называют *скрытым типом-свидетелем*, в том смысле, что его наличие нужно лишь чтобы “засвидетельствовать” существование подходящего типа. При использовании значений экзистенциального типа зачатую требуется обрабатывать не только само значение выражения, но и как-то учесть тип-свидетель.

Трейт `OrStringE` демонстрирует механизм *зависимых ([от пути](https://www.baeldung.com/scala/path-dependent-types)) типов* в Scala. Такие типы реализуют механизм позднего связывания, когда тип значения проверяется *динамически*, во время выполнения с использованием мета-информации, на которую ссылается это значение. На этапе компиляции не получится выяснить, какого типа будет выражение `(a: OrStringE).value`.

Но, учитывая, что элемент экзистенциального типа представляет собой *пару* из типа и значения, то можно применить кодирование по Чёрчу, допускающее статическую типизацию (раннее связывание). В случае обычного произведения типов кодирование Чёрча даёт $PairAB = \forall X.\; (A \rightarrow B \rightarrow X) \rightarrow X$. Соответственно, для экзистенциального типа, построенного на выражении `Expr`, получается такое альтернативное представление:
$$\{\exists X,\; Expr\} = \forall Y.\; (\forall X.\; Expr \rightarrow Y) \rightarrow Y$$
На Scala можно таким образом записать универсальный и экзистенциальный типы, построенные на одном и том же выражении `Expr`:
```scala
type Universal   = [Expr[_]] =>> [X] =>> Expr[X] // Universal[F] ≡ F
type Existential = [Expr[_]] =>> [Y] => ([X] => Expr[X] => Y) => Y

type ListU = [A] =>> Universal[List][A] // List[A]
type ListE = Existential[List] // [Y] => ([X] => List[X] => Y) => Y

val listUInt: ListU[Int] = List(4, 2)
val listEInt: ListE = // {*Int, List[Int]}: {∃X, List[X]}
	[Y] => (continuation: [X] => List[X] => Y) => continuation(listUInt)

listEInt[String]([X] => (_: List[X]).mkString("; ")) // "4; 2"
```
В коде Scala хорошо видны все “стрелочки” кодировки Чёрча. В таком представлении экзистенциальный тип представляет собой *полиморфную функцию*, принимающую в качестве аргумента другую полиморфную функцию-продолжение `continuation`. В определении значения `listEInt` этого типа в функцию-продолжение передаётся значение `listUInt` простого типа, полученного подстановкой в тип-выражение `List[_]` конкретного типа `Int`. Факт существования “подходящего” типа `Int` спрятан в использовании переменной `listUInt: List[Int]`, в то время как результирующий тип переменной `listEInt` уже не содержит упоминания скрытого типа-свидетеля. Такое сокрытие осуществляется с помощью универсальной квантификации обобщённой функции `continuation` – если пользователь хочет обработать значение *некого* неизвестного типа, то он должен предоставить инструмент для работы с *любыми* типами.

Наконец, безотносительно кодировки Чёрча, универсальные типы сами по себе могут описывать “экзистентность” типов:
```scala 
trait Number[A]:
  def zero: A
  def one: A
  def sum(x: A, y: A): A
  def mul(x: A, y: A): A
```
Значения трейта `Number`, конкретизированного простым типом, доказывают возможность использования перечисленных в трейте функций для этого типа:
```scala
val boolAsNumber = new Number[Boolean]:
  def zero = false
  def one = true
  def sum = _ || _
  def mul = _ && _
```
Совокупность доступных значений типа `Number[A]` определяет те типы, для которых доступны возможности, описанные трейте. Таким образом, универсальный тип $\forall A.\; Number[A]$ трактуется, как описание экзистенциального типа $\{\exists A,\; Number[A]\}$. При этом сам конструктор типов `Number[A]` при такой трактовке описывает *класс типов*.

В статье Бартоша Милевски [Parametricity: Money for Nothing and Theorems for Free](https://bartoszmilewski.com/2014/09/22/parametricity-money-for-nothing-and-theorems-for-free/) говорится о преимуществах использования универсальных типов (см. также оригинальную статью лямбда-мена Филиппа Водлера [Theorems for free!](https://users.cs.utah.edu/~mflatt/past-courses/cs7520/public_html/s06/wadler89.pdf)). Но дуальные экзистенциальные типы, в свою очередь, не могут похвастать аналогичными свойствами – использование типов аналогичных представленному выше трейту `OrStringE` оказывается неудобным (требуют динамической валидации “существующего” типа во время выполнения). Поэтому ищутся различные способы избавится от явной экзистенциальности, свести её к универсальным типам. В математической логике такой стандартный алгоритм превращения экзистенциальных высказываний в универсальные известен под названием “[*сколемизация*](https://en.wikipedia.org/wiki/Skolem_normal_form)“.

>В Scala 2 [существовал](https://www.scala-lang.org/files/archive/spec/2.13/03-types.html#existential-types) специальный синтаксис для экзистенциальных типов (см. также [Existential Types in Scala](https://dzone.com/articles/existential-types-in-scala)):
>`type F = SomeClass[A] forSome { type A }`
>Позднее такой синтаксис [решили упразднить](https://docs3.scala-lang.org/scala3/reference/dropped-features/existential-types.html#), ссылаясь на сложности поддержки компилятором и на то, что схожих результатов можно добиться с помощью других синтаксических конструкций.

<anchor>ad_hoc_polymorphism</anchor>
### Специальный полиморфизм

Универсальный полиморфизм соответствует идее параметризации алгоритма типами, когда один код позволяет работать с *любыми* типами. Концепция экзистенциальности определяет дуальное понятие – *специальный полиморфизм*, когда код предполагает *существование некоторых* типов, для которых он будет корректным.

Пожалуй, самый простой сценарий, когда срабатывает специальный полиморфизм – это перегрузка функций:
```scala
def add(a: Int,    b: Int)    = a + b      // перегрузка для Int
def add(a: String, b: String) = a concat b // перегрузка для String

add( 4,   2 )    // 6
add("4", "2")    // "42"
add(true, false) // ОШИБКА!!! Для Boolean нет перегрузки add
```
В трёх последних строках используется одно и то же имя функции `add` для значений разных типов, но при компиляции в последней строчке будет ошибка, так как *существуют* реализации `add` только для аргументов типа `Int` и `String`, но не для `Boolean`, или каких-либо других типов. На этом примере видно, почему такой полиморфизм называется *специальным* – он работает только для специально описанных случаев (также говорят *ad hoc полиморфизм* от латинской фразы “ad hoc” – “для данного случая”).

Другая разновидность специального полиморфизма – это *полиморфизм прив**е**дения* (не путать с 👻!). Имеется в виду возможность создания пользовательских функций неявного приведения типов, существующая в разных языках программирования. В Scala 3 [неявные преобразования рекомендуется реализовывать](https://docs.scala-lang.org/ru/scala3/book/ca-implicit-conversions.html) посредством предоставления *неявных значений* обобщённого типа `Conversion`:
```scala
given Conversion[Int,     String] = _.toString
given Conversion[Boolean, String] = _.toString

def palindrome(str: String) = str concat str.reverse

palindrome(42)    // "4224"
palindrome(true)  // "trueeurt"
palindrome(4.2)   // ОШИБКА! значения Double нельзя туда, где нужен String
```
Видя, что в функцию, принимающую `String`, посылаются значения других типов *компилятор сам ищет* в области видимости неявные нужные преобразования. В последних строчках специальный полиморфизм срабатывает прямо перед вызовом `palindrome`, неявно приводя передаваемые значения к нужному типу с помощью функций преобразования, если таковые обнаружены.

Кстати, в точности таким же образом работает ООП-шный полиморфизм подтипов, который обычно относят, наоборот, к универсальному полиморфизму, имея в виду его модификацию с ограничениями подтипизации. Эти ограничения и есть проверка наличие неявного приведения от подтипа к супертипу. Только в этом случае не нужно объявлять их вручную – компилятор сделает это автоматически, как только вы объявите свой класс наследником родительского. 
```scala
trait Base  { def method(): Int }
class Child { def method() = 42; val i = 0 } // Нет наследования,
given Conversion[Child, Base] = child =>     // но есть неявное приведение!
  new Base { def method() = child.method() }

val child = new Child
def getInt(producer: Base) = producer.method()
getInt(child) // полиморфизм приведения!
```
То, что в случае отсутствия наследования при приведении типов приходится создавать в памяти новый экземпляр, не существенно, так как сейчас мы рассматриваем только верхнеуровневую семантику, не заморачиваясь с оптимизацией. Ещё одним отличием от наследования является то, что экземпляр `Base` “не помнит” о первоначальном типе `Child`. Это не позволит выполнить *принудительное* обратное приведение типов (например, при сопоставлении с шаблонами), как это работало с наследованием, и восстановить значение поля `i`. 

Вообще, “правильность” классифицирования полиморфизма подтипов (универсальный или специальный) совершенно не принципиальна, но важно понимать, каким образом обосновываются разные точки зрения на этот вопрос.

В приведённых выше фрагментах кода при объявлении неявных преобразований используется ключевое слово `given`. С помощью этого слова в контекст добавляются неявные значения определённого типа, но это лишь малый элемент очень мощного механизма языка Scala, называемого “[контекстные абстракции](https://docs.scala-lang.org/ru/scala3/book/ca-contextual-abstractions-intro.html)” ([тут](https://docs.scala-lang.org/scala3/reference/contextual/) подробнее). Этот механизм уже реализован в языках “доказательства теорем”, вроде Coq или Agda, но и во некоторых популярных языках появляются предложения реализовать что-то похожее. Под “контекстом” в общем случае подразумевается область видимости в которой доступны некоторые объявленные ранее типы, функции и значения, а ключевой особенностью является возможность [*вывода термов*](https://users.scala-lang.org/t/what-is-so-called-term-inference/8912/2) – когда *компилятор сам ищет значения нужного типа* (например, неявные преобразования, как было выше). И, кстати, это ещё один способ путешествия из вселенной типов во вселенную значений 😉.

В компиляторе Scala реализован автоматический поиск неявных значений обобщённого типа `Conversion`, параметризированного нужными типами. Но есть возможность и явно указать ему, неявные значения каких типов искать в контексте. Такую возможность зачастую относят к отдельной разновидности специального полиморфизма:
```scala
def palindromeDouble(dob: Double)(using dobToStr: Conversion[Double, String]) =
    palindrome(dobToStr(dob))

given Conversion[Double, String] = _.toString // Это значение
palindromeDouble(4.2) // "4.22.4"             // сюда передаяётся неявно!
```
Здесь `palindromeDouble` принимает аргумент типа `Double`, а далее указан ещё один параметр с использованием ключевого слова `using`. Это позволяет не передавать в функцию значение типа `Conversion[Double, String]` *явно* – компилятор сам найдёт в контексте нужное значение и передаст в функцию, но только если значение этого типа *существует* в контексте, было помещено туда *специально*. Конечно же, не обязательно перед каждым использованием неявных значений требуется явно прописывать необходимые `given`. Их можно, например, импортировать из других пакетов, или пробрасывать внутрь метода с помощью `using`. Алгоритм поиска неявных значений хорошо раскрывается в этом ответе на вопрос [Where does Scala look for implicits?](https://stackoverflow.com/questions/5598085/where-does-scala-look-for-implicits/5598107#5598107).

> Вывод термов является одной из основ *логического программирования*. Компилятор, видя что из значения одного типа нужно получить значение другого, сам ищет способ достичь этого на основе встроенных и пользовательских правил (неявных значений в контексте). Аналогичным образом в логическом программировании строится вся цепочка вывода искомого результата на основе заданных правил. У Бартоша Милевски есть хорошие публикация в его блоге под общим названием *Logic Programming in Scala*: [часть 1](https://like-a-boss.net/2020/07/07/logic-programming-in-scala.html), [часть 2](https://like-a-boss.net/2020/07/10/logic-programming-in-scala-part-2.html).

> В Scala 2 для работы с контекстом было только одно ключевое слово `implicit`, “неявно”. Оно использовалось и при объявлении неявных значений (методов/классов/объектов), и с аргументами метода, которые должны передаваться неявно. В Scala 3 сочли более идеоматичным использование двух ключевых слов `given` и `using`, но в актуальной версии “старый стиль” по-прежнему поддерживается.

Дополнительные материалы по работе с контекстными абстракциями в Scala:
- хабр-статья [Implicits в Scala — неявные методы, функции, значения и особенности](https://habr.com/ru/companies/beeline_tech/articles/741824/);
- ещё одна хабр-статья [Как использовать implicit'ы в Scala и сохранить рассудок](https://habr.com/ru/articles/329600/);
- статья у Юджина Баелдунга: [Scala 3 Implicit Redesign](https://www.baeldung.com/scala/scala-3-implicit-redesign);
- видео-обзор [Scala Implicits Revisited](https://www.youtube.com/watch?v=dr0PUXQhg3M&ab_channel=GOTOConferences) от автора Scala Мартина Одерски.

<anchor>scala_type_classes</anchor>
### Классы типов в Scala

Перепишем пример из начала обсуждения классов типов используя контекстные абстракции:
```scala
case class Context[A](meta: String)  
def enrichWithMeta[A](a: A)(using context: Context[A]) = (a, context.meta)  

given Context[Int]("целые числа")  

enrichWithMeta(4)   // (4, "целые числа")
enrichWithMeta("2") // Ошибка компиляции!
```
При вызове обобщённого метода `enrichWithMeta` требуется только один аргумент – значение, которое нужно “обогатить” строчкой. Но, не смотря на универсальную квантификацию метода, его использование ограничено только теми типами, для которых в текущем контексте существуют неявные значения обобщённого типа `Context[_]`.

Обычно о классах типов говорят именно как о *комбинировании* универсального и специального полиморфизмов, когда *параметризация* методов типами ограничивается *специальными* случаями *существования* значений определённых классов типов. Большое влияние на формирование такой точки зрения оказал язык Haskell, в котором для работы с классами типов предлагается синтаксис, основанный сочетании эти двух полиморфизмов. Впрочем, как и в случае полиморфизма подтипов, вопрос о классификации понятий, относится скорее к софистике, нежели к пониманию концепции и к её применению.

Контекстные абстракции представляют собой многогранный инструментарий, для которого классы типов являются лишь частным случаем его использования. Но классы типов сами по себе очень мощный инструмент, поэтому для удобства работы с ними в Scala существует ещё понятие [границ контекста](https://docs.scala-lang.org/ru/scala3/book/ca-context-bounds.html). Это просто “синтаксический сахар“, приправив которым пример выше получим такой код:
```scala
type Id = [A] =>> A
def enrichWithMeta[A: Context: Id] = (summon[A], summon[Context].meta)
//                  ↑↑↑↑↑↑↑↑↑↑↑↑↑	- "границы контекста"
given Int = 42 // Id[Int]
enrichWithMeta // (42, "целые числа")
```
При такой записи явно подчёркивается, что “любой” тип `A` на самом деле ограничен наличием в контексте вызова экземпляров типов `Context[A]` и `Id[A] = A`.  Так же здесь виден утвердительный ответ на вопрос, заданный в начале раздела – “можно ли считать значение `a: A` ограничением, накладываемым на тип `A`?“ При этом  `Id[A] = A`

Встроенный в язык метод `summon[_]` позволяет “призвать” значение нужного типа, неявно размещённое в контексте, ведь имя неявного значения здесь нигде не указывается.
![[Призыватели.png|Скалисты-призыватели, случайно пойманные объективом во время работы.|800]]
Впрочем, на практике призывы обычно выносятся в инструментальный код, определяющий язык предметной области (DSL), на котором будет описана вся бизнес-логика.

>Ещё один очень любопытный момент. В коде `A: Context` обобщённый тип `Context` вида `⋆ → ⋆` выступает **в роли типа** для `A` просто вида `⋆`! В этом смысле, все типы высокого ранга вида `k → ⋆` могут считаться *типами для типов* вида `k`, следовательно, они образуют ещё одну мультивселенную типов, независимую от иерархии (видов) типов, описанной ранее!

Классы типов в Haskell могут иметь *только один экземпляр* конкретного типа. В Scala же мы можем создать несколько таких экземпляров и передать любой из них как аргумент явно (не полагаясь на неявное разрешение, которое в таком случае породит ошибку компиляции). Например, это позволяет определить для чисел экземпляры класса типа моноида как на базе сложения, так и на базе умножения, и выбирать любой из них по необходимости (см. далее). Но приходится следить, чтобы неявно использовались именно *нужные* экземпляры классов типов.

![[Сквончи.png|Язык Сквончи контекстуальный. Слова можно понять, только если для них *существует специальный* смысл в контексте общения. Поэтому, дабы избежать нелепых казусов, очень важно следить, чтобы у слушателей был именно тот контекст, на который рассчитывает говорящий.]]

В Scala 3 появилось ключевое слово `derives`, которое при определении нового типа автоматически добавляет (в [объект-компаньон](https://docs.scala-lang.org/ru/tour/singleton-objects.html#%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D1%8B-%D0%BA%D0%BE%D0%BC%D0%BF%D0%B0%D0%BD%D1%8C%D0%BE%D0%BD%D1%8B)) неявные значения экземпляров классов типов, указанных после `derives`:
```scala
import cats.Show, cats.derived.*
enum IntTree derives Show: // ключевыое слово derives!
  case Branch(left: IntTree, right: IntTree)
  case Leaf(elem: Int)
  
// использование derives Show приводит к генерированию примерно такого кода:
//object IntTree:
//  given Show[IntTree] = Show.derived // макрос!
```
В данном примере мы просим компилятор автоматически предоставить экземпляр класса типов `Show`, импортированного из широко используемой библиотеки [Cats](https://typelevel.org/cats/) 🐈 . Ключевое слово `derives` – это просто синтаксический сахар для хитрого добавления последней строчки. При добавлении неявного значения в объект-компаньон, компилятор сможет найти его при любом использовании типа `IntTree` без каких-либо дополнительных импортов. Сгенерированный код (последняя закомментированная строчка) подразумевает, что в одноименном с классом типа объекте-компаньоне `Show` должно быть определено значение (или метод без параметров) `derived`. Почему-то в “Кошках” для классов типов не определены `derived`, но нас выручит дочерняя библиотека [Kittens](https://github.com/typelevel/kittens) 😹 – оттуда импортируется пакет `cats.derived.*`, в котором есть подходящий [метод расширения](https://docs.scala-lang.org/ru/scala3/book/ca-extension-methods.html) для объекта `Show` и прочих. Воспользоваться выведенным экземпляром класса типа `Show` можно с помощью метода-расширения `show`, неявно требующего этот экземпляр:
```scala
import IntTree.*
val myTree = Branch(Leaf(4), Leaf(2))

import cats.syntax.all.*
myTree.show // неявно используется "выведенный" экземпляр Show[IntTree]
```
Мы можем потребовать *сгенерировать* реализацию класса типа для *любого* типа, вместо того, чтобы писать её вручную! Но необходимо, чтобы этот класс типа поддерживал `derived`. А вот там уже происходит настоящая “зазеркальная магия”, основанная на том, что *любой тип представляется в виде алгебраического выражения*, построенного из сумм, произведений и экспоненциалов. Реализация класса типа конструируется на базе синтаксического дерева алгебраического выражения указанного типа. И всё это происходит (макросы выручают) на этапе компиляции!

Далее будут примеры использования классов типа для реализации моноида и в качестве альтернативы ООП. Классы типов высокого рода рассматриваются в следующем разделе про типы-контейнеры. Также можно ознакомится с этими источниками знаний о классах типов:
- Хабр-статьи
	- [Type classes в Scala](https://habr.com/ru/companies/tinkoff/articles/147759/);
	- [Классы типов в Scala (с небольшим обзором библиотеки cats)](https://habr.com/ru/articles/318960/);
	- [Что такое класс типов?](https://habr.com/ru/articles/771896/)
- Статья от авторов Scala [Type Classes as Objects and Implicits](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=d30d65ca9ce7891352024a5c71ebe0ae8c41f7ac).
- Статья на ScalaJobs [Typeclassery — A sure way of making generic programs context aware](https://scalajobs.com/blog/typeclassery-in-scala/).
- Статья [о классах типов](https://typelevel.org/cats/typeclasses.html) в библиотеке Cats.
- Фрагмент документации Scala [Implementing Type classes](https://docs.scala-lang.org/scala3/reference/contextual/type-classes.html).
- [Глава 12: Классы типов](https://github.com/anton-k/ru-neophyte-guide-to-scala/blob/master/src/p12-type-classes.md) из переведённой серии [Путеводитель неофита по Scala](https://github.com/anton-k/ru-neophyte-guide-to-scala/tree/master) Даниеля Вестсайда.
- Статья [Generic Type Class Derivation in Scala 3](https://blog.1punch.dev/scala/dotty/en/generic-type-class-derivation.html).
- Замечательная статья Лео Чунга [Ad-hoc Polymorphism In Scala](https://blog.genuine.com/2020/01/ad-hoc-polymorphism-in-scala/) в которой к классам типов приходят от F-ограниченного полиморфизма, упоминавшегося ранее в данной статье.


<anchor>monoid</anchor>
### Моноид

Опять этот неприветливый математический термин… Впрочем, он уже упоминался не раз, а в предыдущей статье был раскрыт с помощью картинок. Моноид – это конструкция, которая позволяет “сворачивать” списки до единственного значения, это всё, что необходимо, для построения функции `List[A] => A`. С помощью моноида можно пробежать список, накапливая в неком “аккумуляторе” результирующее значение. Это значит, что моноид должен предоставить, во-первых, “начальное значение” для случая пустого списка, а во-вторых бинарную операцию, принимающую аккумулятор и элемента списка, а возвращающую новое значение аккумулятора.
```scala
trait Monoid[A]:
  val neutral: A
  val combine: (A, A) => A

def imperativeFold[A](list: List[A])(using mon: Monoid[A]) =
  // реализация может быть разной
  var accum = mon.neutral // не ФП-шно, но наглядно
  for (a <- list)
    accum = mon.combine(accum, a)
  accum
```

Да, свёртку можно реализовать и рекурсивно, или даже воспользоваться встроенной функцией для `List`, но кажется, что императивная реализация будет более удобной для демонстрации концепции моноида. С помощью моноида можно сворачивать списки любых типов, даже закрытых для подтипизации (наследования), достаточно только реализовать моноид для этих типов. На целых числах можно определить два очевидных моноида – на основе сложения и умножения:
```scala
given inSumMonoid: Monoid[Int] = new:
  val neutral = 0
  val combine = _ + _

val inProdMonoid: Monoid[Int] = new:
  val neutral = 1
  val combine = _ * _

val lst = List(4, 2)
imperativeFold(lst)                     // 6
imperativeFold(lst)(using inProdMonoid) // 8
```
В двух последних строчках свёртка списка проводится с помощью разных моноидов. В первом случае из контекста неявно тянется `inSumMonoid`, что в результате даёт сумму элементов списка, а во втором случае явная передача `inProdMonoid` позволяет перемножить элементы.

Данный сценарий, типичен для применения классов типов. То, что полиморфный метод `imperativeFold[A]` принимает параметр `Monoid[A]`, ограничивает его использование только классом таких типов, для которых предоставлен неявный экземпляр `Monoid[A]`.

> Для того, чтобы “сворачивание” списка можно было проводить в любом порядке, в том числе и по частям, необходимо, чтобы бинарная операция была ассоциативной, а начальное значение – нейтральным элементом этой операции. Именно эти *законы* и определяют математическое понятие “моноид”. Технически, Scala позволяет учесть такие законы явно, но мы не станем так заморачиваться (популярные библиотеки также не особо следят за соблюдением законов своих классов типов).

<anchor>oop_classtypes</anchor>
### Эксперименты с ООП

Возьмём, к примеру такой сервис:
```scala
trait StorageOop:
  def getVal(key: Int): Option[String]
  def setVal(key: Int, value: String): Unit
  def combine(other: StorageOop): Unit
```
И вроде тут описано всё, что мы можем получить, имея терм типа `StorageOop`, но
- это не все функции, связанные с типом, например, тут нет конструктора;
- метод `combine` выглядит неуместным – его реализация может переопределяться в наследниках, в то время как, по сути, он однозначно должен определяться двумя другими функциями; он не должен “принадлежать значению” типа `StorageOop`.

Перепишем этот трейт в виде универсального представления экзистенциального типа:
```scala
trait StorageTC[Storage]:
  def empty: Storage
  def getVal (storage: Storage)(key: Int): Option[String]
  def setVal (storage: Storage)(key: Int, value: String): Storage
  def combine(first: Storage, other: Storage): Storage
```
“Существует такой `Storage`, для которого определены эти функции”. Здесь
- явно присутствует один “конструктор” `empty` для типа `Storage`,
- функции `getVal` и `setVal` принимают первым параметром “хранилище” типа `Storage`,
- причём `setVal` и `combine` также возвращает новое, изменённое хранилище (ведь про тип `Storage` неизвестно ничего, он может быть неизменяемым),
- функция `combine` приняла законченный вид – это бинарная операция на значениях одного и того же типа. 

Введём термины предметной области (DSL)
```scala
extension [Storage](storage: Storage)(using tools: StorageTC[Storage])
  def extract(key: Int)			    = tools.getVal(storage)(key)
  def keep(pair: (Int, String))	= tools.setVal(storage).tupled(pair)
  def mergeWith(other: Storage)	= tools.combine(storage, other)
object Storage:
  def empty[Storage: StorageTC] = summon[StorageTC[Storage]].empty
```
чтобы ими было удобно оперировать при описании бизнес-логики:
```scala
def businessLogic[Storage: StorageTC](storage1: Storage, storage2: Storage) =
  storage1 mergeWith storage2 keep (42 -> "ответ") extract 42
```

Чтобы вызвать бизнес-логику с хранилищем какого-то типа, необходимо предоставить “свидетельство” существования `StorageTC` для этого типа:
```scala
type Storage = Int => Option[String]

given StorageTC[Storage] = new:
  def empty = _ => None
  def getVal (storage: Storage)(key: Int) = storage(key)
  def setVal (storage: Storage)(key: Int, value: String) =
    k => Option.when(k == key)(value) orElse storage(k)
  def combine(first: Storage, other: Storage): Storage =
    first combine other
```
По сути, это реализация интерфейса.

Вот теперь мы можем вызвать бизнес-логику для двух разных (ну, типа 😉) хранилищ `Storage`:
```scala
val emptyStorage = Storage.empty[Storage]
businessLogic(emptyStorage, emptyStorage) // Some("ответ")
```

Подводя итоги эксперимента можно сказать, что
- классы типов позволяют полностью покрыть возможности ООП-шных решений;
- слой “синтаксического сахара” – терминов предметной области – необязателен, но зачастую он позволяет писать очень выразительный код;
- решение задачи через традиционное ООП и через классы типов по объему примерно одинаковы;
- классы типов позволяют описывать требуемое поведение для любых существующих типов, в том числе и закрытых для дальнейшего наследования (`final class`); 
- пример метода `combine` демонстрирует недостатки ООП подхода, когда “наследование” и “переопределение методов” может сделать код плохо предсказуемым; да и, в целом, инкапсуляция, “владение методов данными” не всегда удачно предметную область.

В дополнение парочка статей на ту же тему:
- вики-страница Haskell [OOP vs type classes](https://wiki.haskell.org/OOP_vs_type_classes);
- пост из блога Александру Недельку [OOP vs Type Classes, Part 1: Ideology](https://alexn.org/blog/2022/05/13/oop-vs-type-classes-part-1-ideology/);
- сказка [О тяжёлой судьбе глаголов в Королевстве Существительных](https://ru.hexlet.io/blog/posts/javaland).

<anchor>container_types</anchor>
## Типы-контейнеры

Обобщённые типы (generics) появились в программировании, когда в функциональном (по большей части) языке [ML](https://ru.wikipedia.org/wiki/ML) реализовали элементы [системы F](https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B0_F). То были простые конструкторы типов вида $\star\rightarrow\star$, основа [предикативного полиморфизма](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%BF%D0%BE%D0%BB%D0%B8%D0%BC%D0%BE%D1%80%D1%84%D0%B8%D0%B7%D0%BC#%D0%9F%D1%80%D0%B5%D0%B4%D0%B8%D0%BA%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D1%8B%D0%B9_%D0%BF%D0%BE%D0%BB%D0%B8%D0%BC%D0%BE%D1%80%D1%84%D0%B8%D0%B7%D0%BC), и другие виды тогда не поддерживались. Позднее такие обобщённые типы появились и в более популярных языках: C++, Delphi, Java, C# и т.п. Изначально ФП-шная “математическая” абстракция стала повсеместной (впрочем, таким же образом зародилось и развивается всё программирование), и возникла необходимость донести её до широкой публики. В качестве удобной аллегории для обобщённых типов вида $\star\rightarrow\star$, призванной “визуализировать” в воображении читателей некоторые ключевые соотношения, часто привлекается идея “*контейнера*”. Ей и посвящён этот раздел.

<anchor>container_conecpt</anchor>
### Идея обобщённого контейнера

Опять же, начнём с конкретного примера:
```scala
case class WithLog[A](a: A, log: String)

val intWithLog = WithLog(42, "создали значение;")
val stringWithLog = WithLog(
  intWithLog.a.toString,
  intWithLog.log + " преобразовали его в строку;"
)

stringWithLog.a // "42"
```
Трактовка `WithLog[A]` как “контейнера” для значения некого типа `A` весьма очевидна:
- вызывая конструктор `WithLog[A]`, мы “*запаковываем*” значение пресловутого типа `A` в *контейнер*;
- в дополнительном поле `log` обобщённого класса `WithLog` мы можем накапливать журнал операций, производимых со значениями поля `a`;
- в последней строчке с помощью проектора `a` мы “*распаковываем*” его.
Так может быть, что понятие “контейнер” определяется возможности распаковки значения?

Но, пожалуй, самым популярным примером контейнера является обобщённый список, имеющийся практически во всех статически-типизированных языках программирования:
```scala
val list: List[Int] = List(4, 2)
val emptyList = list.filter(_ > 42) // пусто!

val i1: Int = list.???      // какое из значений "распаковать"???
val i2: Int = emptyList.??? // как вытащить значение из пустого списка???
```
И тут список преподносит сюрпризы:
- не всегда возможно “распаковать” список, ведь этот контейнер может быть пустым;
- непонятно, что называть “распаковкой”, если в контейнере несколько значений.
Ещё первым свойством обладают также некоторые стандартные контейнеры Scala, например, `Option`, `Either`, `Try` или `Future`.

Тогда будем называть контейнерами такие обобщённые типы, в которых значения типа параметра “хранятся” в отдельных полях?

Но вот ещё один пример:
```scala
type Func[A] = String => A
val parseInt: Func[A] = _.toIntOption.getOrElse(0)
val duplicateString: String => String = (s: String) => s concat s
val parseDouleInt: Func[A] = parseInt compose duplicateString
parseDouleInt("42") // 4242
```
Обобщённый тип `Func[A]` описывает функцию, возвращающую значение типа `A`, вычисляемую на основе переданной туда строки. Функция `parseDouleInt: Func[Int]` предваряет выполнение `parseInt: Func[Int]` удвоением исходной строки – мы опять получаем новый “контейнер” на основе исходного. В последней строчке, мы однозначно “распаковываем из контейнера” значение типа `A = Int`, используя строку `"42"`. Но при этом, само “хранение” распаковываемого значения даже не предусмотрено!

Более запутанный случай представляет такой тип (ранее при обсуждении вариантности обобщённых типов уже упоминалось что-то похожее):
```scala
type Cont[A] = (A => Boolean) => Boolean

def value() = "значение"
val contStr: Cont[String] = continuation => continuation(value()) // замыкание!

val strToInt: String => Int = _.length
val contInt: Cont[Int]    = continuation => contStr(strToInt andThen continuation)

val strVal: String = contStr.??? // как распаковать???
val intVal: Int    = contInt.??? // как распаковать???

contStr(_ == "знание") // false. "значение" не равно "знание"!
contInt(_ <  10)       // true.  "значение".lenght меньше 10
```
Тут у нас тип функции, принимающей *функцию-продолжение* для типа `A` и возвращающий значение фиксированного типа. Функция-продолжение может как забывать исходное значение, так и, наоборот, обогащать его (тогда это значение удастся восстановить). Структура типа `Cont[A]` не предполагает хранения значений, поэтому для него нет ни только проектора этого значения, ни вообще какого-либо честного способа распаковки! Тем не менее, можно считать, что значение всё-таки содержится внутри `contStr` – в данном случае, это метод `value()`, умеющий вычислять значение нужного типа. Другая контейнерная переменная `contInt` определяется через преобразование `contStr` с помощью функции `strToInt` и перенимает всё тот же метод `value`. Его использование можно проследить в двух последних строчках. В итоге для конструктора типов `Cont` получаем следующее:
- “распаковка” значения не предусмотрена,
- но тип оказывается полезным – из его значений мы можем получать значения других типов;
- внутри скрытно “хранится” значение целевого типа, а точнее, способ его использования;
- из одного контейнеризированного значения можно получить другие контейнеризированные значения без распаковки!
Можно ли `Cont[A]` считать “контейнером”? Вопрос выглядит спорным, но для содержательности дальнейших рассуждений предлагаю считать, что можно.

Приведённые примеры демонстрируют, что контейнерные типы не столько “хранят” значение, сколько содержат некий *вычислительный контекст*, который позволяет (или не позволяет) использовать значения указанного типа. При создании контейнера появляется “начальный” контекст, который меняется при “преобразованиях внутри контейнера” и используется при “распаковке”.

Вот ещё пара тривиальных, но важных типов-контейнеров:
```scala
type Id[A] = A
type Void[A] = Unit
```

Итак, 
> *контейнером* будем называть обобщённый тип вида $\star\rightarrow\star$, *ковариантный* по своему параметру. В этом случае можно говорить о том, что любую функцию `A => B` можно “применить ко всем хранящимся в контейнере `F[A]` значениям”, чтобы получить `F[B]`;

Обобщением приведённых выше случаев являются контейнеры для сразу нескольких простых типов (N-контейнеры, для некого $N>1$), например,
```scala
type Triple[+A, +B, +C] = (A, B Either C) // A × (B + C)
```
Такие обобщённые типы также нередко встречаются в программировании, и они ещё будут упомянуты далее.

Большинство обобщённых типов, с которым приходится иметь дело программистам – это ковариантные типы-контейнеры. Но очевидно, что не все конструкторы типов являются ковариантными. *Контравариантные* и *инвариантные* типы уже не получиться отнести к контейнерам:
```scala
type Contravaianat[-A] = A => String
type Invariant    [ A] = A => A
```

Также как и для большинства других типов, важно понимание, как использовать значения типов-контейнеров. С функциональной точки зрения *любой* контейнерный тип полностью определяется единственной функцией “распаковки” `F[A] = [B] => ???[A, B] => B`. Здесь `???[A, B]` – это всё, что необходимо для такого процесса. Однако, тип $B$ в общем случае не совпадает с $A$, как это было с контейнером `Cont`, значит, и термин “распаковка” может показаться не достаточно удачным. Но для нас же это не проблема 😉?

Помимо распаковки таких типов, важны и другие их “контейнерные возможности” вроде `map`, `flatMap` и т.п. В Scala и многих других языках программирования они обычно реализованы как отдельные методы соответствующих обобщённых классов. Вынести эти возможности в некий *общий* родительский трейт не получится, ввиду широкого разнообразия контейнерных типов, не связанных наследованием. Да и, как уже упоминалось выше, ООП-шный подход плохо работает с функциями комбинирования (контейнеров, в нашем случае). Для единообразной работы с контейнерными типами удобнее использовать *классы типов высокого рода*.

<anchor>container_typeclasses</anchor>
### Классы типов для контейнеров

Характерные возможности контейнерных типов распадаются на три основные группы:
- “преобразование внутри контейнера” (ковариантность);
- “преобразование самого контейнера”, когда имея значение одного контейнера, получаем другой контейнер, но с тем же простим типом;
- “перестановка контейнеров”, вложенных один в другой.

Запишем эти возможности в виде функциональных типов высокого рода: 
```scala
type Lift[F[_]]       = [A, B] => (A => B) => (F[A] => F[B])
type ~>  [F[_], G[_]] = [A   ] => F[A]     => G[A]
type Swap[F[_], G[_]] = [A   ] => F[G[A]]  => G[F[A]]
```
Рассмотрим их детальнее.

Класс типов `Lift` отражает ковариантную сущность контейнера `F`. На практике удобнее использовать такие функции:
```scala
extension [A, B] (func: A => B)
  def lift[F[_]: Lift]: F[A] => F[B] = summon[Lift[F]](func)

extension [F[_]: Lift, A] (fa: F[A])
  def map(func: A => B): F[B] = func lift[F] f
```
Говорят, что функция высокого рода `lift` “поднимает” функцию `func` в “мир `F`” в то время как `map` “отображает” `F[A]` в `F[B]` посредством `func: A => B`. В многих языках для встроенных контейнеров доступна функция `map`, но, возможно, под другим именем (например, в C# это `Select` из Linq), так что всегда нужно обращать внимание на сигнатуру метода, тип функции, нежели на название. В Scala-библиотеке Cats, есть аналогичный класс типов `Functor`, название которого позаимствовано из теории категорий.

Стрелочку `~>` иногда называют “естественным преобразованием”, что также восходит к теории категорий. В Cats есть тип `FunctionK`, но он чаще используется под таким же псевдонимом `~>`. Этот обобщённый тип принимает сразу два типа-параметра, так что его значения не накладывают ограничений на какой-то *один* тип, что немного затрудняет его трактовку как класса типов. Но давайте введём такие каррированные псевдонимы
```scala
type To  [G[_]] = [F[_]] =>> F ~> G  
type From[F[_]] = [G[_]] =>> F ~> G
type Iso [F[_]] = [G[_]] =>> F ~> G & G ~> F // изоморфизм конейнеров... но это не точно 😏
```
и с пользованием вспомогательных типов
```scala
type Id[A] = A  
type Dupe[F[_]] = [X] =>> F[F[X]]
```
получим наиболее часто встречающиеся примеры классов типов, основанных на естественных преобразованиях:
```scala
type Pure[F[_]]    = Id      ~> F   // = From[Id]  
type Extract[F[_]] = F       ~> Id  // = To[Id]  
type Flatten[F[_]] = Dupe[F] ~> F   // = From[Dupe[F]]
```

Введём полезные методы расширения:
```scala
extension[F[_], A] (fa: F[A])  
  def ~>[G[_]: From[F]]: G[A] = summon[F ~> G](fa)

extension[A] (a: A)
  def pure[F[_]: Pure]: F[A] = a.~>[F]

extension[F[_]: Extract, A] (fa: F[A])
  def extract: A = fa.~>[Id]

extension [F[_]: Flatten, A] (ffa: F[F[A]])
  def flatten: F[A] = ffa.~>[F]

extension[F[_]: Flatten: Lift, A] (fa: F[A])
  def flatMap[B](func: A => F[B]): F[B] = (fa map func).flatten
```
Функция `pure` “запаковывает” значение в контейнер. Название заимствовано у хаскелистов, подразумевающих хранение в контейнере именно вычислительного контекста – “запаковка” значения в контейнер заключается в создании *чистого*, “*обеднённого*” (pure) контекста. “Распаковку” контейнера представляет в примере выше функция `extract` – обычно такая возможность реализуется в классах-контейнерах как метод с названием, специфичным для каждого контейнера (`run`, `get`, `reduce`, `use` и т.п.). Естественное преобразование `flatten` называется так скорее всего потому, что в качестве контейнера `F` часто выступает список, и в этом случае `flatten` превращает двумерный список `List[List[A]]` в плоский (flat) `List[A]`. Часто встречающийся в коде Scala `flatMap` демонстрирует, что полезно комбинировать элементарные возможности, представленных основными классами типов-контейнеров. Другой пример – привычная фильтрация значений в контейнере `F`:
```scala
extension [F[_]: Lift: Flatten: From[Option], A] (fa: F[A])
  def filter(predicate: A => Boolean): F[A] =
    fa.flatMap(a => Option.when(predicate(a))(a).~>[F])
```

Наконец, третья ключевая возможность `Swap` позволяет переставлять вложенные контейнеры местами. К сожалению, не существует однозначного способа переставить местами произвольные вложенные контейнеры. Но это возможно в некоторых частных случаях, например, когда внешний контейнер представляет собой некую коллекцию, и её можно “свернуть” (fold), пробежаться по ней (traverse), а для внутреннего контейнера есть возможность преобразования пары контейнеров в контейнер для пары (про функции `zip` и `tupled` см. чуть ниже). В библиотеке Cats есть подходящий класс типов – [Traverse](https://typelevel.org/cats/typeclasses/traverse.html), предоставляющий для таких контейнеров следующие функции (выражаются друг через друга):
```scala
extension[F[_]: Iso[Seq], A] (fa: F[A])  // F[_] - "сворачиваемый" список, Foldable
  def traverse[G[_]: Lift: Zip2: Pure, B](func: A => G[B]): G[F[B]] =
    fa.~>[Seq].foldLeft(Seq.empty[B].pure)((accum, a) => (accum zip func(a)).map(_ appended _)).map(_.~>[F])
   //  ↑↑↑↑↑↑↑                       ↑↑↑↑                       ↑↑↑          ↑↑↑                ↑↑↑   ↑↑↑↑↑

val urls: List[URL] = ???
def getStringFromUrl(url: URL): Future[String] = ???

val contents: Future[List[String]] = urls.traverse(getStringFromUrl)
//                                        ↑↑↑↑↑↑↑↑
```
Для прочих же ситуаций обычно предлагается реализовать такой класс типов для *вложенного* контейнера:
```scala
type Distributive[G[_]] = [F[_], A] => F[G[A]] => G[F[A]]

extension[F[_], G[_]: Distributive, A] (fga: F[G[A]])
  def cosequence: G[F[A]] = summon[Distributive[G]](fga)

extension[F[_]: Lift, A] (fa: F[A])
  def distribute[G[_] : Distributive, B](agb: A => G[B]): G[F[B]] = summon[Distributive[G]](fa map agb)
```

Перестановку можно произвести не только с простыми, но и с N-контейнерами. В качестве последних часто выступают произведения типов (кортежи):
```scala
type Swap2  [F[_, _], G[_]   ] = [A, B] => F[G[A], G[B]] => G[F[A,    B]]
type Coswap2[F[_],    G[_, _]] = [A, B] => F[G[A,    B]] => G[F[A], F[B]]

// классы типов для контейнеров-кортежей:
type ×[A, B] = (A, B) // инфиксный синоним для произведения типов
type Zip2  [F[_]] = Swap2  [×, F]
type Unzip2[F[_]] = Coswap2[F, ×]

extension[F[_]: Zip2, A] (fa: F[A])
  def zip[B](fb: F[B]): F[A × B] = summon[Zip2[F]]((fa, fb))

extension[F[_]: Unzip2, A, B] (fab: F[A × B])
  def unzip: F[A] × F[B] = summon[Unzip2[F]](fab)
```
Здесь в названиях методов прослеживается аналогия между опять же списками и застёжками-молниями:
```scala
val ints = List(4, 2)
val strings = List("4", "2")
val intStrings = ints zip strings     // List((4, "4"), (2, "2"))
val (ints1, ints2) = intStrings unzip // (List(4, 2), List("4", "2"))
```
Комбинатор `zip` производит контейнерные вычисления *независимо* друг от друга – например, даже если в одном из них произойдёт ошибка, другое всё равно будет запущено. Иными словами, безотносительно разнесения по времени, вычисления посредством `zip` производятся *параллельно*, в то время как `flatMap` организует *последовательное* выполнение, при котором сбой на любом шаге прервёт всю цепочку. Исходя из этих соображений, для комбинирования независимых вычислений вместо `Zip2` вводится класс типов “аппликативный функтор” – к нему относят возможность `zip` и другие вспомогательные функции (`prodctL`, `productR` и т.п.). В библиотеке Cats этот класс типов называется [Applicative](https://typelevel.org/cats/typeclasses/applicative.html). Аналогичные функции встречаются под названиями `tupled/untupled`, явно указывая, что они работают с кортежами.

Особняком стоит возможность, общая для большинства типов – вычисление значения *произвольного* типа на основе контейнеризированного: `F[A] => B`. Такие функции, как и обычная “распаковка“, называются по-разному в зависимости от самого контейнера (`use`, `apply`, `fold` и т.п.). В Scala для списков и других похожих на них контейнеров (`Option`, `Either` и т.п.) такая функция называется `fold` (“свёртка”). В библиотеке Cats представлен класс типов `Foldable` c реализациями для контейнеров, представимых в виде списков (`Option`, различные деревья и т.п.). На самом деле, такой класс типов эквивалентен естественному преобразованию `F ~> List`:
```scala
extension[F[_]: To[List], A] (fa: F[A])
  def fold[B](start: B, combine: (B, A) => B) =
    fa.~>[List].foldLeft(start)(combine)
```
Для произвольных контейнеров не получится описать *одну общую* функцию вида `F[A] => ???[A, B] => B` – сигнатура функции оказывается специфичной для каждого типа контейнера, поэтому и общего класса типа для этого случая нет. Но сама возможность обычно реализуется для каждого контейнера индивидуально.

Такой минимальный “джентельменский набор” возможностей контейнерных типов доступен не только в Scala – в том или ином виде что-то похожее можно найти практически в любом языке программирования, поддерживающем обобщённые типы.

То, что в данной статье называется “контейнерными типами” в других источниках нередко именуется “функторами” или даже чаще “монадами”. Всё дело в том, что такая возможность как `map` (`lift`) является ключевой для понятия “функтор”, а `flatMap` (`flatten`) – для “монады”, и эти названия транслируются на контейнерные типы, обладающими таким возможностями (что, на самом деле, не совсем корректно). Различие в терминологии стоит иметь в виду при изучении других источников на ту же тему:
- хабр-переводы статей из [блога Эдит Баргавы](https://www.adit.io/), с примерами на Haskell, но большим количеством замечательных авторских картинок, раскрывающих концепцию контейнера:
	- [Функторы, аппликативные функторы и монады в картинках](https://habr.com/ru/articles/183150/);
	- [Тройка полезных монад](https://habr.com/ru/articles/18472.2/);
- более фундаментальная, но достаточно популярная PDF-статья [The Essence of the Iterator Pattern](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/3FC26EB2A63E6A2B29E07B9F0D5C5BCD/S0956796809007291a.pdf/the-essence-of-the-iterator-pattern.pdf) на английском (и на Haskell);
- в [документации к библиотеке Cats](https://typelevel.org/cats/) контейнеры и соответствующе классы типов не отделены от прочих, поэтому более точную ссылку не получится дать.
- статья Конора Макбрайда и Росса Патерсона [Applicative programming with effects](http://staff.city.ac.uk/~ross/papers/Applicative.pdf) об аппликативных функторах.

<anchor>effects</anchor>
### Эффекты

Контейнерный тип позволяет разнести по времени создание экземпляра и его “распаковку”. Это позволяет клиентскому коду самому решать, когда и как “распаковывать контейнер”. Например, подготовленный в одном месте список целых чисел в других местах может быть просуммирован, или просто выведен на экран (это также своеобразный вариант “распаковки”), причём, сам контейнер может быть предварительно модифицирован – числа могут быть отфильтрованы, преобразованы в строки и т.п.

Преждевременная распаковка бывает также не целесообразной при *асинхронных* вычислениях. Дело в том, что логика приложения заключается в реализации взаимодействия с различными объектами окружения – пользовательский ввод/вывод, работа с памятью и файловой системой, взаимодействие с базами данных и прочими сервисами. Важной особенностью такого взаимодействия является *ожидание* каких-либо событий от окружения. В любой момент времени можно увидеть, что на компьютере одновременно работают десятки, а то и сотни процессов, которые, в свою очередь, одалживают у операционной системе по несколько потоков вычисления. Как правило, все эти процессы и их потоки – те ещё ждуны. Но каждый поток является весьма ценным ресурсом операционной системы, и ей не просто жонглировать ими на имеющемся железе. Обычно крайне неудачным решением является реализация всей логики программы в единственном потоке вычисления, который большую часть времени будут ждать, впустую растрачивая ресурсы системы.

Для решения таких проблем в Scala есть контейнер `Future`, который хранит контекст *асинхронного вычисления* сложной задачи (см. например, статью [A Guide to Scala Futures](https://www.baeldung.com/scala/futures)). При создании экземпляра контейнера на основе какой-либо функции, её вычисление запускается в новом потоке (но это не точно 😉). Отложенная “распаковка” производимых в контейнере вычислений позволит среде исполнения и операционной системе более рационально распоряжаться мощностями компьютера, тем самым экономя ресурсы, прежде всего, время. Для `Future` также реализованы ключевые возможности контейнеров, вроде тех же `map` или `flatMap` – преобразования будут производится не в основном потоке (при необходимости), даже если изначально контейнер создавался методом `Future.successful` с чистым (pure) контекстом. Кроме того, в библиотеке [Cats.Effect](https://typelevel.org/cats-effect/) есть реализации некоторых классов типов для `Future`, предоставляющие этому контейнеру дополнительные возможности. Аналогичные обобщённые контейнеры для асинхронных вычислений встречаются в многих популярных языках программирования.

При учёте взаимодействия с окружением обычные функции вида $A \Rightarrow B$ превращаются в $U\Rightarrow(A\Rightarrow B\times U)$, где псевдотип $U$ описывает состояние окружения (universe). Проблема с этим псевдотипом заключается в том, что теоретически нельзя предоставить неизменяемое значение, описывающее состояние целой вселенной – невозможно гарантировать постоянство даже небольших её частей. Этот факт существенно ослабляет преимущества теории типов, как инструмента обеспечения корректности алгоритмов. В частности, и запаковка, и распаковка контейнера `Future` не являются *чистыми функциями*. Сам контейнер обычно используется для асинхронных *вычислений с [побочными эффектами](https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D0%B1%D0%BE%D1%87%D0%BD%D1%8B%D0%B9_%D1%8D%D1%84%D1%84%D0%B5%D0%BA%D1%82_(%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5))*, которые запускаются единственный раз, либо в момент создания контейнера, либо при применении преобразований внутри него. При запаковке среда исполнения принимает решение о необходимости резервирования потока операционной системы. В свою очередь, распаковка может давать различные результаты, в зависимости от того, завершилось ли вычисление – возможности этого контейнера не обладают *ссылочной прозрачностью*.

Впрочем, всё не так плохо. Есть несколько популярных Scala-библиотек, которые предоставляют *ленивые контейнеры*, предназначенные для построения композиции функций с побочными эффектами. Их “ленивость” заключается в том, что они не запускают вычисления сразу, а просто *сохраняют* внутри себя все преобразования до самого этапа распаковки. Это позволяет “*чисто*“ описать весь алгоритм, позволив компилятору гарантировать его корректность, а все побочные эффекты скобинированных внутри функций сработают только в самом конце программы, когда неявно библиотечными инструментами будет производится распаковка.

Хорошим примером является контейнер [IO](https://typelevel.org/cats-effect/docs/2.x/datatypes/io) (Inpout/Output) из упомянутой ранее библиотеки Cats.Effect. *Очень упрощённо* этот контейнер можно определить так:
```scala
enum IO[+A]:
  case Pure[A](a: A)                           extends IO[A] // ≅ A
  case FlatMap[A, B](ib: IO[B], f: B => IO[A]) extends IO[A] // ≅ IO[B] × IO[A]ᴮ
```
Можно заметить, что контейнер `IO` представляет собой по сути *список* разнородных (по типу) функций, а в самом начале этого списка лежит некое исходное значение. Для такого типа очевидным образом определяются все основные возможности, присущие контейнерам. Отличительной особенностью `IO` и прочих ленивых контейнеров является то, что их всегда можно преобразовать к *любому* другому контейнеру *без потерь*. Способность контейнеров быть преобразованными к любым другим контейнерам без потерь часто называется “начальной” или “свободной” ~~монадой~~. 

```scala
import IO.* // из примера выше

type ~>[F[_], G[_]] = [A] => F[A] => G[A] // "естественное" преобразование контейнеров

val ioToOption: IO ~> Option =
  [A] => (_: IO[A]) match
    case Pure(a)          => Some(a)
    case FlatMap(ib, fba) => ioToOption(ib) flatMap {fba andThen ioToOption.apply}

val initIO = FlatMap(FlatMap(Pure(
  42),
  i => {                  println("Int: " + i); Pure(i.toString)}),
  s => {val l = s.length; println("Len: " + l); Pure(l)})

val res1 = ioToOption(initIO)
val res2 = ioToOption(initIO)
println("Res: " + res1)
// Вывод в консоль:
// Int: 42
// Len: 2
// Int: 42 <-- эффекты срабатывают не при конструировании IO,
// Len: 2      а при КАЖДОЙ его "перепаковке" (например, в Option)
// Res: Some(2)
```
Здесь демонстрируется преобразование самописного контейнера `IO` в стандартный `Option`, но не сложно экстраполировать это решение на любой другой конечный контейнер. Также пример раскрывает “ленивость” `IO` – побочные эффекты преобразований срабатывают не при конструировании контейнера (как в случае `Future`), а при *каждой* его “распаковке”, или “перепаковке” в другой контейнер. Впрочем, `IO` из Cats, или аналогичные ленивые контейнеры из других библиотек не являются “полностью свободными”, в том смысле, что для их распаковки не обязательно самому предоставлять преобразования к “неленивым” контейнерам, так как в библиотеках уже есть встроенные механизмы “интерпретации” (то бишь распаковки) этих контейнеров.

Контейнер `IO` в большинстве ситуаций является лучшей альтернативой в сравнении с `Future`.  Использование `IO` позволяет писать “чистый” код в функциональном стиле. Про преимущества `IO` над `Future` можно прочесть тут:
- Gist.github: [From Scala Future to Cats Async?](https://gist.github.com/sentenza/c1fed5856a2ade343d999321458003c4), [IO vs Future and Referential transparency](https://gist.github.com/dcastro/c451883ff8aac44c57233ef1c6fd75ee);
- Stackoverflow: [Why future has side effects?](https://stackoverflow.com/questions/44196088/why-future-has-side-effects), [Scala with cats IO/Either instead of Future/Exceptions](https://stackoverflow.com/questions/69826999/scala-with-cats-io-either-instead-of-future-exceptions);
- замечательная статья [IO monad: which, why and how](https://kubuszok.com/2019/io-monad-which-why-and-how/ "IO monad: which, why and how") Матеуша Кубушока, опубликованная в его блоге.

Однако, в функциональном программировании термин “эффекты” часто понимают шире, чем просто “побочные эффекты”. В частности, к эффектам относят также возможные сбои, работу с “продолжениями”, интерактивный ввод/вывод (бесконечные потоки событий), недетерминированность (когда возвращается не одно значение, а целый *список*) и т.п. Носителями эффектов являются функции, значит обработка эффектов заключается в неком “обёртывании” таких функций, а точнее, в их правильном *комбинировании*. 

Классы типов контейнеров как раз и предоставляют такие *комбинаторы*, вроде `flatmap`. Передаваемые в них функции комбинируются с хранящимся в контейнере значением, или другими функциями, в соответствии с эффектом, связанным с алгебраической структурой этого контейнера. Действительно, на любой эффект можно натянуть ~~сову~~ тип-контейнер с соответствующими этому эффекту комбинаторами. И обратно, алгебраической структуре любого типа-контейнера соответствуют возможности комбинирования функций-носителей некоторого эффекта. Именно это и лежит в основе полезности концепции контейнеров.

В качестве примера рассмотрим контейнер для эффекта "возможного сбоя" вычислений:
```scala
import scala.util.Try
type F[X] = Try[X]

// шаги вычисления; реализация не важна
val fa :      F[A] = ??? // начальное значение в контейнере
val afb: A => F[B] = ??? // функция с "эффектом"
val bc:  B =>   C  = ??? // "чистая" функция
val cfd: C => F[D] = ??? // функция с "эффектом"

// один из вариантов записи композции вычислений
val program: F[D] = // : Try[D]
  fa  flatMap
  afb map
  bc  flatMap
  cfd
```
Здесь комбинаторы `map` и `flatMap` записаны в инфиксной операторной форме, что разгружает описание алгоритма, избавляя от избыточных скобок и точек.

В дополнение можно прочитать хабр-обзор [Особенности сред исполнения различных систем эффектов в Scala](https://habr.com/ru/companies/tinkoff/articles/736056/). Подробнее об использовании контейнеров для обработки эффектов можно узнать из оригинальных работ Евгения Могги [Notions of computation and monads](https://www.cs.cmu.edu/~crary/819-f09/Moggi91.pdf) и [Monads and Effects](file:///C:/Users/sviri_k9k74mq/Downloads/monadsandeffectsfinal.pdf), или на основанной на них статье Бартоша Милевски [Monads and Effects](https://bartoszmilewski.com/2016/11/30/monads-and-effects). Другая фундаментальная статья – [The marriage of effects and monads](https://homepages.inf.ed.ac.uk/wadler/papers/effectstocl/effectstocl.pdf) от Филиппа Вадлера и Питера Тиманна.

<anchor>mtl</anchor>
### Монадные трансформеры

Контейнерный тип позволяет комбинировать вычисления с каким-либо эффектом. Однако шаги вычислений бывают носителями *разных* эффектов, соответственно для их композиции нужно использовать контейнер, позволяющий работать со всеми эффектами, порождаемыми этими вычислениями. Придётся ли вручную реализовывать возможности таких комбинированных контейнеров, или их можно вывести, имея простые контейнеры для базовых эффектов?

Очевидный путь для организации обработки (двух) разных эффектов заключается во вложении одного контейнера в другой:
```scala
  type  F[+X]           // полноценный контейнер со всеми возможностями
  type  G[+X]           // и ещё один
  type FG[+X] = F[G[X]] // комбинация контейнеров
```
Будет ли новый тип “контейнерным”? Согласно данному в этой статье определению контейнера через ковариантность – безусловно да. В библиотеке Cats есть класс [Nested](https://typelevel.org/cats/datatypes/nested.html) вида $((\star\Rightarrow\star),\;(\star\Rightarrow\star),\,\star)\Rightarrow\star$ , с уже реализованной возможностью `map` для вложенных контейнеров:
```scala
import cats.syntax.all.*
import cats.data.Nested

val listOptInt: List[Option[Int]] = List(Some(2), Some(1), None)

Nested(listOptInt)
  .map(_ * 2) // умножаем на 2 всё непустые элементы списка
  .value      // List(Some(4), Some(2), None)
```

К сожалению, `Nested` не умеет комбинировать “эффективные” функции – для него нет возможности “разматрёшивания” `flatten: F[F[X]] => F[X]`, которая для вложенного контейнера `FG` из примера выше будет выглядеть так
```scala
def flattenFG[X]: F[G[F[G[X]]]] => F[G[X]]
```
Теоретически, функцию `flatten` можно сконструировать для любого контейнера, но ввиду того, что количество потенциальных комбинаций эффектов неограниченно, было бы здорово уметь собирать такую функцию *автоматически* из возможностей имеющихся контейнеров. Например, если в `flattenFG` переставить местами средние контейнеры `F[G[F[G[X]]]] => F[F[G[G[X]]]]`, останется только “разматрёшить“ `F` и `G`. То есть нужно отношение (которое почему-то называют [дистрибутивным законом](https://en.m.wikipedia.org/wiki/Distributive_law_between_monads)) вида
```scala
def swapGF[X]: G[F[X]] => F[G[X]]
```
Проблема заключается в том, что реализовать автоматичекую перестановку для *произвольных* контейнеров `F` и `G` не получается – в общем случае *контейнеры не коммутируют* (см. статью Тони Морриса: [Monads do not compose](https://blog.tmorris.net/posts/monads-do-not-compose/)).

Тем не менее, есть несколько полезных контейнеров, которые всегда можно “протащить на верх” композиции с любым другим контейнером. Это означает, что для каждого такого частного случая можно *трансформировать* произвольный контейнер в новый, обогащённый контекстом для работы с дополнительным эффектом. Значит, нам нужны новые типы – контейнерные *трансформеры* 🤖, который обычно называются **монадными трансформерами**, так как они “сохраняют” возможность `flatten`, ассоциирующуюся с понятием “монада”.

Контейнерный трансформер представляет собой обобщённый тип вида $(\star\Rightarrow\star)\Rightarrow(\star\Rightarrow\star)$, но чаще встречаются трансформеры дополненные вспомогательными типами: $(\star\Rightarrow\star,\;\star)\Rightarrow\star$. Библиотека Cats предлагает следующте трансформеры:

| Трансформер | Композиция |
| ---- | ---- |
| `OptionT[F[_], A]` | `F[Option[A]]` |
| `EitherT[F[_], A, B]` | `F[A Either B]` |
| `ReaderT[F[_], A, B]` | `A => F[B]` |
| `WriterT[F[_], A, B]` | `F[(A, B)]` |
| `StateT[F[_], A, B]` | `A => F[(A, B)]` |
| `ContT[F[_], A, B]` | `(A => F[B]) => F[B]` |

Трансформеры обогащают контекст исходного контейнера возможностью обработки дополнительных эффектов и сохраняют возможность `flatMap` исходного контейнера для комбинирования “эффективных” функций:
```scala
import cats.data.OptionT
import cats.syntax.all.*

def twiceAndTrice(i: Int) = OptionT(List(Some(i * 2), Some(i * 3)))

OptionT(List(Some(2), Some(1), None))
  .flatMap(twiceAndTrice)  // OptionT(List(Some(4), Some(6), Some(2), Some(3), None))
  .map(_ + 100)            // OptionT(List(Some(104), Some(106), Some(102), Some(103), None))
  .reduceLeftOption(_ + _) // Some(415)
```

К сожалению, контейнерные трансформеры не решают окончательно проблему композируемости контейнеров. Для одних контейнеров можно построить более одного соответствующего ему трансформера, а для других почти не возможно этого сделать. Например, сложности построения трансформера для контейнера `List` прояснили авторы Cats в ответе на частый вопрос [Where is ListT?](https://typelevel.org/cats/faq.html#where-is-listt).

Помимо таких простых трансформеров есть носители и более интересных эффектов. В библиотеке Cats есть, например, такие трансформеры:
- [Fiber](https://typelevel.org/cats-effect/docs/datatypes/fiber) позволяющий производить вычисления параллельно;
- [Resource](https://typelevel.org/cats-effect/docs/std/resource), который открывает доступ к ресурсу, только при попытке его использования (распаковки контейнера) и гарантирует его “освобождение“ сразу после этого;
- [Ref](https://typelevel.org/cats-effect/docs/std/ref), обеспечивающий конкурентный доступ к изменяемым данным.
Библиотека [FS2](https://fs2.io/) предоставляет трансформер `Stream[F[_], A]`, позволяющий работать с потоками данных (в том числе с асинхронными). Возможны и другие трансформеры.

Ещё про монадные трансформеры можно прочесть тут:
- хабр-перевод: [Монадные трансформеры для практикующих программистов](https://habr.com/ru/articles/327030/) статьи Габриэля Петронеллы;
- фрагмент лекции [Трансформаторы монад](https://wiki.livid.pp.ru/students/lambda/lectures/5.html#%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%82%D0%BE%D1%80%D1%8B-%D0%BC%D0%BE%D0%BD%D0%B0%D0%B4) (“*трансформаторы*”, Карл!🤠) из курса [Функциональное и логическое программирование](https://wiki.livid.pp.ru/students/lambda/) на ресурсе Николая Якимова;
- статья [Monad transformers](https://eed3si9n.com/herding-cats/monad-transfomers.html) с ресурса *herding cats* Юджина Йокоты;
- более фундаментальная статья [Combining Monads](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=abd8bfd9dafbbf27c10f4044c784198bfab99163) Девида Кинга и Филиппа Вадлера.

Чаще всего трансформеры используются для надстройки контейнеров побочных эффектов, вроде `Future` или `IO`. Если необходимо использовать более одного трансформера, то это может вызвать определённую боль, которую можно попробовать полечить, например, с помощью библиотеки [Cats-MTL](https://typelevel.org/cats-mtl/getting-started.html). Другое решение предлагает библиотека [ZIO](https://zio.dev/) ([тут](https://scalac.io/zio/) красочная реклама) – одноимённый тип позиционируется как *универсальный контейнер*, у которого имеются возможности для работы со всеми нужными эффектами. Этот тип *очень упрощённо* можно представить как применение к `IO` сразу двух трансформеров: `ReaderT` для инъекции зависимостей и `EitherT` для управления обработкой ошибок:
```scala
type ZIO[R, E, X] = R => IO[E Either X] 
//                = ReaderT[[A] =>> EitherT[IO, E, A], R, X]
```
Авторы библиотеки утверждают, что контейнер `ZIO` (в совокупности “ресурсами“ и “потоками” оттуда же, а также многочисленными интеграциями с другими библиотеками) предоставляет все необходимые возможности для комфортной “чистой” работы с эффектами, и не требует дополнительного применения трансформеров, или классов типов, вроде тех, что предлагает библиотека Cats.

<anchor>container_programming</anchor>
## Контейнеры как фундамент для разработки

В этом разделе будет продемонстрировано, как на основе обобщённых типов-контейнеров реализуются различные ФП-техники “чистого” построения “эффективных” программ. Сложные приложения декомпозируются на модули поменьше, которые традиционно называются сервисами, а в функциональной парадигме такие *обобщённые* сервисы часто называют “алгебрами”. Ключевой задачей является реализация высокоуровневых сервисов (в том числе и всей программы) посредством построения композиции вычислений из функций от других сервисов. Но, прежде всего, необходимо построить иерархию зависимостей сервисов и выбрать механизм их предоставления при реализации логики приложения.

<anchor>traditioal_di</anchor>
### Традиционный подход

Пожалуй, самым простым способом работы с зависимостями является их игнорирование, когда логика реализуется “в лоб” в статических методах. Термин “зависимости” в этом случае вообще не актуален – доступ к сторонним методам “импортируется” из других модулей, причём, зачастую, в самом начале файле, без привязки к целевому методу.

При функциональном подходе “сервисы” являются неизменяемыми, и их допустимо реализовывать в объектах-одиночках, не задумываясь о внедрении зависимостей. Это соответствуют идее “отказа от зависимостей”, когда они как эффекты обрабатываются в самом конце программы, а не в начале. Но, например, от зацикливания зависимостей такой подход не защищает. Более того, такой подход нарушает принцип “[инверсии зависимости](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B8%D0%BD%D1%86%D0%B8%D0%BF_%D0%B8%D0%BD%D0%B2%D0%B5%D1%80%D1%81%D0%B8%D0%B8_%D0%B7%D0%B0%D0%B2%D0%B8%D1%81%D0%B8%D0%BC%D0%BE%D1%81%D1%82%D0%B5%D0%B9)”, внося в код излишнюю связность, что в свою очередь приводит к нарушению более важно принципа “[открытости/закрытости](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B8%D0%BD%D1%86%D0%B8%D0%BF_%D0%BE%D1%82%D0%BA%D1%80%D1%8B%D1%82%D0%BE%D1%81%D1%82%D0%B8/%D0%B7%D0%B0%D0%BA%D1%80%D1%8B%D1%82%D0%BE%D1%81%D1%82%D0%B8)” и, как следствие, издержкам в сопровождении этого кода.

В ООП хорошим тоном считается описание сервиса в виде абстрактного класса (`trait` в Scala), классы-реализации которого принимают другие сервисы-зависимости в своём конструкторе:
```scala
trait Service1 { def func1(d: Double): Int    }
trait Service2 { def func2(i: Int)   : String }
trait Service3 { def func3(d: Double): String }

// "инъекция" зависимостей через конструктор
final case class Service3Impl(srv1: Service1, srv2: Service2) extends Service3:
  override def func3(d: Double) = srv2.func2(srv1.func1(d))
```
В реализации `Service3` используется композиция возможностей `func1` и `func2` сервисов `Service1` и `Service2`. Но чтобы выполнить эту композицию, необходимо *сперва* представить экземпляры сервисов-зависимостей:
```scala
val srv1: Service1 = ???
val srv2: Service2 = ???

val srv3: Service3 = Service3Impl(srv1, srv2)
srv3.func3(4.2)
```

При большом количестве сервисов со сложной многоуровневой иерархией такой наивный подход приводит к “вскипанию” кода со всеми сопутствующими проблемами. В Scala для упрощения такого рода инъекций используют библиотеку [MacWire](https://github.com/softwaremill/macwire) – макросы автоматически генерируют вызов конструкторов, а также рекурсивно ищут и подставляют в конструкторы значения уже их зависимостей. Если же вдруг какая-то зависимость не найдена, об этом становится известно на этапе компиляции.

Во многих других языках стандартным решением является использование *[DI-контейнеров](https://habr.com/ru/articles/350708/#start_DI_containers)* (dependency injection container). Туда предварительно регистрируются классы-реализации сервисов, а в дальнейшем, на *запрос по типу* какого-либо верхнеуровневого сервиса, контейнер сам сконструирует этот экземпляр, используя все найденные зависимости (и зависимости этих зависимостей, и т.п.). Особенностью многих DI-контейнеров является возможность управлять созданием и временем жизни экземпляров сервисов. Например, можно потребовать, чтобы сервисы создавались при каждом запросе к контейнеру, или единственный раз при первом обращении. Также зачастую DI-контейнеры защищают от зацикливания зависимостей.

Проблема большинства DI-контейнеров заключается в том, что проверка наличия всех необходимых зависимостей в иерархии производится *в процессе выполнения*. Значит остаётся вероятность, что ошибки, связанные с зависимостями, сможет обнаружить только конечный пользователь.

В Scala в качестве DI-контейнера могут выступать *контекстные абстракции*. Механизм *вывода термов* позволяет явно или неявно извлекать из контекста экземпляры нужного типа:
```scala
given Service1 = new Service1 { override def func1(d: Double) = ??? }
given Service2 = new Service2 { override def func2(i: Int   ) = ??? }

object Service3:
   def instance(using srv1: Service1, srv2: Service2) = Service3Impl(srv1, srv2)

Service3.instance.func3(4.2)
```
В последней строчке при обращении к `instance` будут найдены в контексте и неявно переданы как аргументы экземпляры сервисов `Service1` и `Service2`, так как в определении функции эти аргументы указаны с ключевым словом `using`. Если же по какой-либо причине в момент вызова `instance` контекст не будет содержать значения нужных типов, то компилятор выдаст ошибку – проверка корректности иерархии зависимостей осуществляется средствами языка на этапе компиляции, причём без использования макросов!

> Далее будут рассмотрены техники, основанные на контейнерных типах, но ради справедливости стоит упомянуть ещё одну, известную под названием [Cake pattern](https://www.baeldung.com/scala/cake-pattern). В этом подходе сервисы-зависимости описываются как трейты с уже реализованными методами, а непосредственно инъекция в верхнеуровневый сервис осуществляется посредством расширения этого сервиса теми самыми трейтами. Cake-pattern базируется на полиморфизме подтипов, но для него не требуются использовать обобщённые типы, поэтому в данной статье не будет подробностей об этом. Кроме того, такой подход имеет ряд принципиальных недостатков (см., например, статью [Cake antipattern](https://kubuszok.com/2018/cake-antipattern/ "Cake antipattern")), и в настоящее время его использование не рекомендуется.

Помимо построения иерархии зависимостей компонентов приложения, нужно также решить задачу композиции предоставляемых ими функций. Тривиальное решение из примера выше оказывается недостаточным, если нужна более оптимальная работа с потоками вычислений, “чистая” работа с эффектами и т.п. Тут выручают контейнерные типы с соответствующим образом реализованными контейнерными возможностями.

В Scala таким контейнером эффектов, в первую очередь, являлся встроенный `Future`. Он позволяет распределять вычисления по отдельным потокам, тем самым снижая потребление ресурсов компьютера. Но его “жадный” характер снижает возможности статической проверки корректности программы. Эту проблему могут решить такие “ленивые” контейнеры, как `IO` из [Cats](https://typelevel.org/cats/), `ZIO` из [одноимённой библиотеки](https://zio.dev/), `Task` из чуть менее популярной библиотеки [Monix](https://monix.io/).

На практике наиболее востребованы такие возможности, которые позволяют комбинировать эффективные функции. По этому представленные ранее контейнерные возможности часто комбинируются в более сложных классах типов, что-то вроде таких:
```scala
type Functor    [F[_]] = [A, B] =>  (A =>   B)  => (F[A] => F[B]) // Lift
type Applicative[F[_]] = [A, B] => F[A =>   B]  => (F[A] => F[B]) // Lift & Zip2
type Monad      [F[_]] = [A, B] =>  (A => F[B]) => (F[A] => F[B]) // Lift & Flatten
```
Такая запись показывает схожесть этих возможностей, нацеленность их на комбинирование различных эффектов, объединённым одним контейнером `F[_]`. В частности, `Applicative` отвечает за независимое вычисление эффектов, в то время как `Monad` – за последовательное. Это, например, означает, что при комбинировании посредством `Monad` вычисления выстраиваются в цепочку, и сбой в любом звене приведёт к её разрыву, и остальные вычисления не будут выполнены. Вот типичный фрагмент программы на базе контейнера `IO`:
```scala
import cats.effect.IO
import cats.syntax.all.*
//                                                реализации шагов не важны
def findTheKeys:        Clue          => IO[Keys]  = ???
def obtainPart1:        Keys          => IO[Part1] = ???
def obtainPart2:        Keys          => IO[Part2] = ???
def completeThePuzzle: (Part1, Part2) => Treasure  = ???

def findTheTreasure(someClue: Clue) =
  findTheKeys(someClue)
    .flatMap(keys => obtainPart1(keys) product obtainPart2(keys)) 
    .map(completeThePuzzle.tupled)
```
Возможности комбинирования здесь предоставляются реализациями классов типов для контейнера `IO`:
- `map` $\Leftarrow$ `Functor`,
- `product` $\Leftarrow$ `Applicative`,
- `flatMap` $\Leftarrow$ `Moand`.

В каких-то командах разработки предпочитают более императивный стиль, основанный на использовании `for`-выражений:
```scala
def findTheTreasure(someClue: Clue) =
  for {
    keys  <- findTheKeys(someClue)
    part1 <- obtainPart1(keys)
    part2 <- obtainPart2(keys)
  } yield completeThePuzzle(part1, part2)
```
`For`-выражения представляют собой “синтаксический сахар”, который на этапе предкомпиляции раскрывается в цепочку вызовов тех же `map`, `flatMap`. Например, вызов `map` спрятан здесь в последней строчке с `yield`, а возможности `Applicative` вообще не задействованы – вместо этого используется дополнительный вызов `flatMap` и, если не удастся получить `part1`, то вычисление `part2` даже не начнётся.

Какой бы стиль ни был выбран, основная суть традиционного подхода остаётся прежней – зависимости инъектируются (зачастую, неявно) в конструкторы классов, в методах которых используются обобщённые контейнерные типы для более удобной (и, по возможности, чистой!) композиции эффективных вычислений. Использование вывода термов для инъекции зависимостей и возвращение значений в контейнере `Future/IO`/`ZIO`/`Task` выглядят как минимальный набор для построения Scala-программы. Но иногда встречаются задачи, требующие более сложных решений. Далее будут рассмотрены несколько таких примеров.

<anchor>reader</anchor>
### “Читатель”

Вычисление зависимостей и передача их в бизнес-логику является типичным шаблонном, просматривающимся во всех фрагментах приложения. Это не основная, а *вспомогательная сквозная логика*, на которой не стоило бы акцентировать внимание. А ведь именно и происходит в ОПП-шной инъекции зависимостей, когда сервисы вычисляются и передаются функциям *перед* их вычислением. Перенести всю возню с зависимостями в самый конец вычислений помогает шаблон “читатель” (reader).

Давайте снова вернёмся к сценарию “избавления от зависимости”, упомянутому в самом начале статьи. Вот типичный ООП-шный класс, принимающий в конструктор сервис-зависимость:
```scala
trait Dep
final case class ServiceImpl(dep: Dep):
  def func(d: Double): String = ???
```
Зависимость `dep: Dep` передаётся в конструктор класса только для того, чтобы её можно было использовать при реализации его функций. Иначе говоря, класс – это лишь набор функций, для которых *сперва* должны быть предоставлены все зависимости как параметры. Выразим это утверждение явно на примере одной функции и произведём пару манипуляций:
```scala
def func_1(dep: Dep)(d: Double)    =  ???
//  ⇓⇓⇓⇓⇓⇓ вследствие алгебраического изоморфизма типов (Aᴮ)ᴰ ≡ (Aᴰ)ᴮ
def func_2(d: Double)(dep: Dep)    =  ???
//  ⇓⇓⇓⇓⇓⇓ можно считать, что это просто иная запись func_2
def func_3(d: Double) = (dep: Dep) => ???
```
Функция `func_3`, принимая значение `Double` возвращает *другую функцию* от значения `Dep`. Теперь вычисление функции `func_3` *не требует предварительной передачи зависимости* `Dep`:
```scala
val packedRes = func_3(4.2)  // Dep => Srting
```
И только после этого подставляются зависимости:
```scala
val dep = new Dep{}
val finalRes = packedRes(dep) // String
```
Основная логика приложения никак не изменилась, но с помощью простых алгебраических изоморфизмов типов получилось вынести упомянутую ранее вспомогательную логику по вычислению и передаче зависимостей в самый конец!

Выразим явно обобщённый тип результата `func_3`:
```scala
type Reader[D] = [A] =>> D => A
type ReaderDep[A] = Reader[Dep][A]
def func_3(d: Double): ReaderDep[String] = ???
```
Обобщённый тип `Reader` основан на стандартном функциональном типе Scala, который, очевидно, является контейнерным по типу результата. Для него уже реализованы “контейнерные” возможности `map`, `flatMap`, следовательно, можно стоить композиции функций вида `func_3`, возвращающих значения в контейнере `ReaderDep[_]`.

Тип `Reader` сам по себе не решает задачу композиции эффективных вычислений. Но тут выручает основанный на нём трансформер:
```scala
type ReaderT[F[_], D] = [A] =>> Reader[D][F[A]] // D => F[A]
```
Контейнер `F[_]` является носителем произвольных эффектов, а трансформер над ним транслирует возможности комбинирования эффективных функций.

В библиотеке Cats похожим образом определён тип `ReaderT`. Особенности реализации его контейнерных возможностей требуют, чтобы у комбинируемых функций были “зависимости” одного и того же типа (в примере выше это `trait Dep`). Для этого иногда посредством наследования (расширения) строится общий тип, объединяющий все возможные зависимости комбинируемых функций, выбирается контейнер эффектов и на этой основе строится свой:
```scala
import cats.data.ReaderT                    // импортируется трансформер
import cats.effect.IO                       // импортируется какой-то контейнер эффетов

trait Dep1; trait Dep2                      // исходные сервисы-зависимости
type TotalDep = Dep1 & Dep2                 // общая "жирная" зависимость как пересеченеи типов
type ReaderIO[A] = ReaderT[IO, TotalDep, A] // итоговый контейнер
```
Необходимость ручного построения такой “жирной зависимости” ограничивает разработку приложения. Альтернативой может быть множественное “наслоение” `ReaderT`, распаковка которого потребует точно соблюдения порядка передачи зависимостей.

Более удобное решение предлагает вторая версия библиотеки ZIO. Как уже упоминалось ранее, одноимённый контейнер может интерпретироваться как применение трансформера `ReaderT`. Например, построим функцию, реализация которой зависит от сервисов `Dep1` и `Dep1`:
```scala
def func(d: Double) = for {
  dep1 <- ZIO.service[Dep1]
  dep2 <- ZIO.service[Dep2]
} yield (??? : String) // тут используются d, dep1, dep2
```
Её можно вызвать сразу:
```scala
val packedRes = func(4.2) // ZIO[Dep1 & Dep2, Nothing, String]
```
Как и с контейнером `ReaderT`, зависимости можно предоставить в дальнейшем:
```scala
val dep1Layer = ZLayer.succeed(new Dep1{}) 
val dep2Layer = ZLayer.succeed(new Dep2{})

val zioRes = packedRes.provide(dep2Layer, dep1Layer) // ZIO[Any, Nothing, String]
```
Итоговое значение `zioRes` уже не имеет зависимостей, оно лишь упаковано в контейнер эффектов, аналогичный `cats.IO[_]`.

Особенностью такого подхода является то, что зависимости могут быть предоставлены *в произвольном порядке* и не обязательно одновременно. “Слои” (layers) намекают на то, что иерархия зависимости может быть дополнительно структурирована.

Итак, шаблон “читатель” переносит предоставление зависимостей на финальный этап вычислений. На первоначальном этапе  остаётся построение функции, принимающей эти зависимости. Стоит заметить, что таким способом первый этап можно сделать “чистым”, без побочных эффектов. Схожими особенностями обладают и другие “контейнерные” подходы, представленные далее – сперва идёт “чистое” построение композиции вычислений внутри некого контейнера, и лишь в самом конце при распаковке требуются реализации зависимостей.

<anchor>free</anchor>
### Свободный контейнер

Рассмотрим такой обобщённый тип:
```scala
enum Freee[F[_], A]:
  case Pure   [F[_], A](a: A)              extends Freee[F, A]
  case Suspend[F[_], A](a: F[Freee[F, A]]) extends Freee[F, A]
```
Утверждается, что типы `Freee[F, A]` и `F[A]` изоморфны для любых `A` и ковариантного `F[+_]`. Доказательство утверждения, как и само происхождение этого *рекурсивного* типа выходит за рамки данной статьи, здесь мы изучим лишь некоторые его свойства.

Имея возможность `map` для `F[_]`, можем "поднять" её и до `Freee`, например, добавив этот метод в `enum`:
```scala
def map[B](f: A => B)(using Lift[F]): Freee[F, B] = this match // this: Freee[F, A] - мы же внутри enum
  case Pure(a)     => Pure(f(a))
  case Suspend(fa) => Suspend(fa.map(_.map(f)))
```
Здесь использован класс контейнерных типов `Lift`, введённый в этой статье ранее – он позволяет вызвать `map` для `fa` в последней строчке.

Но гораздо интереснее то, как мы можем определить “разметрёшивание” `Freee`:
```scala
import Freee.*
extension [F[_]: Lift, A](ffa: Freee[F, Freee[F, A]])
  def flatten: Freee[F, A] = ffa match
    case Pure(fa) => fa
    case Suspend(a) => Suspend(a.map(_.flatten))
```
Обратите внимание на то, что наличие возможностей контейнера `F[_]` вроде `flatten`, или `flatmap` не требуется. Получается что, ввиду заявленного изоморфизма с `F[_]`, `Freee` *обогащает* исходный ковариантный контейнер возможностью “разматрёшивания”!

Примеры использования будут далее, а сейчас попробуем попробуем избавится от назойливого требования `F[_]: Lift`, которое необходимо для композиции вычислений посредством `Freee`. Оказывается, для этого достаточно в тип-сумму `Freee` добавить ещё одно слагаемое, получив “более свободный“ контейнер `Freer`:
```scala
enum Freer[F[_], A]:
  case Pure   [F[_], A](a: A)                                      extends Freer[F, A]
  case Suspend[F[_], A](a: F[Freer[F, A]])                         extends Freer[F, A]
  case FlatMap[F[_], A, B](fb: Freer[F, B], afb: B => Freer[F, A]) extends Freer[F, A]

import Freer.*

extension [F[_], A](ffa: Freer[F, A])
  def map[B](f: A => B): Freer[F, B] = FlatMap(ffa, f andThen Pure.apply)
  def flatMap[B](f: A => Freer[F, B]): Freer[F, B] = FlatMap(ffa, f)

extension [F[_], A](ffa: Freer[F, Freer[F, A]])
  def flatten: Freer[F, A] = FlatMap(ffa, identity)
```
Теперь можно строить композицию вычислений с носителем эффектов `F`, при этом даже не ожидая, что для него предоставлены контейнерные возможности! Распаковку `Freer` можно реализовать так:
```scala
extension [F[_], A](ffa: Freer[F, A])
  def go(extract: [X] => F[Freer[F, X]] => Freer[F, X])(using Lift[F]): A =
    ffa match
      case Pure(fa)         => fa
      case Suspend(ffa)     => extract(ffa) go extract
      case FlatMap(fb, bfa) => bfa(fb go extract) go extract
```
В чём же выгода, если для распаковки `Freer` всё равно потребуются контейнерные возможности `F`? Хитрость заключается в том, что распаковаться можно в совсем другой контейнер! Такая функция, зачастую, называется `foldMap` и требует контейнерные возможности для нового контейнера `G[_]`; позаимствуем их из класса типов `cats.Monad`:
```scala
import cats.Monad
import cats.syntax.all.*

extension [F[_], A](ffa: Freer[F, A])
  def foldMap[G[_]: Monad](fToG: F ~> G): G[A] = ffa match
    case Return(a)      => Monad[G].pure(a)                            // pure    из Monad[G]
    case Suspend(ma)    => fToG(ma).flatMap(_ foldMap fToG)            // flatMap из Monad[G]
    case FlatMap(fa, f) => fa.foldMap(fToG).flatMap(f(_) foldMap fToG) // flatMap из Monad[G]
```
Это полностью освобождает от ограничений на `F[_]` – можно использовать *произвольные* обобщённые типы в качестве описания бизнес-эффектов. Остаётся лишь в самом конце предоставить “естественные“ преобразования `~>` из этих бизнес**о**вых контейнеров в универсальные, вроде `IO`. Класс `Free[F[_], _]` представляет собой контейнерный трансформер, но его не правильно называть “монадным”, как аналогичные типы из раздела выше, потому что в качестве `F[_]` он принимает *любой* контейнер, даже без явных “монадных” возможностей, вроде `flatMap` – вообще *никакие ограничения на исходный контейнер не накладываются*!

Реализация “более свободного” контейнера `Freer` присутствует в библиотеке Cats под именем [Free](https://typelevel.org/cats/datatypes/freemonad.html). Разберём его особенности на примере композиции таких элементов (чистое значение и функция):
```scala
val initVal: Future[Int] = Future.successful(21)
def effeciveFunc(i: Int)(using ExecutionContext): Future[Int] =
  Future {
    val intRes = i * 2
    println(s"$i => $intRes")
    intRes
  }
```

Соберём из них простенькую программу, “подняв” исходные элементы, определённые через контейнер `Future[_]`, в “мир” трансформированного контейнера `Free[Future, _]` из библиотеки Cats с помощью функции `Free.liftF`:
```scala
val freeInitVal      = Free.liftF(initVal)             // поднимаем значение
val freeEffeciveFunc = effeciveFunc andThen Free.liftF // поднимаем функцию (у liftF есть нужная перегрузка)
def buildFreeProgram(using ExecutionContext): Free[Future, Int] =
  freeInitVal
    .flatMap(freeEffeciveFunc)
    .flatMap(freeEffeciveFunc) // просто по-приколу, вызываем ту же функцию ещё раз
```
Для `Free` конечно же реализованы ключевые возможности контейнеров, позволяющие строить композицию “эффективных” вычислений, и пока не заметно отличий от исходного контейнера `Future` . Они проявятся позднее, когда будет вызвана функция `freeProgram` и произведена “распаковка” результата.

 Для распаковки можно воспользоваться методом `def go(f: S[Free[S, A]] => Free[S, A])(implicit S: Functor[S]): A`:
```scala
given ExecutionContext = ExecutionContext.global
import cats.instances.future.catsStdInstancesForFuture // импорт неявного Functor[Future]

def extractFuture[A]: Future[A] => A =
  Await.result(_, Duration.Inf)

val freeProgram = buildFreeProgram // "конструируем" программу

// и выполняем её вычисление (распаковку) дважды:
val res1 = freeProgram go extractFuture // (using Functor[Future]), так как "под капотом" нужен map
val res2 = freeProgram go extractFuture // (using Functor[Future]), так как "под капотом" нужен map
print(res1, res2)
```
Выполнение этого кода приведёт к такому выводу на консоль:
```
21 => 42
42 => 84
21 => 42
42 => 84
(84,84)
```
Не смотря на то, что контейнер `Future` является “жадным”, трансформаця с помощью в `Free` даёт “ленивый” контейнер, как представленный ранее `IO` – все внутренние вычисления откладываются на этап распаковки. Именно поэтому все побочные эффекты (вывод на консоль строчек вида `x => y`) сработали дважды – при распаковке в переменные `res1` и `res2`. Для распаковки `Free` требуются возможности *вложенного* контейнера. В примере выше это `extractFuture: Future[A] => A` и `map` из неявного значения класса типа `Functor[Future]`, предоставляемого библиотекой Cats.

Более интересен второй способ распаковки, основанный на `foldMap`:
```scala
def extractFuture[A]: Future[A] => A =
  Await.result(_, Duration.Inf)

val interpreter: Future ~> Id =           // "естественное" преобразование контейнеров
  FunctionK.lift{ [X] => (fx: Future[X]) => extractFuture(fx) }

val res = freeProgram foldMap interpreter // неявно используется Monad[Id] для flatMap, который
println(res)                              // нужен для ленивой хвостовой рекурсии
```

Такая особенность трансформера `Free` позволяет использовать элегантный трюк для декомпозиции бизнес-логики приложения на отдельные блоки. Ранее уже упоминалось, что с контейнерным типом можно связать те или иные эффекты. Эффекты завязаны не столько на устройстве самого обобщённого типа (какие поля и как именно размещены в памяти), сколько на реализацией его “контейнерных функций” – запаковки, внутренних преобразований, перепаковки в другие контейнеры и, в частности, распаковки. Это даёт возможность строить *чистую композицию эффективных вычислений*. Но трансформер `Free` позволяет достичь того же результата с контейнерами, для которых эти возможности даже не заданы изначально, а следовательно, и эффекты не определены. Их, конечно, придётся конкретизировать для распаковки `Free`, но до этого момента исходный контейнер считается совершенно абстрактным. Иными словами, **свободный контейнер позволяет абстрагироваться от эффектов**.

Рассмотрим следующий пример. Допустим, нужно описать функции взаимодействия с репозиторием пользователей. Используя эти типы
```scala
type UserId    = Int
type UserInfo  = String
type UserSaved = Unit
```
нужно определить операции
```scala
type GetUser = UserId => Option[UserInfo]
type PutUser = (UserId, UserInfo) => UserSaved
type ListAll = Unit => List[(UserId, UserInfo)]
```
Проблема в том, что такие функции не могут быть “чистыми”, так как они работают с изменчивым состоянием хранилища – это “эффективные” функции. Чтобы сделать их “чистыми”, они должны возвращать результат в некотором контейнере, чья “распаковка” вызывала бы срабатывание соответствующих эффектов. Традиционно такие функции реализуются через соотношение подтипизации для слагаемых обобщённого алгебраического типа:
```scala
enum UsersRepository[A]:
  case Get(id: UserId)                 extends UsersRepository[Option[UserInfo]]
  case Put(id: UserId, user: UserInfo) extends UsersRepository[UserSaved]
  case ListAll                         extends UsersRepository[List[(UserId, UserInfo)]]
```
Контейнерный тип `UsersRepository[_]` соответствует эффекту работы с репозиторием, но не имеет ничего, кроме функций неявно приведения к себе от своих подтипов-слагаемых. Он является носителем *абстрактного эффекта*.

Для удобства композиции вычислений, часто вводятся вспомогательные функции, своего рода *синтаксический ~~мусор~~ сахар*:
```scala
import UsersRepository.*
type FreeUsersRepo[X] = Free[UsersRepository, Option[UserInfo]] // псевдоним для наглядности
def liftUserRepo = cats.free.Free.liftK[UsersRepository]        // UsersRepository ~> FreeUsersRepo

def getUser(id: UserId)                : FreeUsersRepo[Option[UserInfo]] = liftUserRepo(Get(id))
def putUser(id: UserId)(user: UserInfo): FreeUsersRepo[Unit]             = liftUserRepo(Put(id, user))
def listUsers                          : FreeUsersRepo[List[UserInfo]]   = liftUserRepo(ListAll)
```
Аннотации типов излишни. Они лишь подчёркивают, что функции возвращают значения в *свободном* контейнере над трансформированным `UsersRepository`. Из этих “освобождённых” функций можно построить композицию для реализации произвольной бизнес-логики:
```scala
import cats.syntax.all.*
val program = // FreeUsersRepo[List[(UserId, UserInfo)]]
  putUser(42)("answer") >>
  listUsers
```
Здесь `>>` – это лишь псевдоним из Cats для `flatMap`, в котором игнорируется аргумент (“произведение эффектов”, при котором учитывается только “правый“ результат). Переменная `program` содержит описание композиции функций с неизвестным ещё эффектом. Чтобы эту программу “запустить”, нужно знать, как *интерпретировать* исходный абстрактный контейнер `UsersRepository`, как преобразовать его к другому контейнеру с учётом специфичных эффектов:
```scala
import cats.arrow.FunctionK.{lift as liftTransform}
import cats.{Id, ~>}
import scala.collection.mutable.{Map as MutMap}

val usersRepoInterpreter: UsersRepository ~> Id = {
  val storage = MutMap.empty[UserId, UserInfo]
  liftTransform{[A] => (fa: UsersRepository[A]) =>
    {fa match
      case Get(id)       => storage.get(id)
      case Put(id, user) => storage.addOne(id, user)
      case ListAll       => storage.toList
    }.asInstanceOf[A] // а ведь компилятор и сам мог бы догадаться...
  }
}

program foldMap usersRepoInterpreter // List((24,rewsna), (42,answer))
```

Здорово! Но в настоящей программе приходится работать с разными эффектами одновременно. К примеру, добавим ещё такие:
```scala
enum SearchServcie[A]:
  case SearchBest (request: String) extends DataServcie[String]
  case FindSeveral(request: String) extends DataServcie[List[(Relevance, String)]]

enum NotificationService[A]:
  case Send(notification: String) extends NotificationService[NotificationResult]
```
Теперь для построения композиции нужно “освободить” контейнер, который сочетал бы все эти эффекты. Для этого библиотека Cats предлагает тип [EitherK](https://typelevel.org/cats/api/cats/data/EitherK.html) вида $(\star\Rightarrow\star,\;\star\Rightarrow\star,\;\star)\Rightarrow\star$. Это не просто трансформер контейнеров, но их *комбинатор*. С его помощью можно сформировать контейнер для всех эффектов:
```scala
import cats.data.EitherK
type :+:[F[_], G[_]] = [A] =>> EitherK[F, G, A] // лево-ассоциативный оператор над типами-контейнерами
type TotalAlgebra[A] = (
  UsersRepository     :+:
  SearchServcie       :+:
  NotificationService
)[A]
```
Лево-ассоциативные операторы, вроде введённого тут `:+:` заметно упрощают работу со свободными контейнерами. Аналогичное решение, а также другие плюшки для работы со свободными контейнерами встречаются в различных библиотеках, например, [Freek](https://github.com/ProjectSeptemberInc/freek/tree/master).

Контейнеры, подобные представленному выше `TotalAlgebra`, действительно иногда называются “алгебрами” над типом-параметром, потому что, как и в академической математике, они описывают N-арные операции для переменных разных типов, в том числе и типа-параметра (даже если операция только возвращает значение этого типа).

“Сахарные” функции нужно теперь поднимать до `TotalAlgebra`:
```scala
import SearchServcie.*
import NotificationService.*

def liftF = cats.free.Free.liftInject[TotalAlgebra]

def searchBest      (request: String)            = liftF(SearchBest (request))
def findSeveral     (request: String)            = liftF(FindSeveral(request))
def sendNotification(notification: Notification) = liftF(Send(notification))
```
Конечно, также придётся переписать аналогичные функции для `UsersRepository`. Функция `liftInject` принимает неявный параметр типа `InjectK[Big[_], Small[_]]`, который, по сути, предоставляет “естественное” преобразование от контейнера `Small` к `Big`. В библиотеке Cats уже есть неявные значения `InjectK` с комбинатором `or` для контейнеров, связанных посредством `EitherK`.

Подготовив аналогично `usersRepoInterpreter` интерпретаторы `dataServcieInterpreter` `notificationInterpreter` можно собрать полный с помощью `or` (важно соблюсти порядок комбинации контейнеров в `TotalAlgebra`):
```scala
def searchServcieInterpreter: SearchServcie       ~> Id = // какая-то реализация
def notificationInterpreter : NotificationService ~> Id = // какая-то реализация

extension[F[_], G[_]](fg: F ~> G)
  def :+:[H[_]]      (hg: H ~> G) = fg or hg // лево-ассоциативный синоним для or

def totalInterpreter =
  usersRepoInterpreter     :+:
  searchServcieInterpreter :+:
  notificationInterpreter
```
И теперь можно писать уже вот такие *большие* программы 😉:
```scala
val littleBigProgram =
  searchBest("best user")           productL
  sendNotification("user captured") flatMap
  putUser(42)                       productR
  getUser(42)                       map
  {_.fold("")(_.reverse)}           flatMap // перворачиваем имя в обратном порядке. Типа, так заказчик захотел)))
  putUser(24)                       productR
  listUsers

littleBigProgram foldMap totalInterpreter
```

Такая техника интересна тем, что позволяет создавать *программы-как-данные*. Единожды собранную программу можно модифицировать и интерпретировать разными способами. Помимо преобразования свободного контейнера в `Id`, полезными бывают также преобразования в  `Either` (для модульных тестов), или всякие ~~`Future` (забудьте)~~ `IO`, `ZIO` (для самого продукта). На практике всё же такая возможность `Free` редко бывает востребованной. Однако, свободные контейнеры используются не только для компоновки больших приложений, но и в некоторых библиотечных инструментах. Например, в библиотеке [doobie](https://tpolecat.github.io/doobie/) есть `type ConnectionIO[A] = Free[ConnectionOp, A]` – надстройка над `ConnectionOp`, обобщённой сумой типов, олицетворяющих различные JDBC-операции.

Вот список дополнительной литературы об устройстве и применении контейнера `Free`.
- Русскоязычные публикации на Хабре:
	- [Scala: Гексагональная архитектура и DDD на Free Monad в функциональном программировании](https://habr.com/ru/articles/655089/) Мухаммада Зунунова.
	- [Чем хороши свободные монады](https://habr.com/ru/articles/254715/) – перевод статьи Габриеллы Гонсалес (Haskell).
- Англоязычные статьи
	- [The debatably Free monad](https://nrinaudo.github.io/articles/free_monad.html) подробное последовательное конструирование контейнера `Free` от Николя Ринаудо.
	- [Free Monad in Scala](https://blog.rockthejvm.com/free-monad/) Даниэля Чокырлана с его ресурса [Rock the JVM!](https://rockthejvm.com/)
	- [Free monads - what? and why?](https://softwaremill.com/free-monads/) Адама Варски.
	- [Free Monads Are Simple](https://underscore.io/blog/posts/2015/04/14/free-monads-are-simple.html) Ноэля Велша.
- Тип `Free[F[_], _]` из библиотеки Cats:
	- [Free Monad](https://typelevel.org/cats/datatypes/freemonad.html) на официальном сайте Type Level;
	- [Free monads](https://eed3si9n.com/herding-cats/Free-monads.html) с ресурса *herding cats* Юджина Йокоты.
- “Более свободный” контейнер Freer:
	- статья Олега Киселёва и Хироми Ишии [Freer Monads, More Extensible Effects](https://okmij.org/ftp/Haskell/extensible/more.pdf);
	- библиотека [eff](https://atnos-org.github.io/eff/) – определённый там трансформер `Eff`, в отличие  от `Free` из Cats, не требует сборки общего интерпретатора – эффекты “свободной” программы можно интерпретировать последовательно, причём в произвольном порядке;
	- ответ на Stackoverflow [Different between Eff monad and Free monad](https://stackoverflow.com/questions/45039766/different-between-eff-monad-and-free-monad);
	- [FreeR - Hybrid Free Monads for Reduced Quadratic Complexity/Observability & Map-Fusion Optimization in Scala](http://mandubian.com/2015/04/09/freer/) - статья в блоге Паскаля Войто;
	- [Extensible Effects in Scala](https://halcat.org/scala/extensible/index.html#freer-monad) – статья из блога Санширо Йошиды (тут вы сможете попрактиковаться в японском языке… или же просто воспользоваться Google-переводчиком).


<anchor>continuations</anchor>
### Продолжения и алгебраические эффекты

В данной статье уже неоднократно упоминалось, что типы целиком определяются отношениями с другими типами, тем, что мы можем сделать, имея данный тип. И для большинства типов важны именно функциональные отношения, возможности *использования его значений*. Наиболее выразительно эту особенность представляет кодирование Чёрча. Типы в кодировке Чёрча представляют собой способы **продолжения** вычислений из состояний, характеризуемых значениями этих типов. 

Допустим, у нас есть некий тип `Type1`. Для его значений доступен набор возможностей вида `Type1 => A` *для некоторых* типов `A`. *Экзистенциальный* характер этого утверждения (“*существуют* такие типы `A`, что…“), отражается в следующей *универсальной* кодировке:
```scala
type Type2 = [A] => (Type1 => A) => A
```
Получаем тип полиморфной функции, принимающей на вход *функцию-продолжения* вычислений из состояния, в котором известно значение типа `Type1`. Типы `Type1` и `Type2` изоморфны: из значений одного типа всегда можно получить значения другого баз потери данных:
```scala
val туда:    Type1 => Type2 = (v: Type1) => [A] => (f: Type1 => A) => f(v)
val обратно: Type2 => Type1 = (v: Type2) => v(identity)

assert((туда    andThen обратно)(t1) == t1) // для любых t1: Type1
assert((обратно andThen туда   )(t2) == t2) // для любых t2: Type2
```
И всё же `Type1` и `Type2` не эквивалентны – более сложная структура второго даёт больше интересных возможностей.

Функциональные типы, аргументы которых представляют собой другие функции, являются характерной чертой особого *стиля передачи продолжений* (continuation passing style – CPS). Это типы-контейнеры, для распаковки которых необходимо конкретизировать, как именно будут *продолжены* вычисления с использованием “хранимого” там значения.

В CPS вызовы продолжений являются [хвостовыми](https://en.wikipedia.org/wiki/Tail_call). Если язык поддерживает [оптимизацию хвостовых вызов](https://stackoverflow.com/questions/310974/what-is-tail-call-optimization) (TCO – tail call optimization), то в сочетании с CPS это может дать прирост производительности. В Scala есть [оптимизация хвостовой рекурсии](https://www.baeldung.com/scala/tail-recursion) (частный случай TCO) и некоторые неочевидные оптимизации для локальных функций.

Полезные CPS-трансформеры для произвольного типа-контейнера, могут иметь весьма нетривиальную структуру. Например, утверждается, что трансформер *коплотности* для контейнера `F[_]` изоморфен этому контейнеру:
```scala
type Codensity = [F[_]] =>> [A] =>> [B] => (A => F[B]) => F[B]
```
Для него также определены все необходимые контейнерные возможности: 
```scala
trait Monad[F[_]]: // важные контейнерные возможности
  val pure:    [A]    => A => F[A]
  val lift:    [A, B] => (A => B) => (F[A] => F[B])
  val flatten: [A]    => F[F[A]] => F[A]
  // map и flatMap строятся из них очевидным образом:
  val map     = [A, B] => (f: A => B) => lift(f)
  val flatMap = [A, B] => (afb: A => F[B]) => (fa: F[A]) => flatten(lift(afb)(fa))
  
given [F[_]]: Monad[Codensity[F]] with
  val pure    = [A]    => (a: A) => [B] => (f: A => F[B]) => f(a)
  val lift    = [A, B] => (ff: A => B) => (coda: Codensity[F][A])  => [C] => (f: B => F[C]) => coda(f compose ff)
  val flatten = [A]    => (codCodA: Codensity[F][Codensity[F][A]]) => [B] => (f: A => F[B]) => codCodA(_ apply f)
```
Не сложно заметить, что также как и для “более свободного” трансформера `Freer`, коплотность позволяет строить композицию эффективных вычислений, *не накладывая никаких ограничений на исходный контейнер*. Но чтобы “поднять” значение из “мира” `F[_]` в “мир” `Codensity[F]` всё же потребуются контейнерные возможности для `F[_]`:
```scala
def rep[F[_]: Monad, A](fa: F[A]): Codensity[F][A] = // неявно тянутся возможности Monad[F]
  [B] => (afb: A => F[B]) => summon[Monad[F]].flatMap(afb)(fa) // Monad[F].flatMap

given Monad[Option] with // контейнерные возможности для Option
  val pure =    [A]    => (a: A) => Some(a)
  val lift =    [A, B] => (f: A => B) => (coda: Option[A]) => coda map f
  val flatten = [A]    => (optOptA: Option[Option[A]]) => optOptA.flatten

val codOptInt: Codensity[Option][Int] = rep(Some(42))
val optInt:              Option [Int] = codOptInt(Some.apply) // Some(42)
```
Таким образом, в отличие от `Freer`, коплотность не позволяет “освободиться” от контейнерных возможностей `F[_]`. Однако взамен мы получаем неплохую компенсацию.

Хорошим примером применения коплотности является концепция *ресурса*, предполагающая следующий цикл вычислений: $$\text{захват ресурса}\Rightarrow\text{использование ресурса}\Rightarrow\text{освобождение ресурса}.$$
В библиотеке Cats есть трансформер [Resource](https://typelevel.org/cats-effect/docs/std/resource), суть которого можно выразить такой конструкцией:
```scala
type Resource = [F[_]] =>> [R] =>> (Unit => F[R], R => F[Unit]) => Codensity[F][R]
//                                 (    accure   ,   release  ) => use with continuation
```
Другими словами, предоставив функции захвата (accure) и освобождения (release) ресурса `R`, получаем функцию, принимающую на вход функцию-продолжение с реализацией использования (use) ресурса, и возвращающую результат этого использования.

Трансформер `Codensity` представляет собой полиморфную функцию, что вызывает определённые неудобства при работе с таким типом. Чаще используется тип `ContT`, представляющий собой такую же функцию, но уже не полиморфную:
```scala
type ContT     = [F[_], A, X] =>> (X => F[A]) => F[A]
type Codensity = [F[_]] =>> [X] =>> [A] => ContT[F][A, X]
```
Трансформер `ContT[F, A, X]` является контейнером для значений `X` и его контейнерные возможности также определяются очевидным образом. С типом `ContT` связана одна очень интересная функция, несколько страшноватого вида:
```scala
def callCC[F[_], A, X, Y]
  : ((Y => ContT[F, A, X]) => ContT[F, A, Y]) => ContT[F, A, Y]
  = f => yfa => f { y => _ => yfa(y) }(yfa)
  //                     ↑↑↑↑↑↑↑↑↑↑↑ игорируем переданное продолжение!
```
Эту функцию “вызова с текущим продолжением” (**call** with **c**urrent **c**ontinuation – callCC) [не получится](https://stackoverflow.com/questions/7178919/how-to-make-callcc-more-dynamic/7180154#7180154) написать для трансформера коплотности. Она позволяет очень гибко управлять потоком вычислений, реализовывать управляющие конструкции, в том числе `goto`, `try/throw/catch/finally`, `async/await` и т.п.

В библиотеке Cats есть [своя реализация трансформера ContT](https://typelevel.org/cats/datatypes/contt.html), и там уже [присутствует](https://www.javadoc.io/static/org.typelevel/cats-docs_2.13/2.10.0/cats/data/ContT$.html) метод `callCC`. На его основе можно построить *метод получения текущего продолжения*:
```scala
def getCC[M[_] : Defer : Monad, R, A]: ContT[M, R, ContT[M, R, A]] = {
  ContT.callCC[M, R, ContT[M, R, A], A] { c =>
    lazy val x: ContT[M, R, A] = ContT.later(c(x).run) // ленивая рекурсия!
    ContT.pure(x)
  }
}
```
Эту реализацию предложил Матеуш Кубужок (ранее уже упоминались публикации из его замечательного [блога](https://kubuszok.com/)), путь к ней он подробно расписал в [этом ответе на Stackoverflow](https://stackoverflow.com/a/78073145/4583514). Метод `getCC` позволяет, например, реализовать ФП-аналог конструкции `goto`:
```scala
def asksLoop =
  for {
    gotoLabel <- getCC[IO, Unit, Unit]
    _         <- ContT.liftF(IO.println("Ходите продолжить? [д/н]"))
    answer    <- ContT.liftF(IO.readLine)
    _ <-      if (answer == "д") gotoLabel
              else               ContT.liftF(IO.unit)
  } yield ()

asksLoop.run(_ => IO.println("Пока!")).unsafeRunSync()
```
В данном случае можно организовать только “переход назад“, но технически возможны и более сложные сценарии, в том числе, и с передачей состояния.

Так же, по следам [другого ответа на Stackoverflow](https://stackoverflow.com/a/6004732/4583514), рассмотрим простой сценарий с использованием `callCC` для обработки ошибок – будем отслеживать деление на 0.
```scala
// вспомогательная функция для удобства
def whenA[F[_], R](b: Boolean)(happyWay: ContT[F, R, Unit]) =
  if (b) happyWay else ContT.pure(())

def div[R](x: Int, y: Int)(handler: String => ContT[IO, R, Int]): ContT[IO, R, Int] =
  ContT.callCC((ok: Int => ContT[IO, R, String]) =>             // "счастливое" продолжение
    ContT.callCC((notOK: String => ContT[IO, R, Unit]) =>       // "несчастливое" продолжение
      whenA(y == 0)(notOK("Нельзя делить на 0 ")) >> ok(x / y)  // выбираем продолжение
    ).flatMap(handler)                                          // обрабатываем "несчастливое" продолжение неизвестным пока методом
  )
val calc1 = div[Unit](10, 2) // : (String => ContT[IO, Unit, Int]) => ContT[IO, Unit, Int]
val calc2 = div[Unit](10, 0) // : (String => ContT[IO, Unit, Int]) => ContT[IO, Unit, Int]
```
В переменных `calc1` и `calc2` лежат функции, принимающие на вход строку, а возвращающие… контейнер, для распаковки которого необходимо передать ещё одну функцию-продолжение… Выражения и так не тривиальны, а типы термов в нём ещё сложнее. Но не всё так плохо 🙂 – далее будут упомянуты библиотеки позволяющие использование более простых конструкций, да и сложные типы там не торчат наружу. Пока же посмотрим, как распаковываются подготовленные вычисления. Для этого понадобится *обработчик* ситуации деления на 0:
```scala
def myErrorHandler(str: String) = ContT[IO, Unit, Int]{f => IO.print(str) >> f(42)}
//        не только журналируем, но и ВОССТАНАВЛИВАЕМСЯ с некторым значением ↑↑↑↑↑

// распаковщик вычислений, который и использует обработчик myErrorHandler
def myRun(calc: (String => ContT[IO, Unit, Int]) => ContT[IO, Unit, Int]) = 
  calc
    .apply(myErrorHandler) // применяем обработчик эффекта
    .run(IO.println(_))    // распаковка ContT в IO
    .unsafeRunSync()       // распаковка IO (в Id)

myRun(calc1) // 5
myRun(calc2) // Нельзя делить на 0 42
```
В комментариях к последним строчкам приведён соответствующий вывод в консоль. Видно, что обработчик ошибок вычислил значение `42` оно *вернулось в то место, где была сгенерирована ошибка*!

Стиль передачи продолжений позволяет обрабатывать схожим образом не только ошибки, но и *любые эффекты*. Возможности `callCC` и передача обработчиков в конце при “распаковке” контейнера подводят к идее **алгебраических эффектов**. Этот подход позволяет удобно и эффективно комбинировать как стандартные, так и свои абстрактные эффекты, откладывая их интерпретацию на конец программы. В сравнении с свободными контейнерами, когда *предварительно* требовалось знать перечень всех эффектов для формулировки “тотального” контейнера, концепция алгебраических эффектов не обязывает перечислять все эффекты заранее. Кроме того, основанные на концепции продолжений алгебраические эффекты зачастую обещают выигрыш в производительности.

Для Scala есть несколько библиотек с инструментами для работы с алгебраическими эффектами. Используемые там синтаксические конструкции отличаются друг от друга, поэтому вместо фрагментов кода оставлю ссылки на официальную документацию этих библиотек:
- [Scala Effekt](https://b-studios.de/scala-effekt/) (не путать с Cats.Effect) в которой эффекты описываются обычными (не обязательно обобщёнными) трейтами с методами, возвращающими значения в контейнере `Control` – именно он отвечает за композицию и обработку разных эффектов;
- [Turbolift](https://marcinzh.github.io/turbolift/) также позволяет работать с абстрактными пользовательскими эффектами, предлагает не самые привычные операторы вроде `!!` или `!@!` (😱) и гордится высокой производительностью;
- [Kyo](https://getkyo.io/) ориентирован на работу со стандартными эффектами, предоставляет оригинальный синтаксис на основе “стрелок” `>` и `<` , и в целом предлагает множество вкусных плюшек. 

С алгебраическими эффектами и передачей продолжений связана ещё одна набирающая популярность тема. В англоязычной литературе она называется “**Direct Style**”, а в русскоязычной… ещё не встречалась 🙂. Далее будем называть его “*императивным стилем*”. Давайте посмотрим, ”откуда дует ветер”.

Распространение многозадачных систем и стремление к повышению производительности привела к добавлению в популярные языки программирования специальных синтаксических конструкций, упрощающих асинхронные вычисления. Рассмотрим такой код на C#:
```csharp
async Task<int> CalcStep1(int v0)
async Task<int> CalcStep2(int v1)

async Task<int> Calc(int v0)
{
	var v1 = await CalcStep1(v0);
	return   await CalcStep2(v1);
}
```
Связка `async/await` указывает, что в процессе вычислений, пока операция `CalcStep1` ожидает какого-то стороннего сигнала: ответа web-службы и т.п. Процессор (точнее, поток, thread) может переключиться на другие вычисления и вернётся к первоначальному, лишь после завершения ожидания. Под капотом этот синтаксический сахар разворачивается в весьма нетривиальный код, который очень упрощённо можно представить так:
```csharp
Task<int> Calc(int v0)
{
	return CalcStep1(v0)
		.ContinueWith(task1 => CalcStep2(task1.Result), TaskContinuationOptions.OnlyOnRanToCompletion)
		.Unwrap();
}
```
Метод `ContinueWith` со вторым параметром `TaskContinuationOptions.OnlyOnRanToCompletion` похож на знакомый комбинатор `map`, разве что в принимаемой функции нужно явно вытащить свойство `Result` у аргумента `task1: Task<int>`. В свою очередь, метод `Unwrap`, превращающий `Task<Task<int>>` в `Task<int>`, суть не менее знакомый `flatten`. Вызов `ContinueWith` в сочетании с `Unwrap` образуют аналог `flatMap`. Таким образом, обобщённый C#-тип `Task<>` является типичным контейнером со всеми ключевыми контейнерными возможностями. Значит `async/await` – это способ организовать императивную (direct) композицию эффективных вычислений в контейнере!

Также стоит обратить внимание на название метода `ContinueWith` – явный намёк, что код организован в стиле передачи продолжений. В [этом ответе на вопрос](https://stackoverflow.com/a/4071015/4583514) на Stackoverflow, демонстрируется, что вызов `await CalcStep1(v0)` можно *символически* переписать с помощью (несуществующего в C#) комбинатора `callCC` как-то так
```
callCC CalcStep1(v0).GetAwaiter().BeginAwait;
```

В Cats есть трансформер `ContT` над любым эффективным контейнером, и даже функция `callCC` при нём. Значит, должен найтись способ описывать композицию любых эффективных вычислений в *императивном стиле*, аналогичном использованию `async/await` в C#. Есть, конечно, for-выражения, но у них слишком много ограничений. Достаточно полноценные решения представлены в виде отдельных библиотек:
- [scala-async](https://github.com/scala/scala-async) для контейнера `Future`;
- [cats-effect-cps](https://typelevel.org/cats-effect/docs/std/async-await) для `IO`;
- [zio-direct](https://github.com/zio/zio-direct), очевидно, для `ZIO` (тут используется связка `defer/run`);
- [gears](https://github.com/lampepfl/gears) – “доказательство концепции” от [авторов](https://www.epfl.ch/labs/lamp/) Scala 3;
- [dotty-cps-async](https://rssh.github.io/dotty-cps-async/) – ещё одна экспериментальная библиотека для Scala 3;
- [Monadless](https://github.com/monadless/monadless) с помощью макросов конвертирует обычные императивные вычисления в контейнерные, используя конструкцию `lift/unlift`;
- [Each](https://github.com/ThoughtWorksInc/each) ещё одна макро-библиотека, но здесь уже работает пара `monadic/each`;
- [Unwrapped](https://github.com/xebia-functional/Unwrapped) библиотека на Scala 3, похоже, что не использует макросы; вместо `await` там используется `bind`, а `async` замещают [контекстные функции](https://docs.scala-lang.org/scala3/reference/contextual/context-functions.html).

У каждого решения свои особенности, но общая суть . Вот пример по мотивам документации [dotty-cps-async](https://rssh.github.io/dotty-cps-async/):
```scala
val c = async[F] {                                     // c: F[String]
  val url     = "http://www.example.com"
  val data    = await(api.fetchUrl(url))               // fetchUrl:         String          => F[String]
  val theme   = api.classifyText(data)                 // classifyText:     String          =>   String
  val dmpInfo = await(api.retrieveDMPInfo(url, theme)) // retrieveDMPInfo: (String, String) => F[String]
  dmpInfo
}
```
Методы `fetchUrl` и `retrieveDMPInfo` возвращают значения в контейнере `F` и их вызовы обёрнуты в `await`. Это не распаковка, а некий маркер для макроса `async`, которой преобразует переданный ему блок в стиле передачи продолжений. Конструкция `= await` немного напоминает стрелку `<-` в `for`-выражении, но никак не ограничивает использование простых императивных операций вроде `if`, `return` (ранний выход), или того же `for`. Более того, поздние версии библиотеки [позволяют не писать](https://rssh.github.io/dotty-cps-async/AutomaticColoring.html) `await`, что избавляет от неприятного явления “[разноцветных функций](https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/)”.

Минусы прямого использования стиля передачи продолжений в Scala хорошо [сформулировал](https://stackoverflow.com/questions/78055394/get-current-contiuation-in-scala?noredirect=1#comment137630265_78055394) Матеуш Кубужок. Работа с `ContT`, `Codensity` и другими подобными типами сильно напрягают механизм вывод типов Scala, но он всё же слабоват для таких задач, в сравнении, например, с Haskell. То, что в Haskell решается в одну строчку, требует значительных усилий для аналогичных решений в Scala. Также стиль передачи продолжений засоряет стек вызовов, что усложняет отладку кода. Но, с другой стороны, основанные на CPS библиотеки алгебраических эффектов маскируют сложные детали реализации и упрощают стек вызовов, предоставляя очень удобные инструменты для разработки.

Дополнительная литература:
- wiki-сатьи про стиль передачи продолжений:
	- [Продолжение (информатика)](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D0%B4%D0%BE%D0%BB%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5_(%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)),
	- [Haskell/Continuation passing style](https://en.wikibooks.org/wiki/Haskell/Continuation_passing_style);
- статьи на Хабре про CPS (смесь русского с хаскелем):
	- [Монада ContT в картинках](https://habr.com/ru/articles/149174/) – тут хорошо раскрывается смысл `calcCC`,
	- [Продолжения в Haskell](https://habr.com/ru/articles/127040/) – тут, в частности, рассмотрен пример использования `getCC`;
- ещё про продолжения:
	- [Why would you use ContT?](https://ro-che.info/articles/2019-06-07-why-use-contt) статья Романа Чепляка,
	- [when to use CPS vs codensity vs reflection without remorse in Haskell](https://stackoverflow.com/questions/45334985/when-to-use-cps-vs-codensity-vs-reflection-without-remorse-in-haskell) вопрос на Stackoverflow;
- алгебраические эффекты:
	- [An Introduction to Algebraic Effects and Handlers](https://www.eff-lang.org/handlers-tutorial.pdf) pdf-статья Матии Претнара,
	- [Effects Without Monads: Non-determinism Back to the Meta Language](https://arxiv.org/pdf/1905.06544.pdf) pdf-статья Олега Киселёва,
	- [«Алгебраические эффекты» человеческим языком](https://habr.com/ru/articles/470718/) – хабр-превод [статьи](https://overreacted.io/algebraic-effects-for-the-rest-of-us/) Дана Абрамова,
	- хорошую информационную поддержку имеет библиотека Kyo:
		- [Kyo - Functional Scala 2023](https://speakerdeck.com/fwbrasil/kyo-functional-scala-2023) (презентация),
		- [Writing Modular Applications Using The Kyo Library](https://www.scalamatters.io/post/writing-modular-applications-using-the-kyo-library) – статья Хорхе Васкеса;
- императивный стиль (direct style):
	- [Martin Odersky DIRECT STYLE SCALA](https://www.youtube.com/watch?v=0Fm0y4K4YO8) – видео-доклад от автора языка,
	- [Scala 3: What Is “Direct Style”?](https://medium.com/scala-3/scala-3-what-is-direct-style-d9c1bcb1f810) – статья Дина Вамплера на Medium.


<anchor>tagless_final</anchor>
### Tagless Final

Давайте ещё раз рассмотрим контейнер абстрактного эффекта `UsersRepo`, введённый ранее при рассмотрении свободных контейнеров:
```scala
enum UsersRepo[A]:
  case Get(id: UserId)                 extends UsersRepo[Option[UserInfo]]
  case Put(id: UserId, user: UserInfo) extends UsersRepo[UserSaved]
  case ListAll                         extends UsersRepo[List[(UserId, UserInfo)]]
```
Ранее уже было сказано, что этот обобщённый алгебраический тип (GADT) *реализует* три функции неявного приведения экземпляров подтипов к значениям в контейнере. Приведение происходят “*без потерь*“, так как экземпляр типа `UsersRepo[A]` можно *сопоставить с шаблонами*-подклассами, и узнать, каким конструктором и *из каких значений* этот экземпляр создан. По сути, задача подклассов заключается только в хранении исходных параметров.

Экземпляр `UsersRepo[A]` всегда можно реинтерпретировать в любой другой контейнер. Но вот придумать иной *неизоморфный* контейнерный тип, который также отражал бы суть рассматриваемого эффекта, и который можно было бы преобразовать к `UsersRepo` уже не выйдет. То есть, при сохранении семантики такие типы можно лишь *усложнить*, но сделать проще уже не получится. В этом смысле подобные GADT называют <u><i>начальными</i></u> *алгебрами* соответствующего контейнера.

В свою очередь, интерпретация значений в контейнере `UsersRepo`, преобразование к другому контейнеру, считается <u><i>финальным</i></u> шагом. Разделение вычислений на два шага – начальное построение свободной программы и её финальная интерпретация – ведёт к очевидной потере производительности, что, как правило, не желательно. Если “начальную алгебру” `UsersRepo` переписать сразу в “финальной” кодировке, использующей, например, контейнер `IO`, то получится обычный набор функций:
```scala
trait UserRepoIO:
  val getUser:   UserId             => IO[Option[UserInfo]]
  val putUser:   UserId => UserInfo => IO[UserSaved]
  val listUsers:                       IO[List[(UserId, UserInfo)]]
```
Самый обычный ООП-шный трейт `UserRepoIO` представляет собой финальную кодировку, соответствующую начальной алгебре `UsersRepo`. Основное его преимущество заключается в том, что вычисление происходит быстрее, в один шаг. Недостатком в сравнении с начальной алгеброй является избыточная жёсткость – хотя и можно предоставить различную реализацию этих методов, но в их сигнатуре уже вшит тип контейнера, что ограничивает интерпретацию.

Можно ли используя финальную кодировку с её “скоростью” получить “свободу интерпретации”, присущую начальной кодировке? Давайте попробуем заменить `IO` в `UserRepoIO` на некий контейнер `F`:
```scala
trait UserRepoF[F[_]]: // некий неизвестный контейнер F
  val getUser:   UserId             => F[Option[UserInfo]]
  val putUser:   UserId => UserInfo => F[UserSaved]
  val listUsers:                       F[List[(UserId, UserInfo)]]
```
Внезапно, это и есть искомое решение! В то время как разработка на основе свободных контейнеров, помогала абстрагироваться от конкретных эффектов, *техника Tagless Final позволяет абстрагироваться от контейнера*, носителя контекста эффекта. Рассмотрим пару примеров реализации этого трейта (интерпретации алгебры `UserRepoF`):
```scala
type Log[X] = String // константный контейнер
val log = new UserRepoF[Log]:
  val getUser   = id         => s"Получить пользователя с идентификатором $id"
  val putUser   = id => user => s"Сохранить пользователя $user под идентификатором $id"
  val listUsers =                "Перечислить всех пользователей"
```
В подобной интерпретации каждый метод теперь может вернуть значения любого нужного типа; в случае контейнера `Log`, это `String`. А вот так можно получить и начальную алгебру:
```scala
import UsersRepo.*
val usersRepoAlg = new UserRepoF[UsersRepo]:
  val getUser   = Get.apply
  val putUser   = Put.apply.curried
  val listUsers = ListAll
```

Обобщённые трейты вроде `UserRepoF`, параметризированные обобщённым же ковариантным типом-контейнером `F[_]`, представляют собой легко узнаваемую основу техники Scala-разработки, известную под названием **Tagless Final**. Слово “final” в названии соответствует использованию *финальной* кодировки. “Tagless” же отсылает ~~к древнему злу~~ ко временам, когда типизацию приходилось блюсти вручную, сверяя во время выполнения “теги” – дополнительные метаданные, передаваемые вместе с целевыми значениями. Появление в программировании обобщённых типов перенесло соответствующие механизмы типизации на этап компиляции, что позволило перейти к “бестеговой” (tagless) разработке.

Если с основой Tagless Final более или менее познакомились, осталось разобраться, как комбинировать вычисления с использованием конечного кодирования. Будем трактовать обобщённый трейт `UserRepoF` как *класс контейнерных типов*. Значения `UserRepoF[SomeF]` для конкретного `SomeF` содержат реализации соответствующих возможностей для этого контейнера. Ситуация аналогична привязке “контейнерных возможностей” к произвольным обобщённым (ковариантным) типам вида $\star\Rightarrow\star$, когда также используются классы типов. Таким образом, при построении Tagless Final программы требуются экземпляры классов типов как всех используемых финальных алгебр
```scala
trait SearchServcieF[F[_]]:
  def searchBest   (request: String): F[Data]
  def searchSeveral(request: String): F[List[(Relevance, Data)]]

trait NotificationServiceF[F[_]]:
  def sendNotification(notification: Notification): F[NotificationResult]
```
так и “контейнерных”, вроде [Monad](https://typelevel.org/cats/typeclasses/monad.html) из библиотеки Cats, позволяющего, в частности, использовать методы `map` и `flatMap`:
```scala
import cats.Monad
import cats.syntax.all.*

def programTF[F[_]: UserRepoF: SearchServcieF: NotificationServiceF: Monad]: F[List[(Relevance, Data)]] =
  val userRepo = summon[UserRepoF[F]]
  import userRepo.*

  val searchService = summon[SearchServcieF[F]]
  import searchService.*

  val notificationService = summon[NotificationServiceF[F]]
  import notificationService.*

  // далее уже знакомый код
  searchBest("best user")           productL
  sendNotification("user captured") flatMap
  putUser(42)                       productR
  getUser(42)                       map
  {_.fold("")(_.reverse)}           flatMap
  putUser(24)                       productR
  listUsers
```
Чтобы избавиться от “мусорных” призывов и импортов в теле `programTF` рекомендуется описать дополнительный DSL для конечных алгебр:
```scala
object UserRepoF:
  def getUser  [F[_]: UserRepoF] = summon[UserRepoF[F]].getUser
  def putUser  [F[_]: UserRepoF] = summon[UserRepoF[F]].putUser
  def listUsers[F[_]: UserRepoF] = summon[UserRepoF[F]].listUsers

object SearchServcieF:
  def searchBest   [F[_]: SearchServcieF] = summon[SearchServcieF[F]].searchBest
  def searchSeveral[F[_]: SearchServcieF] = summon[SearchServcieF[F]].searchSeveral

object NotificationServiceF:
  def sendNotification[F[_]: NotificationServiceF] = summon[NotificationServiceF[F]].sendNotification
```
В итоге получаем *в точности такое же тело программы*, как и в примере для свободных контейнеров, но уже в финальной кодировке:
```scala
import UserRepoF.*, SearchServcieF.*, NotificationServiceF.*

def programTF[F[_]: UserRepoF: SearchServcieF: NotificationServiceF: Monad] =
  searchBest("best user")           productL
  sendNotification("user captured") flatMap
  putUser(42)                       productR
  getUser(42)                       map
  {_.fold("")(_.reverse)}           flatMap
  putUser(24)                       productR
  listUsers
```
Для выполнения программы необходимо в контекст положить неявные значения финальных алгебр, конкретизированных выбранным контейнером (сами реализации не принципиальны):
```scala
given UserRepoF[IO] with
  override val getUser   = ???
  override val putUser   = ???
  override val listUsers = ???

given SearchServcieF[IO] with
  override val searchBest    = ???
  override val searchSeveral = ???

given NotificationServiceF[IO] with
  override val sendNotification = ???
```
Алгебра `Monad[IO]` уже реализована в объекте-компаньоне контейнера `IO` и импортируется автоматически. Теперь осталось только выполнить программу:
```scala
programTF[IO] // : IO[List[(UserId, UserInfo)]]
```

Функция `programTF`, в свою очередь, также может быть реализацией метода некоторой алгебры, более высокоуровневой с точки зрения предметной области. Это означает, что с Tagless Final очевидным образом можно строить и многослойные приложения.

Техника Tagless Final хорошо сочетается с экосистемой Cats, библиотеки которой содержат как стандартные “контейнерные” классы типов, так и базовые эффекты вроде обработки ошибок, или асинхронщины. Библиотека [Cats-tagless](https://typelevel.org/cats-tagless/) предлагает набор макро-аннотаций для конечных алгебр, которые позволяют сократить объём шаблонного кода, и добавляют другие вкусные плюшки. Контейнеры `ZIO` также можно использовать с конечными алгебрами, но эта экосистема старается дистанцироваться от Tagless Final, говоря, что для ZIO-разработки это всё не нужно.

Tagless Final даёт хорошую иллюстрацию использования типов высокого рода. Будучи основанной на контейнерных типах вида $\star\Rightarrow\star$, она оперирует типами-алгебрами вида $(\star\Rightarrow\star)\Rightarrow\star$. А в статье Луки Якубовича [Optimizing Tagless Final – saying farewell to Free](https://typelevel.org/blog/2017/12/27/optimizing-final-tagless.html) демонстрируется преобразование программ, построенных на конечных алгебрах – полиморфные типы таких программ имеют ещё более сложный вид $((\star\Rightarrow\star)\Rightarrow\star)\Rightarrow\star$.

Как и в случае свободных контейнеров, техника Tagless Final позволяет по-разному интерпретировать сконструированные программы, что может быть удобно, когда возможны миграции на другие контейнеры эффектов, или же когда для тестирования удобно использовать более простые контейнеры. Но благодаря своей “финальности” Tagless Final *избавляет от лишнего шага* построения во время выполнения начальной алгебры программы.

Говоря же о недостатках данной техники, обычно отсылают к статье “[The False Hope of Managing Effects With Tagless-Final in Scala](https://degoes.net/articles/tagless-horror)” автора библиотеки ZIO Джона де Гуса. Да, там заметно стремление продвинуть свой продукт, конкурирующий с экосистемой Cats, но можно найти вполне резонные замечания. Во-первых, даже для абстрактных для контейнеров очень важны “контейнерные возможности”, так что при реализации финальных алгебр почти повсеместно приходится писать что-то вроде `F[_]: Monad` – код уже теряет некоторую долю выразительности. То же замечание относится и к некоторым другим классам типов, отвечающим за “популярные“ эффекты (например, `Async[F[_]]`). Но более важно то, что усложнение кода для “свободы интерпретации” навряд ли может быть оправдано требованиями бизнеса – в большинстве приложений, финальные алгебры реализуются для *единственного* контейнера (чаще всего, это `IO` из библиотеки Cats).

Дополнительная литература:
- [Tagless Final in Scala](https://blog.rockthejvm.com/tagless-final/) – хороший обзор от Даниэля Чокырлана (Rock the JVM).
- [A "quick" introduction to Tagless Final](https://nrinaudo.github.io/articles/tagless_final.html) – ещё одно чуть более современное “введение” Николя Ринаудо.
- Хабр-статья [Возвращаясь к Неразмеченным Конечным Интерпретаторам с Dotty](https://habr.com/ru/articles/325874/).
- теоретическая PDF-статья [Finally Tagless, Partially Evaluated](https://okmij.org/ftp/tagless-final/JFP.pdf).

<anchor>arrows</anchor>
### Клейсли и другие стре́лки

Императивный стиль, о котором говорилось ранее, позволяет “чисто” описывать эффективные программы в привычной старинной манере, основанной на использовании стека. При таком подходе вычисления разбиваются на шаги, переводящие одно состояние стека в другое. Эти состояния можно визуализировать в виде кортежей из инициализированных локальных переменных:
![[Стековая композиция.png]]

К сожалению, слишком редко говорят о том, что такое программирование чревато букетом принципиальных проблем:
- количество инициированных переменных растёт с каждым шагом, при этом, использованные переменные “устаревают”, засоряя контекст:
	- как следствие, очень легко перепутать последовательность шагов (например, сделать лишние действия *до* проверки их надобности), или же
	- вместо нужной использовать “устаревшую“ переменную того же типа и т.п.;
- компьютеры и компиляторы умнеют, но мы по-прежнему относимся к ним как к “дурочкам”, *многословно* объясняя, куда положить вычисленное значение и как потом его использовать;
	- требуются дополнительные (необязательные!) синтаксические конструкции, вроде инициализации локальных переменных,
	- страдает выразительность кода, что, статистически, приводит к просачиванию ошибок на этап исполнения.
С такой точки зрения само стремление разработчиков к традиционному императивному стилю выглядит как *поиск привычных граблей для натренированной мозоли на лбу*.

В качестве альтернативы императивному стилю можно выбрать *потоковый синтаксис* (flow syntax), при котором подразумевается, что состояния между шагами описываются единственной переменной:
```scala
def calc(b: Boolean) = b
  .toString
  .length
  .+(37) // оператор "+" - это самый обычный метод в Scala

calc(false) // 42
```
В данном примере потоковый синтаксис основан на вызове через точку `.` собственных методов классов, или методов расширения. Но аналогичным образом можно композировать и обычные функции:
```scala
def boolToString(b: Boolean) = b.toString
def stringToInt (s: String)  = s.length
def add37       (i: Int)     = i + 37

import scala.util.chaining.scalaUtilChainingOps

def calc(b: Boolean) =
  b            pipe
  boolToString pipe
  stringToInt  pipe
  add37
```
Комбинатор `pipe` – полиморфный метод-расширение, импортированный из `scalaUtilChainingOps` и записанный [в инфиксной операторной форме](https://docs.scala-lang.org/style/method-invocation.html#arity-1-infix-notation). Он просто передаёт левый аргумент в функцию, указанную справа (в нашем случае, на следующей строке). Кстати, похожая запись уже встречалась для *контейнерных* вычислений, где вместо `pipe` использовался комбинатор `flatMap`.

Уже лучше, но мы всё ещё не избавились от императивности окончательно. На каждом шаге вычислений в `calc` у нас остаётся соблазн использовать “устаревшую”, но по-прежнему доступную, переменную `b`, переданную в функцию как аргумент. Можно ли устранить и эту проблему? Конечно, если писать всё сразу в *функциональном стиле*, когда сложные функции представляются в виде *комбинации* простых:
```scala
val calc = // : Boolean => Int - тип выводится автоматически
  boolToString andThen
  stringToInt  andThen
  add37
  
calc(false) // 42
```
Комбинатор `andThen` здесь – встроенный метод класса `Function1`. Итоговая функция есть “*boolToString, затем stringToInt, затем add37*”. Максимально идеоматично, ничего лишнего! Мы полностью избавились от состояний, следовательно, нет и необходимости в трассировке `calc`, тут просто нечему ломаться! Такой стиль называется “бесточечным”. Под “точками” ~~в теории категорий~~ подразумевают промежуточные состояния, значения локальных переменных в стеке.

Также есть дуальный метод `compose`, действующий аналогично `andThen`, но в обратном направлении. Запись `val calc = add37 compose stringToInt boolToString` можно прочесть как “*функция calc – это результат вычисления add37 после stringToInt, после boolToString*”.

В случае контейнерных вычислений нужно комбинировать функции вида `A => F[B]`. Для таких функций библиотека Cats предлагает комбинаторы `andThenF` и `composeF`, доступные, только если для `F[_]` реализован класс типов `FlatMap[F[_]]` с необходимыми контейнерными возможностями.

Также библиотека Cats предлагает синонимы таких комбинаторов в виде стрелочек-операторов: `>>>`, `>=>` и `<<<`, `<=<`. Например:
```scala
val stringToIntOpt: String => Option[Int] = _.toIntOption
val devideOpt:         Int => Option[Int] =
  i => if (42 % i == 0) Some(42 / i) else None

import cats.syntax.all.*
val calc = devideOpt <=< stringToIntOpt
//                   ↑↑↑ оператор 🐟
calc("1") // Some(42)
```

Cемантика последовательной композиции вычислений доступна не только для типов простых и “эффективных” функций. Общий вид этих типов будет таким:
```scala
type ==>[-_, +_]
```

По сути, `==>` и есть абстрактная “*стрелка*”. Но типы, как это было и с контейнерами, определяются через свои возможности. В частности, стрелки также определяются реализацией соответствующего класса типов. Стрелки обладают внушительным количеством базовых возможностей, которые можно собрать из следующих классов:
```scala
type Identity   [==>[-_, +_]] = [A] => () => (A ==> A)
type AndThen    [==>[-_, +_]] = [A, B, C] => (A ==> B, B ==> C) => (A ==> C)
type Category   [==>[-_, +_]] = Identity[==>] & AndThen[==>]

type Dimap      [==>[-_, +_]] = [A, B, C, D] => (C => A, B => D) => (A ==> B) => (C ==> D)
type First      [==>[-_, +_]] = [A, B, C] => (A ==> B) => ((A, C) ==> (B, C)) // технически, можно
type Second     [==>[-_, +_]] = [A, B, C] => (A ==> B) => ((C, A) ==> (C, B)) // обойтись только одним
type Strong     [==>[-_, +_]] = Dimap[==>] & First[==>] & Second[==>]

type Arr        [==>[-_, +_]] = [A, B] => (A => B) => (A ==> B)
type Arrow      [==>[-_, +_]] = Category[==>] & Strong[==>] & Arr[==>]

type Choose     [==>[-_, +_]] = [A, B, C, D] => ((A ==> C), (B ==> D)) => ((A Either B) ==> (C Either D))
type ArrowChoice[==>[-_, +_]] = Arrow[==>] & Choose[==>]
```
Для этих классов типов вводятся следующие удобные функции:
```scala
def ident[==>[-_, +_] : Identity] = summon[Identity[==>]]()

extension[==>[-_, +_]: Dimap, A, B] (fab: A ==> B)
  def dimap[C, D](ca: C => A, bd: B => D) = summon[Dimap[==>]](ca, bd)(fab)

extension[==>[-_, +_]: AndThen, A, B] (fab: A ==> B)
  def andThen[C](fbc: B ==> C) = summon[AndThen[==>]](fab, fbc)
  def >>>    [C](fbc: B ==> C) = fab andThen fbc  
  def compose[C](fca: C ==> A) = fca andThen fab
  def <<<    [C](fca: C ==> A) = fab compose fca

extension[==>[-_, +_]: First, A, B] (fab: A ==> B)
  def first[C]  = summon[First [==>]][A, B, C](fab)
extension[==>[-_, +_]: Second, A, B] (fab: A ==> B)
  def second[C] = summon[Second[==>]][A, B, C](fab)

extension[A, B] (fab: A => B)
  def arr[==>[-_, +_]: Arr] = summon[Arr[==>]](fab)

extension[==>[-_, +_]: Arrow, A, B] (fab: A ==> B)
  def split[C, D](fcd: C ==> D) = fab.first andThen fcd.second
  def ***  [C, D](fcd: C ==> D) = fab split fcd
  def merge[C   ](fac: A ==> C) = ((a: A) => (a, a)).arr[==>] andThen (fab split fac)
  def &&&  [C   ](fac: A ==> C) = fab merge fac

extension[==>[-_, +_]: Choose, A, C] (fac: A ==> C)
  def choose[B, D](fbd: B ==> D) = summon[Choose[==>]](fac, fbd)
  def +++   [B, D](fbd: B ==> D) = fac choose fbd

extension[==>[-_, +_]: ArrowChoice, A, C] (fac: A ==> C)
  def choice[B](fbd: B ==> C) = (fac +++ fbd).dimap(identity[A Either B], _.fold(identity, identity))
  def |||   [B](fbd: B ==> C) = fac choice fbd
```

Возможностей у стрелок больше чем у контейнерных типов, но в коде выше многие функции дублированы своими синонимами в виде символических операторов. Именно они наиболее интересны: `>>>`, `<<<`, `&&&`, `***`, `+++`.

Посмотрим как использовать эти операторы для [стрелок из библиотеки Cats](https://typelevel.org/cats/typeclasses/arrow.html). Там реализованы неявные значения класса `Arrow` для обычных функций, а также для типов [Kleisli](https://typelevel.org/cats/datatypes/kleisli.html) и [Cokleisli](https://typelevel.org/cats/api/cats/data/Cokleisli.html), которые изоморфны таким конструкциям:
```scala
type Function [       -A, +B] =   A  =>   B  // небольшой каламбур 😏
type Kleisli  [F[+_], -A, +B] =   A  => F[B] // синонимичен ReaderT
type Cokleisli[F[+_], -A, +B] = F[A] =>   B  // тоже местами интересен, но тут не будет о нём
```
Будем строить программу как большую эффективную стрелку типа `Kleisli[IO, *, *]` на основе следующих кирпичиков:
```scala
import cats.effect.IO
import cats.data.Kleisli
import cats.syntax.all.*

type ==>[A, B] = Kleisli[IO, A, B]

val boolToString :  Boolean    ==> String = Kleisli{ b     => b.toString.pure}
val getFirstChar :  String     ==> Char   = Kleisli{ s     => IO{s.head}}
val stringToInt  :  String     ==> Int    = Kleisli{ s     => IO{s.length}}
val replicateChar: (Char, Int) ==> String = Kleisli{(c, i) => (c.toString * i).pure}
```
Сама же эффективная программа записывается в полностью бесточечном стиле:
```scala
val program = boolToString >>> (getFirstChar &&& stringToInt) >>> replicateChar
//  program : Boolean ==> String

import cats.effect.unsafe.implicits.global
program(true).unsafeRunSync() // tttt
```
Неужели кто-то всё ещё хочет развивать императивный стиль в Scala?

Стрелки ковариантны по второму параметру, следовательно, они также относятся к контейнерам и для них реализуются все необходимые возможности. Но на самом деле он гораздо богаче. Ранее говорилось, что классы типов `Applicative` и `Monad` ориентированы на, соответственно, независимое (параллельное) и последовательное выполнение эффектов. Стрелки же допускают оба способа комбинирования вычислений.

Стрелки не исчерпываются только лишь *отображениями* из одного контейнера в другой, вида `F[A] => G[B]`. На сайте документации Cats приводится пример рекурсивной стрелки [FancyFunction](https://typelevel.org/cats/typeclasses/arrow.html#fancyfunction). Или другой пример:
```scala
type InverseFunction[-A, +B] = (B => A) => (A => B)
```
Хоть и не очень понятно, как можно использовать эту “инвертированную функцию”, но для неё тоже реализуются основные стрелочные возможности.

Стрелки, также как и контейнеры могут быть “свободными”. Инструменты для построения программ на их основе предоставляются, например, библиотекой [Free Arrow](https://github.com/AdrielC/free-arrow#free-arrow). Операции бизнес-логики описываются в виде привычных алгебраических типов данных, но параметризированных уже двумя типами. Далее они “поднимаются” до “свободных стрелок”, из которых уже строится цепочка вычислений. Для получения результата необходимо предоставить “интерпретатор” – преобразователь из наших абстрактных стрелок во что-то вычислимое, например, в тот же `Kleisli`. Другими словами, достаточно пройти тот же самый путь, что и со свободным контейнерами, но получить более широкие возможности стрелок при построении программы.

Не смотря на то, что стрелки значительно богаче контейнеров, построение решений на самописных стрелках оказывается слишком громоздким для повседневного использования. Обычно рекомендуют стоить программы только на основе контейнеров (в том числе и с `Kleisli` над ними), и только там, где они не справляются, допускается использование самодельных стрелок. Тем не менее, всё это не отменяет очевидный факт:

>*Стрелки отражают саму суть функционального программирования*.

Дополнительные источники по стрелкам:
- Стрелки в популярных Scala-библиотеках:
	- [Arrow](https://typelevel.org/cats/typeclasses/arrow.html) на официальном сайте о Cats от TypeLevel.
	- [Arrow](https://eed3si9n.com/herding-cats/Arrow.html) из библиотеки Cats с ресурса [herding cats](https://eed3si9n.com/herding-cats/) Юджина Йокоты.
	- [Arrow](https://eed3si9n.com/learning-scalaz/Arrow.html#Arrow) из библиотеки Scalaz с того ресурса [learning Scalaz ](https://eed3si9n.com/learning-scalaz/) того же автора.
	- [ZIO Arrow](https://zio.dev/ecosystem/community/zio-arrow/) (без комментариев).
- Стрелки в Scala
	- [Рефакторинг при помощи композиции Клейсли](https://habr.com/ru/companies/wix/articles/304622/) – хабр-статья, в которой используется `Kleisli` из библиотеки Scalaz.
	- [Composing Monadic Functions with Kleisli Arrows](https://blog.ssanj.net/posts/2017-06-07-composing-monadic-functions-with-kleisli-arrows.html) статья Санджива Сахаяма.
	- [Functional Programming with Arrows](https://workday.github.io/assets/scala-functional-programming-with-arrows/) презентация Юрия Полюли.
	- *Arrows, Monads and Kleisli* – статья в [двух](https://medium.com/virtuslab/arrows-monads-and-kleisli-part-i-6c2a35c27a6e) [частях](https://medium.com/virtuslab/arrows-monads-and-kleisli-part-ii-12ffd4da8bc9) на Medium от Марцина Ржежницкого.
- Стрелки в Haskell:
	- [Understanding arrows](https://en.m.wikibooks.org/wiki/Haskell/Understanding_arrows) подробная статья с картинками.
	- [Monads vs. Arrows](https://stackoverflow.com/questions/3652054/monads- vs-arrows) вопрос на Stackoverflow.

<anchor>subcategories_of_types</anchor>
## Подкатегории типов (вместо заключения)

Процесс вычислений разбивается на этапы, последовательно *превращающие* начальное состояние в конечное. Например, этап-функция принимает на вход начальное состояние-значение, возвращает промежуточное, которое передаётся на вход следующему этапу-функции, и так далее до финального состояния-значения. Функции выстраиваются в цепочку, образуя *путь* вычислений. Это можно визуализировать в виде линейного графа:

$$
\stackrel{\color{blue}(a:A)}{\bullet} \xrightarrow{\color{red} \hspace{5mm} f:\;A \Rightarrow B \hspace{5mm}} \stackrel{\color{blue}(b:B)}{\bullet} \xrightarrow{\color{red} \hspace{5mm} g:\;B \Rightarrow C \hspace{5mm}} \stackrel{\color{blue}(c:C)}{\bullet} \xrightarrow{\color{red} \hspace{5mm} h:\;C \Rightarrow D \hspace{5mm}} \stackrel{\color{blue}(d:D)}{\bullet}
$$

Но, как уже говорилось ранее, не все вычисления производятся на уровне значений. Простые конструкторы типов описывают превращения одних типов в другие. Но обобщённые типы и сами могут выступать в качестве точек-состояний для полиморфных типов более высокого рода. Кроме того, в статье уже упоминались “путешествия” между вселенными типов, когда, например, из точки-значения можно прийти к точке-типу, или наоборот.  На самом деле, есть и более интересные совокупности точек и переходов между ними, которые хоть и не очень явно, но также используются в программировании. И чтобы представить полный путь вычислений нужна более общая концепция, чем значения и их типы.

Такая концепция называется **категорией**. Абстрактная категория представляет собой как раз совокупность неких точек-**объектов** и стрелок-**морфизмов** между ними. При этом для категории есть обязательные условия: существование *ассоциативной композиции* морфизмов $g \circ f$, и наличие у каждого объекта *единичного морфизма* $id$, переводящего объект в самого себя:
![[Категории.png]]
Такая банальная, на первый взгляд, конструкция позволяет оперировать уже не только стрелками-морфизмами на графе, но целыми *путями*, построенными из этих стрелок – сравнивать их между собой и выбирать наилучший.

Очевидно, что свои категории образуют значения, типы, конструкторы типов, виды типов и много чего ещё. Например, конструктор типов `Either[A, B]` переводит пару типов в тип. Но *пары типов* сами по себе типами не является – они образуют собственную категорию! А `Either` представляет собой морфизм из категории пар типов в категорию типов. Автоматически напрашивается интуиция, что *совокупность категорий сама образует категорию*. 

В контексте обобщённых типов нам, прежде всего, важно то, что категории могут содержать вложенные *подкатегории*. В категории, объектами которой являются типы, а морфизмами – функции `A => B`, *каждый* обобщённый тип `F[_]` образует свою **подкатегорию типов** с морфизмами-функциями `F[A] => F[B]`. И это даёт очередную интерпретацию обобщённых типов.

Практически все понятия, введённые в статье, так или иначе опираются на теорию категорий:
- все простые обобщённые типы являются морфизмами вида $\star\rightarrow\star$ в *категории типов*;
- каждый обобщённый тип `F[_]` представляют собой *подкатегорию типов* $\mathcal{F}$;
- аналогичные рассуждения можно провести для полиморфных типов любого вида (например, $\star\rightarrow\star\rightarrow\star$ и др.);
- вселенные типов образуют категорию с морфизмами-путешествиями между ними;
- класс контейнерных типов `Lift[F[_]]` (с возможностью `map`) олицетворяет *эндофунктор* из категорией типов в её подкатегорию: $F: \star\rightarrow \mathcal{F}$;
- волнистая стрелка `~>[F[_], G[_]]` представляет собой ~~вообще говоря, функтор между подкатегориями F и G, но обычно говорят, что это~~ *естественное преобразование* $F\leadsto G$ между эндофункторами $F: \star\rightarrow \mathcal{F}$ и $G: \star\rightarrow \mathcal{G}$;
- в частности, класс типов `Flatten[F[_]]` совместно с `Pure[F[_]]` и `Lift[F[_]]` представляют такую пару естественных преобразований (`pure` и `flatten`), которая относится к понятию *монада*;
- возможность перестановки контейнеров местами `F[G[A]] => G[F[A]]`, в том числе, когда один из них кортеж (`Applicative`), определяется тем, как именно функторы $F: \star\rightarrow \mathcal{F}$ и $G: \star\rightarrow \mathcal{G}$ *сопряжены* друг с другом: $F\vdash G$ или $F\dashv G$;
- свободный контейнер `Free[F[_]]` ассоциируется с *начальным (свободным) объектом* в категории монад над функтором $F$ – *свободным моноидом* в категории эндофункторов;
- трансформер коплотности `Codensity[F[_]]` представляет собой *правое расширение Кана* функтора $F: \star\rightarrow \mathcal{F}$ вдоль самого себя: $Codensity(F)=Ran_F(F)$;
- стрелки же описывают *(сильные) профункторы* – функторы в категорию множеств из декартова произведения категорий $\star^{op}\times\star \rightarrow \mathbf{Set}$, где $\star^{op}$ есть категория, дуальная типам (все морфизмы-функции там направлены в противоположную сторону).

Пожалуй, одного только этого списка должно быть достаточно для демонстрации фундаментальности теории категорий. Но всё же, что дают все эти высокоуровневые абстракции обычным программистам?

Теория категория зародилась как раздел топологии с целью предоставить достаточно выразительный язык как для описания уже существовавших там понятий, так и для формулирования новых. Один из классов задач топологии связан с операциями над *путями между двумя точками* – вычисления отношений между ними и т.п. К этому классу относится, например, нахождение кратчайшего пути на ориентированном графе между заданными точками. Но ведь именно это и требуется программистам – с помощью всех доступных возможностей найти наилучший путь вычисления нужного результата!

Теория категория как раз предоставляет удобный инструментарий для работы с путями вычислений. Многие понятия (функторы, монады и т.п.) определяются в ней через *коммутирование* диаграмм – различные пути на этих диаграммах приводят к одинаковому результату, что позволяет выбрать наиболее подходящий. Но, пожалуй, интереснее всего те понятия, которые определяются через своё “*[универсальное свойство](https://ru.wikipedia.org/wiki/%D0%A3%D0%BD%D0%B8%D0%B2%D0%B5%D1%80%D1%81%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B5_%D1%81%D0%B2%D0%BE%D0%B9%D1%81%D1%82%D0%B2%D0%BE)*”, утверждающее “избранность“ какого-то морфизма среди аналогичных. Именно универсальные свойства различных конструкций *указывают наикратчайший путь вычислений*.

> Теория категорий объясняет, почему именно те, а не иные конструкции являются наилучшими инструментами при разработке компьютерных программ.

Упомянутый ранее императивный стиль (direct style) показывает, что сложные вычисления можно “замести под ковёр”, оставив на поверхности лишь нужные синтаксические конструкции. Но надо помнить, что любая такая надстройка стоит на универсальном фундаменте теории категорий.

В данной статье часто упоминается Scala-библиотека с забавным названием Cats. Ресурс [herding cats](https://eed3si9n.com/herding-cats/) со статьями об использовании этой библиотеки отсылает к [шуточному рекламному ролику](https://www.youtube.com/watch?v=m_MaJDK3VNE) (отсылающему к [известной идиоме](https://en.wikipedia.org/wiki/Herding_cats)). Но всё же, в первую очередь, название берёт начало от “теории категорий” (**Cat**egorie**s**). Реализованные в библиотеке инструменты бывают очень полезны в работе не только с контейнером `IO`, но и с `ZIO`, `Future`, не говоря уже об обычных `Option`, `List` и т.п.

Также в данной статье постоянно используется термин “контейнер” везде, где обычно говорят о “монадах” или “функторах”. Такое решение выбрано здесь потому, что использовать такие термины теории категорий по отношению, например, к `Option[_]`, вообще говоря, некорректно. Также функторами и монадами не являются одноименные классы типов – это именно что “классы”, к которым, для того же `Option`, относятся конкретные значения типов `Functor[Option]`, `Moand[Option]`. И только эти значения (кои могут иметь *разные реализации* для одного и того же конструктора типов!) правильно называть функторами и монадами. Поэтому здесь используется более подходящее определение из теории категорий в отношении обобщённых типов – *подкатегории типов*.

Более детальный обзор теории категорий в приложении к программированию ожидается в одной из следующих статей. Здесь же пока предложу ознакомиться с такими материалами:
- [хабр-переводы](https://habr.com/ru/articles/305018/) (см. ссылки в начале и саму статью) первых глав книги “Теория категорий для программистов” Бартоша Милевски;
- [Теория категорий на JavaScript. Часть 1. Категория множеств](https://habr.com/ru/companies/cit/articles/313254/) – тут хорошие картинки, раскрывающие, в частности, понятие “универсального свойства”;
- [Монады с точки зрения программистов (и немного теории категорий)](https://habr.com/ru/articles/445488/) – примеры на Hakell, но также есть несколько наглядных иллюстраций;

Также рекомендую книгу Сергея Виницкого [The Science of Functional Programming](https://github.com/winitzki/sofp/releases/download/v0.11.2/sofp-draft.pdf) – это версия 2021 года, а более свежую версию можно самому [приобрести](https://leanpub.com/sofp), или попробовать собрать из [исходников на GitHub](https://github.com/winitzki/sofp/tree/master/sofp-src).

Итак, мы рассмотрели, на первый взгляд, простое понятие “обобщённые типы” с самых разных ракурсов. Кроме того, прояснили, как они помогают создавать простые, эффективные и надёжные программы. Надеюсь, этот обзор оказался полезен читателю не меньше, чем и автору 😉.


